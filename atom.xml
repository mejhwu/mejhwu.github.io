<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>个人博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://mejhwu.github.io/"/>
  <updated>2018-09-05T12:11:16.195Z</updated>
  <id>https://mejhwu.github.io/</id>
  
  <author>
    <name>jhwu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>EM算法</title>
    <link href="https://mejhwu.github.io/2018/09/05/EM%E7%AE%97%E6%B3%95/"/>
    <id>https://mejhwu.github.io/2018/09/05/EM算法/</id>
    <published>2018-09-04T16:00:00.000Z</published>
    <updated>2018-09-05T12:11:16.195Z</updated>
    
    <content type="html"><![CDATA[<h1 id="em算法">EM算法</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;em算法&quot;&gt;EM算法&lt;/h1&gt;

      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Java 8 新特性</title>
    <link href="https://mejhwu.github.io/2018/09/05/java8%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    <id>https://mejhwu.github.io/2018/09/05/java8新特性/</id>
    <published>2018-09-04T16:00:00.000Z</published>
    <updated>2018-09-05T14:18:45.084Z</updated>
    
    <content type="html"><![CDATA[<h1 id="java-8-新特性">Java 8 新特性</h1><h2 id="lambda表达式">Lambda表达式</h2><p>lambda表达式可理解为简洁地表示可传递的匿名函数的一种方式：没有名称，有参数列表、函数主体、返回类型。</p><p>lambda表达式有3个部分：</p><pre><code>            1. 参数列表    2. 箭头(-&gt;)    3. lambda主体</code></pre><p>下面是一个lambda表达式的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">int</span> a, <span class="keyword">int</span> b) -&gt; a + b;</span><br></pre></td></tr></table></figure><p>在上面的例子中，<code>(int a, int b)</code>是参数列表，参数类型可省略<code>（a, b)</code>。lambda主体为<code>a + b</code>。</p><h3 id="函数式接口">函数式接口</h3><p>函数式接口就是只定义了一个抽象方法的接口，比如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Comparator</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">compare</span><span class="params">(T o1, T o2)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Runnable</span> </span>&#123;Su</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>lambda表达式允许直接以内联的形式为函数式接口的抽象方法提供实现，并把整个表达式作为函数式接口的实例。类似与匿名内部类，lambda表达式相对与匿名内部类而言更加简洁：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Runnable r1 = () -&gt; System.out.println(<span class="string">"Hello World 1"</span>);</span><br><span class="line"></span><br><span class="line">Runnable r2 = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Hello World 2"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数式接口的抽象方法的签名就是lambda表达式的签名，这种抽象方法叫做函数描述符。在将lambda表达式作为参数传递或赋值给变量的时候需要做类型检测，要求lambda表达式的签名与函数式接口的抽象方法的签名一致。</p><p>常见的函数时接口有：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Predicate</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">test</span><span class="params">(T t)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FuncationInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Consumer</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">accept</span><span class="params">(T t)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FuncationInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Function</span>&lt;<span class="title">T</span>, <span class="title">R</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function">R <span class="title">apply</span><span class="params">(T t)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p><code>@FunctionInterface</code>用于标注该接口会设计为一个函数式接口，如果使用<code>@FunctionInterface</code>定义了一个接口，但它不是函数式接口的时候编译器就会返回一个提示原因的错误。</p><p>除了以上3个通用的函数式接口外，java8还提供了一些专为特定类型设计的接口。</p><table><thead><tr class="header"><th align="left">函数式接口</th><th>函数描述符</th><th>原始类型特化</th></tr></thead><tbody><tr class="odd"><td align="left"><code>Predicate&lt;T&gt;</code></td><td><code>T -&gt; boolean</code></td><td><code>IntPredicate, LongPredicate, DoublePredicate</code></td></tr><tr class="even"><td align="left"><code>Consumer&lt;T&gt;</code></td><td><code>T -&gt; void</code></td><td><code>IntConsumer, LongConsumer, DoubleConsumer</code></td></tr><tr class="odd"><td align="left"><code>Functino&lt;T,R&gt;</code></td><td><code>T -&gt; R</code></td><td><code>IntFuncation&lt;R&gt;, IntToDoubleFunction, ...</code></td></tr><tr class="even"><td align="left"><code>Supplier&lt;T&gt;</code></td><td><code>() -&gt; T</code></td><td><code>BooleanSupplier, IntSupplier, ...</code></td></tr><tr class="odd"><td align="left"><code>UnaryOperator&lt;T&gt;</code></td><td><code>T -&gt; T</code></td><td><code>IntUnaryOperator, LongUnaryOperator, ...</code></td></tr><tr class="even"><td align="left"><code>BinaryOperator&lt;T&gt;</code></td><td><code>(T, T) -&gt; T</code></td><td><code>IntBinaryOperator, LongBinaryOperator, ...</code></td></tr><tr class="odd"><td align="left"><code>BiPredicate&lt;L, R&gt;</code></td><td><code>(L, R) -&gt; boolean</code></td><td></td></tr><tr class="even"><td align="left"><code>BiConsumer&lt;T, U&gt;</code></td><td><code>(T, U) -&gt; void</code></td><td><code>ObjIntConsumer&lt;T&gt;, ObjLongConsumer&lt;T&gt;, ...</code></td></tr><tr class="odd"><td align="left"><code>BiFunction&lt;T,U,R&gt;</code></td><td><code>(T, U) -&gt; R</code></td><td><code>ToIntBiFunction&lt;T, U&gt;, ...</code></td></tr></tbody></table><h3 id="类型检测">类型检测</h3><p>Lambda的类型是从使用Lambda的上下文中推断出来的，上下文中Lambda表达式需要的类型称为目标类型。统一个Lambda表达式可以与不同的函数式接口联系起来，只要它们的抽象方法的签名能够兼容。比如<code>Callable</code>和<code>PrivilegeAction</code>的抽象方法的方法签名都是无参数并返回一个T。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Callable&lt;Integer&gt; c = () -&gt; <span class="number">42</span>;</span><br><span class="line">PrevilegedAction&lt;Integer&gt; p = () -&gt; <span class="number">42</span>;</span><br></pre></td></tr></table></figure><h3 id="方法引用">方法引用</h3><p>方法引用就是让你可以重复使用现有的方法定义，并可以想Lambda表达式一样传递。</p><p>方法引用主要有三类：</p><p>（1） 只想静态方法的方法引用（如<code>Interger</code>的<code>parseInt</code>方法，写作<code>Integer::parseInt</code>）</p><p>（2） 指向任意类型实例方法的方法引用（如<code>String</code>的<code>length</code>方法，写作<code>String::length</code>）</p><p>（3） 指向现有对象的的实例方法。</p><p>方法引用可以与Lambda相对应。</p><p>（1） Lambda ——— <code>(args) -&gt; ClassName.staticMethod(args)</code></p><p>​ 方法引用 ——— <code>ClassName::staticMethod</code></p><p>（2） Lambda ——— <code>(arg0, arg1) -&gt; arg0.instanceMethod(arg1)</code></p><p>​ 方法引用 ——— <code>ClassName::instanceMethod</code></p><p>（3） Lambda ——— <code>(args) -&gt; expr.instanceMethod(args)</code></p><p>​ 方法引用 ——— <code>expr::instanceMethod</code></p><p>对于一个现有的构造函数，可以利用它的名称和关键字<code>new</code>来创建一个引用：<code>ClassName::new</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Supplier&lt;Apple&gt; s = Apple::<span class="keyword">new</span>;</span><br><span class="line">Apple a = s.get();</span><br><span class="line"></span><br><span class="line">等价于</span><br><span class="line"></span><br><span class="line">Supplier&lt;Apple&gt; s = () -&gt; <span class="keyword">new</span> Apple();</span><br><span class="line">Apple a = s.get();</span><br></pre></td></tr></table></figure><h2 id="流">流</h2><p>流简单来说就是“从支持数据处理操作的源生成的元素序列”。流操作的两个重要特点：</p><ol style="list-style-type: decimal"><li>流水线 —— 很多流操作本身会返回一个流，这样多个操作就可以链接起来，形成一个大的流水线。</li><li>内部迭代 —— 与使用迭代器显示迭代不同，流的迭代操作是在背后进行的。</li></ol><p>流中的数据只能遍历一次，遍历完后，这个流就已经被消费掉了。</p><p><code>java.util.stream.Stream</code>接口中定义了许多操作，可以大致分为两类，中间操作和终端操作。中间操作会返回另外一个流，终端操作会从流的流水线生成结果。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line"><span class="keyword">long</span> res = numbers.stream()</span><br><span class="line">    .filter(n -&gt; n &gt; <span class="number">3</span>)</span><br><span class="line">    .map(n -&gt; n * n)</span><br><span class="line">    .count();</span><br></pre></td></tr></table></figure><table><thead><tr class="header"><th>操作</th><th>类型</th><th>返回类型</th><th>函数描述符</th></tr></thead><tbody><tr class="odd"><td>filter</td><td>中间</td><td>Stream<t></t></td><td>T -&gt; boolean</td></tr><tr class="even"><td>map</td><td>中间</td><td>Stream<r></r></td><td>T -&gt; R</td></tr><tr class="odd"><td>limit</td><td>中间</td><td>Stream<t></t></td><td></td></tr><tr class="even"><td>sorted</td><td>中间</td><td>Stream<t></t></td><td>(T, T) -&gt; int</td></tr><tr class="odd"><td>distinct</td><td>中间</td><td>Stream<t></t></td><td></td></tr><tr class="even"><td></td><td></td><td></td><td></td></tr></tbody></table><table><thead><tr class="header"><th>操作</th><th>类型</th><th>目的</th></tr></thead><tbody><tr class="odd"><td>forEach</td><td>终端</td><td>消费流中的每个元素并对其应用Lambda。返回void。</td></tr><tr class="even"><td>count</td><td>终端</td><td>返回流中元素的个数。返回long。</td></tr><tr class="odd"><td>collect</td><td>终端</td><td>把流归约成一个集合，比如List、Map、Integer。</td></tr></tbody></table><h3 id="筛选和切片">筛选和切片</h3><p><code>Stream</code>接口支持<code>filter</code>，该操作会接受一个谓词（一个返回<code>boolean</code>的函数）作为参数，并返回一个包括所有符合谓词的元素的流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">List&lt;Integer&gt; odds = numbers.stream().filter(n -&gt; n % <span class="number">2</span> == <span class="number">1</span>).collect(toList());</span><br></pre></td></tr></table></figure><p><code>distinct()</code>方法会返回一个元素各异（根据流锁生成元素的<code>hashCode</code>和<code>equals</code>方法是实现）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>);</span><br><span class="line">numbers.stream().filter(i -&gt; i % <span class="number">2</span> == <span class="number">0</span>).distinct().forEach(System.out::println);</span><br></pre></td></tr></table></figure><p><code>limit(n)</code>方法会返回一个不超过给定长度的流，所需的长度作为参数传递给<code>limit</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>);</span><br><span class="line">numbers.stream().filter(i -&gt; i % <span class="number">2</span> == <span class="number">0</span>).limit(<span class="number">3</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure><p><code>skip(n)</code>方法返回一个扔掉了前n个元素的流，如果流中元素不足n个，则返回一个空流。<code>limit(n)</code>和<code>skip(n)</code>是互补的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>);</span><br><span class="line">numbers.stream().filter(i -&gt; i % <span class="number">2</span> == <span class="number">0</span>).skip(<span class="number">2</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure><h3 id="映射">映射</h3><p><code>map</code>方法接受一个函数作为参数，这个函数会被应用到每个元素上，并将其映射成一个新的元素，返回一个新元素的流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; words = Arrays.asList(<span class="string">"Java 8"</span>, <span class="string">"Lambdas"</span>, <span class="string">"In"</span>, <span class="string">"Actions"</span>);</span><br><span class="line">List&lt;Integer&gt; wordLengths = words.stream().map(String::length).collect(toList());</span><br></pre></td></tr></table></figure><p><code>flatMap</code>方法将一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流。简而言之，就是把流中的函数参数所产生的流中的元素提取出来后组合为一个新的流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; words = Arrays.asList(<span class="string">"Java 8"</span>, <span class="string">"Lambdas"</span>, <span class="string">"In"</span>, <span class="string">"Actions"</span>);</span><br><span class="line">List&lt;String&gt; uniqueCharacters = </span><br><span class="line">    words.stream()</span><br><span class="line">    .map(w -&gt; w.split(<span class="string">""</span>))   <span class="comment">// 返回Stream&lt;String[]&gt;</span></span><br><span class="line">    .flatMap(Arrays::stream)  <span class="comment">//Array::stream将String[]转换为Stream&lt;String&gt;, flatMap将所                                 有Stream中的String提取出来并合成为一个新的Stream&lt;String&gt;</span></span><br><span class="line">    .distinct()</span><br><span class="line">    .collect(toList())</span><br></pre></td></tr></table></figure><h3 id="查找和匹配">查找和匹配</h3><p><code>anyMatch</code>可以检查流中是否有一个元素能匹配给定的谓词。</p><p><code>allMatch</code>检查流中的元素是否都能匹配给定谓词。</p><p><code>noneMatch</code>确保流中没有任何元素与给定谓词匹配。</p><p><code>findAny</code>方法将返回当前流中的任意元素。</p><p><code>findFirst</code>方法查找流中第一个元素。</p><h3 id="归约">归约</h3><p><code>reduce</code>操作可以将流中所有元素反复结合起来，得到一个值，这样的查询操作被称为归约操作（将流归约为一个值）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 元素求和</span></span><br><span class="line"><span class="keyword">int</span> sum = numbers.stream().reduce(<span class="number">0</span>, (a ,b) -&gt; a + b);</span><br></pre></td></tr></table></figure><p><code>reduce</code>接受两个参数：</p><ol style="list-style-type: decimal"><li>一个是初始值。</li><li>一个<code>BinaryOperator&lt;T&gt;</code>来将两个元素结合起来产生一个新值。</li></ol><p><code>reduce</code>还有一个重载变体，它不接受初始值，但是会返回一个<code>Opetional</code>对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Opetional&lt;Integer&gt; sum = numbers.stream().reduce((a, b) -&gt; a + b);</span><br></pre></td></tr></table></figure><h3 id="构建流">构建流</h3><p>可直接使用静态方法<code>Stream.of</code>方法，通过显示值创建一个流，它接受任意数量的参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; stream = Stream.of(<span class="string">"Java 8"</span>, <span class="string">"Lambdas"</span>, <span class="string">"In"</span>, <span class="string">"Action"</span>);</span><br><span class="line">stream.map(String::toUpperCase).forEach(System.out::println);</span><br></pre></td></tr></table></figure><p>可以使用<code>empty</code>得到一个空流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; emptySteam = Stream.empty();</span><br></pre></td></tr></table></figure><p>可以使用静态方法<code>Arrays.stream</code>从数组创建一个流，它接受一个数组作为参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>[] numbers = &#123;<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> sum = Arrays.stream(numbers);</span><br></pre></td></tr></table></figure><p><code>Stream API</code>提供了两个静态方法来从函数生成流：<code>Stream.iterate</code>和<code>Stream.generate</code>。这两个操作可以创建无限流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Stream.iterate(<span class="number">0</span>, n -&gt; n + <span class="number">2</span>).limit(<span class="number">10</span>).forEach(System.out::println);</span><br><span class="line">Stream.generate(Math::random).limit(<span class="number">5</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure><h3 id="收集器">收集器</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;java-8-新特性&quot;&gt;Java 8 新特性&lt;/h1&gt;
&lt;h2 id=&quot;lambda表达式&quot;&gt;Lambda表达式&lt;/h2&gt;
&lt;p&gt;lambda表达式可理解为简洁地表示可传递的匿名函数的一种方式：没有名称，有参数列表、函数主体、返回类型。&lt;/p&gt;
&lt;p&gt;lambda
      
    
    </summary>
    
      <category term="java" scheme="https://mejhwu.github.io/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="https://mejhwu.github.io/2018/06/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://mejhwu.github.io/2018/06/27/神经网络/</id>
    <published>2018-06-27T12:41:46.000Z</published>
    <updated>2018-06-28T03:56:14.926Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络">神经网络</h1><h2 id="神经元模型">神经元模型</h2><p>神经网络中最基本的单元是神经元，类似与生物神经网络中的神经元，当某个神经元的的点位超过某个“阈值”时，那么它被激活并像其他神经元发送信号。</p><p>神经元模型中，神经元接受<span class="math inline">\(n\)</span>个其他神经元传递来的信号，这些信号通过带权重的连接进行传递，神经元接受到的总输入值与阈值进行比较，然后通过激活函数处理产生神经元输出。</p><p>常用的激活函数为<span class="math inline">\(sigmoid(x)\)</span>函数。</p><p><span class="math display">\[sigmoid(x)=\frac{1}{1+e^{-x}}\]</span></p><h2 id="感知机与多层网络">感知机与多层网络</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;神经网络&quot;&gt;神经网络&lt;/h1&gt;
&lt;h2 id=&quot;神经元模型&quot;&gt;神经元模型&lt;/h2&gt;
&lt;p&gt;神经网络中最基本的单元是神经元，类似与生物神经网络中的神经元，当某个神经元的的点位超过某个“阈值”时，那么它被激活并像其他神经元发送信号。&lt;/p&gt;
&lt;p&gt;神经元模型中，神经元
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://mejhwu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>决策树</title>
    <link href="https://mejhwu.github.io/2018/06/27/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    <id>https://mejhwu.github.io/2018/06/27/决策树/</id>
    <published>2018-06-26T16:00:00.000Z</published>
    <updated>2018-09-05T14:19:36.543Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树">决策树</h1><h2 id="基本概念">1. 基本概念</h2><p>决策树是一种常见的机器学习方法,一般一棵决策树为一颗多叉树. 每一个叶子节点就对应于一个决策结果.决策树的生成过程类似于数据结构中的树的生成过程.</p><hr><p>输入:</p><p>训练集<span class="math inline">\(D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\)</span></p><p>属性集<span class="math inline">\(A=\{a_1,a_2,...,a_d\}\)</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">西瓜书基本算法:</span><br><span class="line">过程: 函数TreeGenerate(D, A)</span><br><span class="line">生成节点node</span><br><span class="line"><span class="keyword">if</span> D中样本全属于同一类别C then</span><br><span class="line">    将node标记为C类叶节点; <span class="keyword">return</span></span><br><span class="line">end <span class="keyword">if</span></span><br><span class="line"><span class="keyword">if</span> A为空 OR D中样本在A上的取值相同 then</span><br><span class="line">    将node标记为叶节点,其分类标记为D中样本数最多的类; <span class="keyword">return</span></span><br><span class="line">end <span class="keyword">if</span></span><br><span class="line">从A中选择最优的划分属性a;</span><br><span class="line"><span class="keyword">for</span> a 的每一个值av do</span><br><span class="line">    为node生成一个分支;令Dv表示D中在a上取值为av的样本集;</span><br><span class="line">    <span class="keyword">if</span> Dv 为空 then</span><br><span class="line">        将分支标记为叶节点,其类别标记为D中样本最多的类; <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        以TreeGenerate(Dv, A-&#123;a*&#125;)为分支节点</span><br><span class="line">    end <span class="keyword">if</span></span><br><span class="line">end <span class="keyword">for</span></span><br></pre></td></tr></table></figure><p>输出: 以node为根节点的一颗决策树 ________________________________________</p><p>以下为python代码的伪代码, 参考&lt;<机器学习实战>&gt;</机器学习实战></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(data_set, labels)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> D中样本全输入同一类别C:</span><br><span class="line">        <span class="keyword">return</span> 类别C</span><br><span class="line">    <span class="keyword">if</span> A为空:</span><br><span class="line">        <span class="keyword">return</span> D中样本数最多的类</span><br><span class="line">    从A中选取最优划分属性a</span><br><span class="line">    node = &#123;label: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> a的每一个属性值av:</span><br><span class="line">        node[label][av] = &#123;&#125;</span><br><span class="line">        令Dv表示D在属性a上取值av的样本子集</span><br><span class="line">        <span class="keyword">if</span> Dv为空:</span><br><span class="line">            node[label][av] = D中样本最多的类</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            node[label][av] = create_tree(Dv, labels)</span><br><span class="line">    <span class="keyword">return</span> node</span><br></pre></td></tr></table></figure><p>在&lt;<西瓜书>&gt;中有三种情况导致递归返回:(1)当前节点包含的样本全属于同一类别, 无需划分;(2)当前属性集为空,或是所有样本在所有属性上取值相同,无法划分;(3)当前节点包含的样本集合为空,不能划分</西瓜书></p><p>在&lt;<机器学习实战>&gt;没有判断&quot;所有样本在所有属性上取值相同&quot;这个条件,个人认为原因有两个: 其一, 判断的难度比较大,代码复杂,耗费时间长; 其二, 在满足条件&quot;所有样本在所有属性上取值相同&quot;这个条件时, 其所有样本类别有很大概率是属于同一类, 再者继续训练也只会形成一个单叉树.</机器学习实战></p><h2 id="划分选择">2. 划分选择</h2><p>在以上的算法流程中,最重要的步骤就是在属性集A中选择最优的划分属性a, 一般在划分的过程中,希望划分出来的样本子集尽量属于同一类别, 即节点的&quot;纯度&quot;越来越高.</p><h3 id="信息增益">2.1 信息增益</h3><p><a href="https://zh.wikipedia.org/wiki/%E7%86%B5_%E4%BF%A1%E6%81%AF%E8%AE%BA" target="_blank" rel="noopener">&quot;信息熵&quot;</a>是度量样本集合纯度最常用的一种指标. 假定当前样本集合D中第<span class="math inline">\(k\)</span>类样本的比例为<span class="math inline">\(p_k(k=1,2,...,|\mathcal{Y}|)\)</span>, 则<span class="math inline">\(D\)</span>的信息熵定义为</p><p><span class="math display">\[Ent(D)= \sum ^{|\mathcal{Y}|}_{k=1}p_klog_2p_k\]</span></p><p><span class="math inline">\(Ent(D)\)</span>的值越小,则<span class="math inline">\(D\)</span>的纯度越高.</p><p>计算信息熵时约定:若<span class="math inline">\(p=0\)</span>, 则<span class="math inline">\(plog_2p=0\)</span>. <span class="math inline">\(Ent(D)\)</span>的最小值为0,最大值为<span class="math inline">\(log_2|\mathcal{Y}|\)</span></p><p>下面给出信息增益的计算公式</p><p><span class="math display">\[Gain(D, a)=Ent(D)- \sum ^V_{v=1} \frac {|D|}{|D^v|}Ent(D^v)\]</span></p><p><span class="math inline">\(V\{a^1,a^2,...,a^v\}\)</span>为属性<span class="math inline">\(a\)</span>的属性值集合; <span class="math inline">\(D^v\)</span>为使用属性<span class="math inline">\(a\)</span>在<span class="math inline">\(D\)</span>中进行划分,<span class="math inline">\(D\)</span>中属性<span class="math inline">\(a\)</span>的属性值为<span class="math inline">\(a^v\)</span>的样本子集; <span class="math inline">\(\frac{|D|}{|D^v|}\)</span>为每个分支节点上的权重.</p><p>一般而言, 信息增益越大, 则意味着使用属性<span class="math inline">\(a\)</span>来进行划分所获得的&quot;纯度提升&quot;越大. 所有在算法中选择属性<span class="math inline">\(a_*=arg_{a \in A} maxGain(D, a)\)</span></p><p>python代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain.py" target="_blank" rel="noopener">tree_gain.py</a></p><h3 id="增益率">2.2 增益率</h3><p>信息增益准则对可取值较多的属性有所偏好,为减少这种偏好可能带来的不利影响,可使用&quot;增益率&quot;来选择最优划分属性, 增益率定义为</p><p><span class="math display">\[Gain_ratio(D,a)=\frac{Grain(D,a)}{IV(a)}\]</span></p><p>其中</p><p><span class="math display">\[IV(a)=-\sum_{v=1}^{V}\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}\]</span></p><p><span class="math inline">\(IV(a)\)</span>称为属性<span class="math inline">\(a\)</span>的&quot;固有值&quot;(intrinsic value). 属性<span class="math inline">\(a\)</span>的可能取值数目越多(即V越大), 则<span class="math inline">\(IV(a)\)</span>的值通常会越大.</p><p>需要注意的是, 增益率准则对可取值数目较少的属性所有偏好, 因此根据C4.5算法, 可先从候选划分属性中找出信息增益高于平均水平的属性,再从中选择增益率最高的.</p><p>python代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain_ratio.py" target="_blank" rel="noopener">tree_gain_ratio.py</a></p><h3 id="基尼指数">2.3 基尼指数</h3><p>CART决策树使用&quot;基尼指数&quot;(Gini index)来选择划分属性. 数据集<span class="math inline">\(D\)</span>的纯度可以用基尼值来度量:</p><p><span class="math display">\[Gini(D)=\sum_{k=1}^{|\mathcal{Y}|}\sum_{k{&#39;}\ne k}p_kp_{k^{&#39;}}=1-\sum_{k=1}^{|\mathcal{Y}|}p_k^2\]</span></p><p>直观来说,<span class="math inline">\(Gini(D)\)</span>反映了从数据集<span class="math inline">\(D\)</span>中随机抽取两个样本,其类别不一致的概率. 因此, <span class="math inline">\(Gini(D)\)</span>越小, 则数据集<span class="math inline">\(D\)</span>的纯度越高.</p><p>属性<span class="math inline">\(a\)</span>的基尼指数定义为</p><p><span class="math display">\[Gini\_index(D,a)=\sum_{k=1}^{|\mathcal{Y}|}\frac{|D^v|}{|D|}Gini(D^v)\]</span></p><p>于是,在候选属性集<span class="math inline">\(A\)</span>中选取使划分后基尼指数最小的属性作为最优划分属性,即<span class="math inline">\(a_*=arg_{a\in A}min\ Gini\_index(D,a)\)</span></p><p>python代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gini.py" target="_blank" rel="noopener">tree_gini.py</a></p><h2 id="剪枝处理">3. 剪枝处理</h2><p>剪枝(pruning)是决策树学习算法中对付&quot;过拟合&quot;的主要手段. 决策树剪枝的基本策略有&quot;预剪枝&quot;(prepruning)和&quot;后剪枝&quot;(postpruning).</p><h3 id="预剪枝">3.1 预剪枝</h3><p>预剪枝是指在决策树生成过程中,对每个节点在划分前先进行估计, 若当前节点的划分不能带来决策树泛化性能提升, 则停止划分并讲当前节点标记为页节点.</p><p>预剪枝的决策树生成过程类似于二叉树的先序遍历, 划分前先进行判断是否剪枝, 如果不需要剪枝再生成下一个节点.</p><p>预剪枝基于&quot;贪心&quot;本质禁止这些分支展开,给预剪枝决策树带来了欠拟合的风险.</p><p>预剪枝python伪代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verity_divide</span><span class="params">(train_data_set, train_data_set)</span>:</span></span><br><span class="line">    <span class="comment"># 验证集为空不进行划分</span></span><br><span class="line">    <span class="keyword">if</span> 验证集为空:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    选取最优划分属性a</span><br><span class="line">    划分后节点divide_node = &#123;a: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> a的每一个属性值av:</span><br><span class="line">        令TDv表示训练样本train_data_set中属性a上取值为av的样本子集</span><br><span class="line">        divide_node[a][av] = TDv中类别最多的类</span><br><span class="line">    divide_count表示划分后验证的正确数量</span><br><span class="line">    <span class="keyword">for</span> train_data_set中的每一个样本:</span><br><span class="line">        <span class="keyword">if</span> 验证正确:</span><br><span class="line">            divide_cout += <span class="number">1</span></span><br><span class="line">    not_divide_count表示train_data_set中样本最多的类的数量</span><br><span class="line">    <span class="keyword">if</span> divide_count &gt; not_divide_count:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(train_data_set, verity_data_set, labels)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> train_data_set中样本全输入同一类别C:</span><br><span class="line">        <span class="keyword">return</span> 类别C</span><br><span class="line">    <span class="keyword">if</span> A为空:</span><br><span class="line">        <span class="keyword">return</span> train_data_set中样本数最多的类</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> verity_divide(train_data_set, verity_data_set):</span><br><span class="line">        <span class="keyword">return</span> D中样本最多的类</span><br><span class="line">    <span class="comment"># 此处可优化, 可先获取最优属性后传入verity_divide()</span></span><br><span class="line">    从A中选取最优划分属性a</span><br><span class="line">    node = &#123;label: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> a的每一个属性值av:</span><br><span class="line">        node[label][av] = &#123;&#125;</span><br><span class="line">        令TDv表示train_data_set在属性a上取值av的样本子集</span><br><span class="line">        令TVv表示verity_data_set在属性a上取值为av的样本子集</span><br><span class="line">        <span class="keyword">if</span> TDv为空:</span><br><span class="line">            node[label][av] = train_data_set中样本最多的类</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            node[label][av] = create_tree(TDv, TVv,  labels)</span><br><span class="line">    <span class="keyword">return</span> node</span><br></pre></td></tr></table></figure><p>完整代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain_prepruning.py" target="_blank" rel="noopener">tree_gain_prepruning.py</a></p><h3 id="后剪枝">3.2 后剪枝</h3><p>后剪枝是先从训练集生成一颗完整的决策树, 然后自底向上地对非叶子节点进行考察, 若将该节点对应的子树替换为叶节点能带来决策树的泛化性能提升,则将该子树替换为叶节点.</p><p>后剪枝决策树的生成过程类似于二叉树的后续遍历; 即先生成决策树, 在判断是否需要剪枝, 如果需要剪枝则放弃子树, 直接将节点标记为叶节点.</p><p>后剪枝的过程是在完全决策树之后进行的,并且要自底向上地对决策树中的所有非叶节点进行逐一考察, 因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多.</p><p>后剪枝python伪代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verity_divide</span><span class="params">(tree, train_data_set, verity_data_set)</span>:</span></span><br><span class="line">    <span class="comment"># 验证集为空不剪枝</span></span><br><span class="line">    <span class="keyword">if</span> 验证集为空:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    not_divide_right_rate = 不划分的验证正确率</span><br><span class="line">    divide_right_rate = 划分后的验证正确率</span><br><span class="line">    <span class="comment"># 不划分的验证正确率大于划分的验证正确率时剪枝</span></span><br><span class="line">    <span class="keyword">if</span> not_divide_right_rate &gt; divide_right_rate:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(train_data_set, verity_data_set, labels)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> train_data_set中样本全输入同一类别C:</span><br><span class="line">        <span class="keyword">return</span> 类别C</span><br><span class="line">    <span class="keyword">if</span> A为空:</span><br><span class="line">        <span class="keyword">return</span> train_data_set中样本数最多的类</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> verity_divide(train_data_set, verity_data_set):</span><br><span class="line">        <span class="keyword">return</span> train_data_set中样本最多的类</span><br><span class="line">    从A中选取最优划分属性a</span><br><span class="line">    node = &#123;label: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> a的每一个属性值av:</span><br><span class="line">        node[label][av] = &#123;&#125;</span><br><span class="line">        令TDv表示train_data_set在属性a上取值av的样本子集</span><br><span class="line">        令TVv表示verity_data_set在属性a上取值av的样本子集</span><br><span class="line">        <span class="keyword">if</span> TDv为空:</span><br><span class="line">            node[label][av] = train_data_set中样本最多的类</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            node[label][av] = create_tree(TDv, TVv, labels)</span><br><span class="line">    <span class="keyword">if</span> verity_divide(node, train_data_set, verity_data_set):</span><br><span class="line">        node = train_data_set中样本最多的类</span><br><span class="line">    <span class="keyword">return</span> node</span><br></pre></td></tr></table></figure><p>完整代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain_postpruning.py" target="_blank" rel="noopener">tree_gain_postpruning</a></p><h2 id="连续与缺失值">4. 连续与缺失值</h2><h3 id="连续值处理">4.1 连续值处理</h3><p>由于连续属性的可取值数目不再有限, 因此,不能直接根据连续属性的可取值来对节点进行划分, 需要将连续属性离散化, 最简单的策略是采用二分法对连续属性进行处理.</p><p>给定样本集<span class="math inline">\(D\)</span>和连续属性<span class="math inline">\(a\)</span>, 假定<span class="math inline">\(a\)</span>在<span class="math inline">\(D\)</span>上出现了n个不同的取值, 将这些值从小到大进行排序, 记为<span class="math inline">\(\{a^1,a^1,...,a^n\}\)</span>. 基于划分点<span class="math inline">\(t\)</span>可将D分为子集<span class="math inline">\(D_t^-\)</span>和<span class="math inline">\(D_t^+\)</span>, 其中<span class="math inline">\(D_t^-\)</span>包含那行属性a上取值不大于t的样本, 而<span class="math inline">\(D_t^+\)</span>则包含那些在属性<span class="math inline">\(a\)</span>上取值大于<span class="math inline">\(t\)</span>的样本. 显然, 对相邻的属性取值<span class="math inline">\(a^i\)</span>和<span class="math inline">\(a^{i+1}\)</span>来说, <span class="math inline">\(t\)</span>在区间<span class="math inline">\([a^i,a^{i+1})\)</span>中取任何值产生的划分结果相同. 因此, 对连续属性<span class="math inline">\(a\)</span>, 我们可考察包含<span class="math inline">\(n-1\)</span>个元素的候选划分点集合</p><p><span class="math display">\[T_a=\{\frac{a^i+a^{i+1}}{2}|i\le i\le n-1|\}\]</span></p><p>即把区间<span class="math inline">\([a^i,a^{i+1})\)</span>的中位点<span class="math inline">\(\frac{a^i+a^{i+1}}{2}\)</span>作为候选划分点. 然后就可像离散属性一样来考察这些划分点, 选取最优的划分点进行样本集合的划分.</p><p><span class="math display">\[Gain(D,a)=\max\limits_{t\in T_a} Ent(D) - \sum_{\lambda\in \{-,+\}} \frac{|D|}{|D_t^\lambda|}Ent(D_t^\lambda)\]</span></p><p>其中<span class="math inline">\(Gain(D,a,t)\)</span>是样本集<span class="math inline">\(D\)</span>基于划分点<span class="math inline">\(t\)</span>二分后的信息增益. 于是,可选择<span class="math inline">\(Gain(D,a,t)\)</span>最大化的划分点.</p><p>需要注意, 与离散值不同, 若当前节点划分属性为连续属性, 连续属性还可作为其后代节点的划分属性.</p><p>在写代码的时候需要注意在离散属性和连续属性的<span class="math inline">\(gain(D,a)\)</span>时需要分开处理. 在构建决策树时, 离散属性和连续属性也需要分开处理, 因为划分连续属性时,不需要在数据集中去除连续属性.</p><p>完整python代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain_continuous_value.py" target="_blank" rel="noopener">tree_gain_continuous_value.py</a></p><h3 id="缺失值处理">4.2 缺失值处理</h3><p>面对缺失值需要解决的两个问题: (1)如何在属性值缺失的情况下进行划分属性选择? (2)给定划分属性,若样本在改属性上的值缺失,如何对样本进行划分?</p><p>给定训练集<span class="math inline">\(D\)</span>和属性<span class="math inline">\(a\)</span>, 令<span class="math inline">\(\tilde{D}\)</span>表示<span class="math inline">\(D\)</span>中在属性<span class="math inline">\(a\)</span>上没有缺失值的样本子集. 对问题(1), 显然仅可根据<span class="math inline">\(\tilde{D}\)</span>来判断属性<span class="math inline">\(a\)</span>的优劣. 假定属性<span class="math inline">\(a\)</span>有<span class="math inline">\(V\)</span>个可取值<span class="math inline">\(\{a^1,a^2,...,a^V\}\)</span>, 令<span class="math inline">\(\tilde{D}^v\)</span>表示<span class="math inline">\(\tilde{D}\)</span>在属性<span class="math inline">\(a\)</span>上的取值为<span class="math inline">\(a^v\)</span>的样本子集, <span class="math inline">\(\tilde{D}_k\)</span>表示<span class="math inline">\(\tilde{D}\)</span>属性第<span class="math inline">\(k\)</span>类<span class="math inline">\((k=1,2,...,|\mathcal{Y}|)\)</span>的样本子集, 则显然有<span class="math inline">\(\tilde{D}=\cup_{k=1}^{|\mathcal{Y}|}\tilde{D}_k\)</span>, <span class="math inline">\(\tilde{D}=\cup_{v=1}^V\tilde{D}^v\)</span>. 假定我们为每个样本<span class="math inline">\(\boldsymbol{x}\)</span>赋予一个权重<span class="math inline">\(w_{\boldsymbol{x}}\)</span>, 并定义</p><p><span class="math display">\[\rho=\frac{\sum_{\boldsymbol{x}\in \tilde{D}}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in D}w_{\boldsymbol{x}}}\]</span></p><p><span class="math display">\[\tilde{p}_k=\frac{\sum_{\boldsymbol{x}\in \tilde{D}_k}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in \tilde{D}}w_{\boldsymbol{x}}} \ \ \ \ \ (1\le k\le |\mathcal{Y}|)\]</span></p><p><span class="math display">\[\tilde{r}_v=\frac{\sum_{\boldsymbol{x}\in \tilde{D}^v}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in \tilde{D}}w_{\boldsymbol{x}}} \ \ \ \ \ (1\le v\le V)\]</span></p><p>对属性<span class="math inline">\(a\)</span>, <span class="math inline">\(\rho\)</span>表示无缺失值样本所占的比例, <span class="math inline">\(\tilde{p}_k\)</span>表示无缺失值样本中第<span class="math inline">\(k\)</span>类所占的比例, <span class="math inline">\(\tilde{r}_v\)</span>则表示无缺失值样本中属性a上取值<span class="math inline">\(a^v\)</span>的样所占的比例. 显然<span class="math inline">\(\sum_{k=1}^{|\mathcal{Y}|}\tilde{p}_k=1\)</span>, <span class="math inline">\(\sum_{v=1}^V\tilde{r}_v=1\)</span></p><p>基于上述定义, 可将信息增益的计算式推广为</p><p><span class="math display">\[Gian(D,a)=\rho \times Gain(\tilde{D},a)=\rho \times (Ent(\tilde{D}) - \sum_{v=1}^V \tilde{r}_v Ent(\tilde{D}^v))\]</span></p><p>其中</p><p><span class="math display">\[Ent(\tilde{D}) = - \sum_{k=1}^{|\mathcal{Y}|}\tilde{p}_k log_2 \tilde{p}_k\]</span></p><p>对问题(2), 若样本<span class="math inline">\(\boldsymbol{x}\)</span>在划分属性<span class="math inline">\(a\)</span>上的取值已知, 则将<span class="math inline">\(\boldsymbol{x}\)</span>划入与其取值对应的子节点, 且样本权值在子节点中保持<span class="math inline">\(w_{\boldsymbol{x}}\)</span>. 若样本<span class="math inline">\(\boldsymbol{x}\)</span>在划分属性<span class="math inline">\(a\)</span>上的取值未知, 则将<span class="math inline">\(\boldsymbol{x}\)</span>同时划入所有子节点, 且样本权值在与属性<span class="math inline">\(a^v\)</span>对应的子节点中调整为<span class="math inline">\(\tilde{r}_v \cdot w_{\boldsymbol{x}}\)</span>; 直观地看, 就是让同一样本以不同的概率划入到不同的子节点中去.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;决策树&quot;&gt;决策树&lt;/h1&gt;
&lt;h2 id=&quot;基本概念&quot;&gt;1. 基本概念&lt;/h2&gt;
&lt;p&gt;决策树是一种常见的机器学习方法,一般一棵决策树为一颗多叉树. 每一个叶子节点就对应于一个决策结果.决策树的生成过程类似于数据结构中的树的生成过程.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;输入
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>梯度下降</title>
    <link href="https://mejhwu.github.io/2018/04/24/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <id>https://mejhwu.github.io/2018/04/24/梯度下降/</id>
    <published>2018-04-23T16:00:00.000Z</published>
    <updated>2018-06-27T12:57:51.014Z</updated>
    
    <content type="html"><![CDATA[<p>梯度下降就是在函数当前点梯度(偏导)的反方向的规定步长进行迭代,直至收敛(即到达局部最小值).</p><p>批量梯度下降</p><p>假设有损失函数</p><p><span class="math display">\[J(\theta)=\frac{1}{2}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2\]</span></p><p>其中<span class="math inline">\(h_\theta(x)=\theta_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n\)</span>.</p><p>那么</p><p><span class="math display">\[\theta_j:=\theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta)\]</span></p><p><span class="math display">\[\begin{aligned} \frac{\partial}{\partial \theta_j}J(\theta) = \sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \end{aligned}\]</span></p><p>所以</p><p><span class="math display">\[\theta_j:=\theta_j + \sum_{i=1}^{m}( y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}\]</span></p><p>以上公示就是批量梯度下降,每一次迭代<span class="math inline">\(\theta_j\)</span>时,都需要完全遍历整个输入集合.</p><p>随机梯度下降</p><p>假设只有一个输入样本,则</p><p><span class="math display">\[\theta_j:=\theta_j + ( y - h_\theta(x)x_j\]</span></p><p>以上就是随机梯度下降的公式.即每次更新<span class="math inline">\(\theta_j\)</span>只用一个样本.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;梯度下降就是在函数当前点梯度(偏导)的反方向的规定步长进行迭代,直至收敛(即到达局部最小值).&lt;/p&gt;
&lt;p&gt;批量梯度下降&lt;/p&gt;
&lt;p&gt;假设有损失函数&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[J(\theta)=\frac{1}{2}\su
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>数理统计的基本概念</title>
    <link href="https://mejhwu.github.io/2018/04/22/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E6%80%BB%E7%BB%93/"/>
    <id>https://mejhwu.github.io/2018/04/22/数理统计总结/</id>
    <published>2018-04-21T16:00:00.000Z</published>
    <updated>2018-09-05T14:24:32.127Z</updated>
    
    <content type="html"><![CDATA[<h1 id="总体与样本">总体与样本</h1><h2 id="总体-个体-样本">总体 个体 样本</h2><p>一般将研究对象的全体组成的集合成为<strong>总体</strong>,组成总体的每一个成员成为<strong>个体</strong>.</p><p>从总体中挑选一部分个体的过程叫<strong>样本</strong>, 样本所含的个体数称为<strong>样本容量</strong>.</p><h2 id="抽样方法">抽样方法</h2><p>抽样要保证对每一个个体&quot;机会均等&quot;,即总体中每一个体有同样机会被抽到,谁也不占优.凡是满足这个要求的抽样叫做<strong>随机抽样</strong>.</p><p>常用随机抽样方案:</p><p>(1)&quot;集团抽样&quot;.即先把总体中的全部个体,按某种考虑分成一些大集团,每个大集团内又可分为若干小集团,后者还可以再细分.抽样时,先用随机的方法抽取若干个大集团,再在抽出的每个大集团内分别抽出若干个小集团,<span class="math inline">\(\cdots \cdots\)</span>这样下去,最后在最低一级的集团中随机抽出若干个体.这样抽出的全部个体构成所需的样本.</p><p>(2)&quot;分层按比例抽样&quot;.必须有两个条件:一是分层的标准应合理.这主要是指层与层之间确实有较大差异,而每层内各个个体的差异较小.二是每层所含个体数在总体全部个体数所占的比例要能够比较确切地知道.</p><h1 id="样本分布和统计量">样本分布和统计量</h1><h2 id="样本分布">样本分布</h2><p>样本是按照一定的方法从总体中抽出的一部分个体所组成的集合.样本总所含的个体数称为<strong>样本容量</strong>或<strong>样本大小</strong>.</p><p>将<span class="math inline">\(n\)</span>个抽象的随机变量<span class="math inline">\(X_1,X_2,\cdots,X_n\)</span>称为样本,而把具体的观测数字<span class="math inline">\((x_1,x_2,\cdots,x_n)\)</span>看成该样本的一组取值.</p><p>样本<span class="math inline">\((X_1,X_2,\cdots,X_n)\)</span>既然是随机变量,也就有其概率分布.样本的概率分布称为<strong>样本分布</strong>.</p><p>作为随机变量的<span class="math inline">\(X_1,X_2,\cdots,X_n\)</span>可以认为是相互独立且有相同的分布,每一个<span class="math inline">\(X_i\)</span>的分布都与总体<span class="math inline">\(X\)</span>有相同的分布.</p><p>&quot;随机抽样&quot;的要求保证了样本分量<span class="math inline">\(X_1\)</span>与总体<span class="math inline">\(X\)</span>同分布的性质,&quot;每次抽取时,总体成分保持不变&quot;的要求保证了样本的各分量<span class="math inline">\(X_1,\cdots,X_n\)</span>相互独立且都与总体<span class="math inline">\(X\)</span>有相同分布的性质.</p><p>统计学中将&quot;每次抽取时,总体的成分保持不变的随机抽样&quot;称为<strong>简单随机抽样</strong>.</p><p>由简单随机抽样得到的样本称为<strong>随机样本</strong>.</p><h2 id="统计量">统计量</h2><p>对样本进行必要的加工和运算处理后得到的结果称为<strong>统计量</strong>.</p><p>常用统计量:</p><ol style="list-style-type: decimal"><li>样本均值</li></ol><p><span class="math display">\[\bar{X}=\frac{1}{n}\sum_{i=1}{n}X_k\]</span></p><ol start="2" style="list-style-type: decimal"><li>样本方差</li></ol><p><span class="math display">\[S^2=\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2\]</span></p><ol start="3" style="list-style-type: decimal"><li>样本标准差</li></ol><p><span class="math display">\[S=\sqrt{S}=\sqrt{\frac{1}{n-1}\sum_{i=1}{n}(X_i-\bar{X})^2}\]</span></p><ol start="4" style="list-style-type: decimal"><li>样本<span class="math inline">\(k\)</span>阶原点矩</li></ol><p><span class="math display">\[A_k=\frac{1}{n}\sum_{i=1}^nX_i^k\]</span></p><ol start="5" style="list-style-type: decimal"><li>样本<span class="math inline">\(k\)</span>阶中心矩</li></ol><p><span class="math display">\[B_k=\frac{1}{n}\sum_{i=1}{n}(X_i-\bar{X})^k\]</span></p><ol start="6" style="list-style-type: decimal"><li>从总体<span class="math inline">\(X\)</span>中抽取一容量为<span class="math inline">\(n\)</span>的样本<span class="math inline">\(X_1,X_2,\cdots,X_n\)</span>,设相应的观测值为<span class="math inline">\(x_1,\cdots,x_n\)</span>,将观测值按由小到大的次序重新排列为</li></ol><p><span class="math display">\[x_{(1)} \le x_{(2)} \le \cdots \le x_{(n)}\]</span></p><p>则称<span class="math inline">\(x_{(1)},\cdots,x_{(n)}\)</span>为原始样本观测值<span class="math inline">\(x_1,\cdots,x_n\)</span>的<strong>次序样本观测值</strong>.<span class="math inline">\(x_{(1)},\cdots,x_{(n)}\)</span>由<span class="math inline">\(x_1,\cdots,x_n\)</span>确定,<span class="math inline">\(x_1,\cdots,x_n\)</span>的值有一定随机性,导致<span class="math inline">\(x_{(1)},\cdots,x_{(n)}\)</span>的值也有一定随机性.为此,将次序样本观测值<span class="math inline">\(x_{(1)},\cdots,x_{(n)}\)</span>看成(想象成)某<span class="math inline">\(n\)</span>个随机变量<span class="math inline">\(X_{(1)},\cdots,X_{(n)}\)</span>(其分布可能与<span class="math inline">\(X_1,\cdots,X_n)\)</span>截然不同)的观测值,如此定义的<span class="math inline">\(n\)</span>为随机变量<span class="math inline">\((X_{(1)},\cdots,X_{(n)})\)</span>被称为原始样本<span class="math inline">\(X_1,\cdots,X_n)\)</span>的<strong>次序统计量</strong>.</p><ol start="7" style="list-style-type: decimal"><li>样本中位数</li></ol><p><span class="math display">\[\tilde{X}=\begin{cases} X_(k+1) &amp; \text{if} \quad n=2k+1 \\ \frac{1}{2}(X_{(k)} + X_{(k+1)}) &amp; \text{if} \quad n=2k \end{cases}\]</span></p><ol start="8" style="list-style-type: decimal"><li>样本极差</li></ol><p><span class="math display">\[R=X_{(n)}-X_{(1)}\]</span></p><p>统计量的实质在于:统计量只依赖与样本<span class="math inline">\(X_1,\cdots,X_n\)</span>,而不涉及任何其他未知的量,即它是样本的已知函数<span class="math inline">\(g(X_1,\cdots,X_n)\)</span>,且不能含有任何未知参数.</p><h2 id="统计量的分布">统计量的分布</h2><ol style="list-style-type: decimal"><li><span class="math inline">\(\chi^2\)</span>分布</li></ol><p>设<span class="math inline">\(X_1,\cdots,X_n\)</span>相互独立且都服从<span class="math inline">\(N(0,1)\)</span>分布,它们的平方和</p><p><span class="math display">\[\chi^2 \stackrel{def} = sX_1^2+ \cdots + X_n^2\]</span></p><p>的分布称为自由度为<span class="math inline">\(n\)</span>的<span class="math inline">\(\chi^2\)</span>分布,记为<span class="math inline">\(\chi^2 \sim \chi(n)\)</span>.</p><p>其概率密度</p><p><span class="math display">\[f(y)=\begin{cases} \frac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}y^{\frac{n}{2}-1} e^{-\frac{y}{2}}, &amp; y \ge 0 \\ 0, &amp; y &lt; 0 \end{cases}\]</span></p><p>其中<span class="math inline">\(\Gamma(z)=\int_0^{\infty}u^{z-1}e^{-u}du,(z\ge 0)\)</span>.</p><p>对任意给定的正数<span class="math inline">\(\alpha(0&lt;\alpha&lt;0)\)</span>,称满足条件</p><p><span class="math display">\[\int_{\chi_\alpha^2(n)}^{\infty}f(y)dy=\alpha\]</span></p><p>的点<span class="math inline">\(\chi_\alpha^2(n)\)</span>为<span class="math inline">\(\chi^2(n)\)</span>的上<span class="math inline">\(\alpha\)</span>分位点.</p><p><span class="math inline">\(\chi_\alpha^2(n)\)</span>的概率意义是:服从<span class="math inline">\(\chi_\alpha^2(n)\)</span>分布的随机变量<span class="math inline">\(\chi^2\)</span>,取值大于<span class="math inline">\(\chi_\alpha^2(n)\)</span>的概率正好等于<span class="math inline">\(\alpha\)</span>即</p><p><span class="math display">\[P\{\chi^2 &gt; \chi_\alpha^2(n)\}=\alpha\]</span></p><p>若<span class="math inline">\(\chi_1^2 \sim \chi^2(n_1), \chi_2^2 \sim \chi^2(n_2)\)</span>,且<span class="math inline">\(\chi_1^2\)</span>与<span class="math inline">\(\chi_2^2\)</span>独立,则</p><p><span class="math display">\[\chi_1^2+\chi_2^2=\chi^2(n_1+n_2)\]</span></p><ol start="2" style="list-style-type: decimal"><li><span class="math inline">\(t\)</span>分布</li></ol><p>设<span class="math inline">\(X\sim N(0,1), Y\sim \chi^2(n)\)</span>,且<span class="math inline">\(X,Y\)</span>相互独立,则随机变量</p><p><span class="math display">\[t\stackrel{def} =  \frac{X}{\sqrt{Y/n}}\]</span></p><p>的分布称为自由度<span class="math inline">\(n\)</span>的<span class="math inline">\(t\)</span>分布,记为<span class="math inline">\(t \sim t(n)\)</span>.</p><p><span class="math inline">\(t(n)\)</span>分布的概率密度为</p><p><span class="math display">\[f(x)=\frac{\Gamma(\frac{n+1}{2})}{\sqrt{n\pi}\Gamma(\frac{n}{2})}(1+\frac{t^2}{n})^{-\frac{n+1}{2}}, \qquad -\infty &lt; t &lt; +\infty\]</span></p><p>其中<span class="math inline">\(\Gamma(z)=\int_0^{\infty}u^{z-1}e^{-u}du,(z\ge 0)\)</span>.</p><ol start="3" style="list-style-type: decimal"><li><span class="math inline">\(F\)</span>分布</li></ol><p>设<span class="math inline">\(U\sim \chi^2(n_1), V\sim \chi^2(n_2)\)</span>,且<span class="math inline">\(U,V\)</span>相互独立,则随机变量</p><p><span class="math display">\[F \stackrel{def} =  \frac{U/n_1}{V/n_2}\]</span></p><p>的分布称为自由度<span class="math inline">\((n_1,n_2)\)</span>的<span class="math inline">\(F\)</span>分布,记为<span class="math inline">\(F\sim F(n_1,n_2)\)</span>. 其中<span class="math inline">\(n_1,n_2\)</span>分别称为第一,第二自由度.</p><p><span class="math inline">\(F(n_1,n_2)\)</span>分布的概率密度为</p><p><span class="math display">\[f(y)=\begin{cases} \frac{\Gamma(\frac{n_1+n_2}{2})}{\Gamma(\frac{n_1)}{2}\Gamma(\frac{n_2)}{2}} (\frac{n_1}{n_2})(\frac{n_1}{n_2}y)^{\frac{n_1}{2}-1}(1+\frac{n_1}{n_2}y)^{-\frac{n_1+n_2}{2}}, &amp; y \ge 0 \\ 0 &amp; y &lt; 0 \end{cases}\]</span></p><p><span class="math inline">\(F(n_1,n_2)\)</span>分布的上<span class="math inline">\(\alpha\)</span>分为点定义为满足条件</p><p><span class="math display">\[\int_{F_\alpha(n_1,n_2)}^{\infty}f(y)dy=\alpha\]</span></p><p>的点<span class="math inline">\(F_\alpha(n_1,n_2)\)</span>. 并且</p><p><span class="math display">\[F_{1-\alpha}(n_2,n_2)=\frac{1}{F_\alpha(n_1,n_2)}\]</span></p><h2 id="与正态总体统计量有关的分布">与正态总体统计量有关的分布</h2><ol style="list-style-type: decimal"><li>若<span class="math inline">\(X\)</span>服从一元正态分布<span class="math inline">\(N(\mu, \sigma^2)\)</span>,则<span class="math inline">\(X\)</span>的线性函数</li></ol><p><span class="math display">\[aX+b \sim N(a\mu+b, a^2 \sigma^2)\]</span></p><p>特别</p><p><span class="math display">\[\frac{X-\mu}{\sigma} \sim N(0,1)\]</span></p><ol start="2" style="list-style-type: decimal"><li>若<span class="math inline">\(X \sim N(\mu_1, \sigma_1^2), Y \sim N(\mu_2, \sigma_2^2)\)</span>,且<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>相互独立,则</li></ol><p><span class="math display">\[X \pm Y \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)\]</span></p><ol start="3" style="list-style-type: decimal"><li>如果随机变量<span class="math inline">\(\mathbf{X}\)</span>服从均值向量为<span class="math inline">\(\mathbf{\mu}\)</span>,协方差矩阵为<span class="math inline">\(\mathbf{\Sigma}\)</span>的<span class="math inline">\(n\)</span>元正态分布<span class="math inline">\(N(\mathbf{\mu, \Sigma}),\mathbf{A}\)</span>是<span class="math inline">\(m\)</span>行<span class="math inline">\(n\)</span>列的常数矩阵,则<span class="math inline">\(m\)</span>维随机向量</li></ol><p><span class="math display">\[\mathbf{AX} \sim N(\mathbf{A\mu,A\Sigma A&#39;})\]</span></p><ol start="4" style="list-style-type: decimal"><li>显然<span class="math inline">\(\frac{X_1-\mu}{\sigma},\frac{X_2-\mu}{\sigma},\cdots,\frac{X_n-\mu}{\sigma}\)</span>独立同<span class="math inline">\(N(0,1)\)</span>分布,由<span class="math inline">\(\chi^2\)</span>分布的定义可知它们的平方和</li></ol><p><span class="math display">\[\frac{1}{\sigma^2} \sum_{i=1}^{n}(X_1-\mu)^2 \sim \chi^2(n)\]</span></p><ol start="5" style="list-style-type: decimal"><li>由独立正态变量的线性运算性质得</li></ol><p><span class="math display">\[\sum_{i=1}^nX_i \sim N(n\mu, n\sigma^2)\]</span></p><p>所以</p><p><span class="math display">\[\bar{X}=\frac{\displaystyle \sum_{i=1}^nX_i}{n} \sim N(\mu, \frac{\sigma^2}{n})\]</span></p><p>标准化得</p><p><span class="math display">\[\frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)\]</span></p><ol start="6" style="list-style-type: decimal"><li></li></ol><p><span class="math display">\[\frac{1}{\sigma^2}\sum_{i=1}{n}(X_i-\bar{X})^2 \sim \chi^2(n-1)\]</span></p><p>亦即</p><p><span class="math display">\[\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)\]</span></p><ol start="7" style="list-style-type: decimal"><li><p><span class="math inline">\(\frac{\sqrt{n}{\bar{X}-\mu}}{\sigma}\)</span>与<span class="math inline">\(\frac{n-1)S^2}{\sigma^2}\)</span>相互独立.</p></li><li></li></ol><p><span class="math display">\[\frac{\sqrt{n}(\bar{x}-\mu)}{S} = \frac{\frac{\sqrt{n}(\bar{x}-\mu)}{\sigma}}{\sqrt{\frac{(n-1)S^2}{(n-1)\sigma^2}}} \sim t(n-1)\]</span></p><ol start="9" style="list-style-type: decimal"><li></li></ol><p><span class="math display">\[\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} \sim N(0,1)\]</span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;总体与样本&quot;&gt;总体与样本&lt;/h1&gt;
&lt;h2 id=&quot;总体-个体-样本&quot;&gt;总体 个体 样本&lt;/h2&gt;
&lt;p&gt;一般将研究对象的全体组成的集合成为&lt;strong&gt;总体&lt;/strong&gt;,组成总体的每一个成员成为&lt;strong&gt;个体&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;从总
      
    
    </summary>
    
      <category term="数学" scheme="https://mejhwu.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>概率论总结</title>
    <link href="https://mejhwu.github.io/2018/04/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%80%BB%E7%BB%93/"/>
    <id>https://mejhwu.github.io/2018/04/19/概率论总结/</id>
    <published>2018-04-18T16:00:00.000Z</published>
    <updated>2018-06-27T12:58:09.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念">基本概念</h1><h2 id="古典概型">古典概型</h2><h3 id="古典改型的特点">古典改型的特点:</h3><ol style="list-style-type: decimal"><li>试验的样本空间中的元素个数只有有限个,不妨设为n个,记为<span class="math inline">\(e_1,e_2,...,e_n\)</span>;</li><li>每个基本事件<span class="math inline">\(\{e\}\)</span>出现的可能性相等,即有</li></ol><p><span class="math display">\[P(\{e_1\})=P(\{e_2\})=...=P(\{e_n\})\]</span></p><h3 id="古典概型类型">古典概型类型</h3><h4 id="随机取数问题">随机取数问题</h4><ol style="list-style-type: decimal"><li><p>有放回地随机取数: 若从<span class="math inline">\(n\)</span>个相异的数字中有放回地取<span class="math inline">\(m\)</span>个, 则试验样本空间的基本事件总数可按<span class="math inline">\(n\)</span>个不同数字中取<span class="math inline">\(m\)</span>个的重复排列计算,由乘法原理知为<span class="math inline">\(n*n*... *n=n^m\)</span></p></li><li><p>无放回地随机取数: 若取出的数不还原,则从n个不同的数中任取<span class="math inline">\(m\)</span>个试验样本空间所含基本事件总数要根据取数是计序或不计序,按不重复的排列或组合公式计算,即基本事件总数为:</p></li></ol><ol style="list-style-type: lower-alpha"><li><p>计序时为<span class="math inline">\(A_n^m=n(n-1)...(n-m+1)\)</span></p></li><li><p>不计序时为<span class="math inline">\(C_n^m= \left( \begin{matrix} n \\ m \end{matrix} \right)=\frac{n!}{m!(n-m)!}\)</span></p></li></ol><h4 id="抽球问题">抽球问题</h4><p>从<span class="math inline">\(n\)</span>个球中抽取<span class="math inline">\(m\)</span>个:</p><p>(1)有放回</p><p>(a)计序: <span class="math inline">\(n^m\)</span></p><p>(b)不计序: <span class="math inline">\(C_{n+m-1}^m\)</span>, 相当于在<span class="math inline">\(n+m-1\)</span>个球中无放回抽取<span class="math inline">\(m\)</span>个球</p><p>(2)无放回</p><p>(a)计序: <span class="math inline">\(A_n^m\)</span></p><p>(b)不计序: <span class="math inline">\(C_n^m\)</span></p><h4 id="分房问题">分房问题</h4><p>设有<span class="math inline">\(n\)</span>个人,每个人都等可能的被分配到<span class="math inline">\(N\)</span>个房间中的任意一间中去住<span class="math inline">\((n\le N)\)</span>, 且每个房间可容纳的人数不限.</p><h4 id="配对问题">配对问题</h4><h2 id="几何概型">几何概型</h2><ol style="list-style-type: decimal"><li><p>每次试验的可能有无限多个,且全部可能结果的集合可用一个有度量(如长,面积,体积等)的几何区域来表示.</p></li><li><p>每次试验中每个可能的出现是等可能的.</p></li></ol><h2 id="条件概率">条件概率</h2><p>设<span class="math inline">\(A, B\)</span>为两事件,且<span class="math inline">\(P(A) \gt 0\)</span>, 称</p><p><span class="math display">\[P(B|A)=\frac{P(AB)}{P(A)}\]</span></p><p>为在事件<span class="math inline">\(A\)</span>发生条件下事件<span class="math inline">\(B\)</span>发生的概率.</p><p>全概率公式</p><p>设试验<span class="math inline">\(E\)</span>的样本空间<span class="math inline">\(S\)</span>, <span class="math inline">\(A\)</span>为<span class="math inline">\(E\)</span>的事件, <span class="math inline">\(B_1,B_2,...,B_n\)</span>为<span class="math inline">\(S\)</span>的一个划分,且<span class="math inline">\(P(B_i)\gt 0(i=1,2,...,n)\)</span>, 则</p><p><span class="math display">\[P(A)=P(B_1)P(A|B_1)+P(B_2)P(A|B_2)+...+P(B_n)P(A|B_n)\]</span></p><p>贝叶斯公式</p><p>设试验<span class="math inline">\(E\)</span>的样本空间<span class="math inline">\(S\)</span>, <span class="math inline">\(A\)</span>为<span class="math inline">\(E\)</span>的事件, <span class="math inline">\(B_1,B_2,...,B_n\)</span>为<span class="math inline">\(S\)</span>的一个划分,且<span class="math inline">\(P(A)&gt;0, P(B_i)\gt 0(i=1,2,...,n)\)</span>, 则</p><p><span class="math display">\[P(B_i|A)=\frac{P(B_i)P(A|B_i)}{\sum_{j=1}^nP(B_j)P(A|B_js)}\]</span></p><h2 id="事件独立">事件独立</h2><p>设<span class="math inline">\(A\)</span>,<span class="math inline">\(B\)</span>是两事件,如果具有等式</p><p><span class="math display">\[P(AB)=P(A)P(B)\]</span></p><p>则称<span class="math inline">\(A\)</span>,<span class="math inline">\(B\)</span>为相互独立事件.</p><h1 id="随机变量">随机变量</h1><h2 id="概念">概念</h2><p>设<span class="math inline">\(E\)</span>是随机试验, 其样本空间<span class="math inline">\(S=\{e\}\)</span>. 如果对应每一个<span class="math inline">\(e \in S\)</span>, 均有一个实数<span class="math inline">\(X(e)\)</span>与之对应, 这样一个定义在样本空间<span class="math inline">\(S\)</span>上的单值实数<span class="math inline">\(X=X(e)\)</span>, 称为随机变量.</p><p>设<span class="math inline">\(X\)</span>是一个随机变量, <span class="math inline">\(x\)</span>是任意实数, 函数</p><p><span class="math display">\[F(s)=P\{X \le x\}\]</span></p><p>称为<span class="math inline">\(X\)</span>的分布函数.</p><p>分布函数的基本性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(F(x)\)</span>是一个不减函数.</p></li><li><p><span class="math inline">\(0 \le F(x) \le 1\)</span> 且 <span class="math inline">\(F(-\infty)= \lim_{x \rightarrow -\infty}F(x) = 0 \quad F(+\infty)= \lim_{x \rightarrow +\infty}F(x) = 1\)</span></p></li></ol><h2 id="离散型随机变量">离散型随机变量</h2><p>若随机变量<span class="math inline">\(X\)</span>的可能取值仅有有限个或可列多个,则称此随机变量为离散型随机变量.</p><h3 id="常见分布">常见分布</h3><h4 id="单点分布">单点分布</h4><p>设随机变量<span class="math inline">\(X\)</span>取一个常数值<span class="math inline">\(C\)</span>的概率为1, 即<span class="math inline">\(P\{X=C\}=1\)</span>, 则称<span class="math inline">\(X\)</span>服从单点分布或退化分布.</p><h4 id="分布两点分布">(0-1)分布(两点分布)</h4><p>设随机变量<span class="math inline">\(X\)</span>只可能取0和1两个值,它的分布律是</p><p><span class="math display">\[P\{X=k\}=p^k(1-p)^{1-k} \qquad k=0,1; 0 &lt; p &lt; 1\]</span></p><p>则称<span class="math inline">\(X\)</span>服从(0-1)分布.</p><h4 id="等可能分布离散型均匀分布">等可能分布(离散型均匀分布)</h4><p>如果随机变量<span class="math inline">\(X\)</span>可以取<span class="math inline">\(n\)</span>个不同的值<span class="math inline">\(x_1&lt;x_2&lt;...&lt;x_n\)</span>, 且取每个<span class="math inline">\(x_k\)</span>值的概率相等, 即</p><p><span class="math display">\[P\{X=x_k\}=\frac {1}{n}\]</span></p><p>则称<span class="math inline">\(X\)</span>服从等可能或称离散型均匀分布.</p><h4 id="二项分布">二项分布</h4><p>如果随机变量<span class="math inline">\(X\)</span>取值为<span class="math inline">\(0,1,2,...,n\)</span>的概率为</p><p><span class="math display">\[P\{X=k\}= \left( \begin{matrix}  n \\ k \end{matrix} \right) p^k (1-p)^{n-k}\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(n,p\)</span>的二项分布, 记为<span class="math inline">\(X \sim B(n,p)\)</span></p><p>设试验<span class="math inline">\(E\)</span>的可能结果只有两个,即<span class="math inline">\(A\)</span>或<span class="math inline">\(\bar{A}\)</span>, 且<span class="math inline">\(P(A)=p, P(\bar{A})=1-p=q(0&lt;p&lt;1)\)</span>, 若将此试验<span class="math inline">\(E\)</span>独立地重复<span class="math inline">\(n\)</span>次,则称这一串重复的独立试验为<span class="math inline">\(n\)</span>重贝努力(Bernoulli)试验,或称<span class="math inline">\(n\)</span>重贝努力概型.</p><h4 id="泊松分布">泊松分布</h4><p>如果随机变量X的可能取值为<span class="math inline">\(0,1,2,...\)</span>取各值的概率为</p><p><span class="math display">\[P\{X=k\}=\frac{\lambda ^k e^{-\lambda}}{k!}\]</span></p><p>其中<span class="math inline">\(\lambda&gt;0\)</span>为常数,则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\lambda\)</span>的泊松分布,记为<span class="math inline">\(X \sim P(\lambda)\)</span>.</p><p>泊松逼近定理</p><p>设<span class="math inline">\(\lambda &gt; 0\)</span>是一常数, <span class="math inline">\(n\)</span>是任意正整数, 设<span class="math inline">\(np_n=\lambda\)</span>, 则对于任一固定的非负整数<span class="math inline">\(k\)</span>, 有</p><p><span class="math display">\[\lim_{n\rightarrow \infty} \left( \begin{matrix}n \\ p \end{matrix} \right) (1-p_n)^{n-k} = \frac{\lambda ^k e^{-\lambda}}{k!}\]</span></p><h4 id="几何分布">几何分布</h4><p>如果随机变量<span class="math inline">\(X\)</span>可能取值为<span class="math inline">\(1,2,..\)</span>的概率为</p><p><span class="math display">\[P\{X=k\}=pq^{k-1} \qquad k=1,2,..., \quad 0 &lt; p &lt; 1, \quad q=1-p\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p\)</span>的几何分布,记为<span class="math inline">\(X \sim Ge(p)\)</span>.</p><p>几何分布的数学描述:</p><p>若进行一系列重复的独立试验,每次试验中某事件<span class="math inline">\(A\)</span>发生的概率为<span class="math inline">\(p\)</span>,即<span class="math inline">\(p=P(A)\)</span>, 令<span class="math inline">\(X\)</span>表示事件<span class="math inline">\(A\)</span>首次发送时试验的总次数,则此<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p\)</span>的几何分布.</p><h4 id="帕斯卡分布负二项分布">帕斯卡分布(负二项分布)</h4><p>如果随机变量<span class="math inline">\(X\)</span>的概率分布为</p><p><span class="math display">\[P\{X=k\}=\left( \begin{matrix} k-1 \\ r-1 \end{matrix} \right) p^r q^{k-r} \]</span></p><p><span class="math display">\[k=r,r+1,r+2,...,r \ge 1, \quad 0 &lt; p &lt; 1, \quad q = 1-p\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p,r\)</span>的帕斯卡分布或负二项分布.</p><p>帕斯卡分布的数学描述;</p><p>若进行一系列重复的独立试验, 每次试验中某事件<span class="math inline">\(A\)</span>发生的概率为<span class="math inline">\(p\)</span>发生的概率为<span class="math inline">\(p\)</span>, 即<span class="math inline">\(p=P(A)\)</span>. 令<span class="math inline">\(X\)</span>表示在事件<span class="math inline">\(A\)</span>恰发生<span class="math inline">\(r\)</span>次时试验的总次数,则此<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p,r\)</span>的帕斯卡分布.</p><h4 id="超几何分布">超几何分布</h4><p>如果随机变量<span class="math inline">\(X\)</span>的概率分布为</p><p><span class="math display">\[P\{X=k\}=\frac{\left( \begin{matrix} M \\ k \end{matrix} \right) \left( \begin{matrix} N-M \\ n-k \end{matrix} \right) }{\left( \begin{matrix} N \\ n \end{matrix} \right)}\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(n,M,N\)</span>的超几何分布.</p><p>超几何分布的数学描述:</p><p>设一代中总有<span class="math inline">\(N\)</span>个产品,其中有<span class="math inline">\(M\)</span>个次品,现从中任取<span class="math inline">\(n\)</span>个产品,令<span class="math inline">\(X\)</span>为<span class="math inline">\(n\)</span>个产品中的次品的个数,则此<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(n,M,N\)</span>的超几何分布.</p><p>定理:</p><p>设<span class="math inline">\(p(0&lt;p&lt;1)\)</span>为一常数,当<span class="math inline">\(N \rightarrow \infty\)</span>时, <span class="math inline">\(\lim \frac{M}{N} = p\)</span>, 则对固定的非负整数<span class="math inline">\(n(n\le M)\)</span>, 任一固定的非负整数<span class="math inline">\(k=0,1,2,...,n\)</span> 有</p><p><span class="math display">\[\lim_{N \rightarrow \infty} \frac {\left( \begin{matrix} M \\ k \end{matrix} \right) \left( \begin{matrix} N-M \\ n-k \end{matrix} \right)}{\left( \begin{matrix} N \\ n \end{matrix} \right)} = \left( \begin{matrix} n \\ k \end{matrix} \right)p^k(1-p)^{n-k}\]</span></p><h2 id="连续型随机变量">连续型随机变量</h2><h3 id="概念-1">概念</h3><p>如果对于随机变量<span class="math inline">\(X\)</span>的分布函数<span class="math inline">\(F(x)\)</span>, 存在非负函数<span class="math inline">\(f(x)\)</span>, 使对于任意实数<span class="math inline">\(x\)</span>均有</p><p><span class="math display">\[F(x)=\int^x_{-\infty} f(t)dt \]</span></p><p>则称<span class="math inline">\(X\)</span>为连续型随机变量, 其中函数<span class="math inline">\(f(x)\)</span>称为<span class="math inline">\(X\)</span>的概率密度函数,简称概率密度.</p><p>概率密度<span class="math inline">\(f(x)\)</span>具有以下性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(f(x) \ge 0\)</span></p></li><li><p><span class="math inline">\(\int_{- \infty}^{+ \infty}f(x)dx=1\)</span></p></li><li><p><span class="math inline">\(P\{x_1 &lt; X \le x_2\} = F(x_2) - F(x_1) = \int_{x_1}^{x_2}dx \qquad (x_1 \le x_2\)</span>)</p></li><li><p>若<span class="math inline">\(f(x)\)</span>在点<span class="math inline">\(x\)</span>处连续, 则有<span class="math inline">\(F^{&#39;}(x) = f(x)\)</span></p></li></ol><p>对于连续型随机变量<span class="math inline">\(X\)</span>来说,<span class="math inline">\(X\)</span>取任一固定值<span class="math inline">\(a\)</span>的概率为0, 故连续型随机变量概率与区间开闭无关:</p><p><span class="math display">\[P\{a \le x \le b\} = P\{a \le x &lt; b\} = P\{a &lt; x \le b\} = P\{a &lt; x &lt; b\}\]</span></p><h3 id="连续型随机变量的分布">连续型随机变量的分布</h3><h4 id="均匀分布">均匀分布</h4><p>若随机变量<span class="math inline">\(X\)</span>具有概率密度</p><p><span class="math display">\[f(x)=\begin{cases} &amp; \frac{1}{b-a} \quad &amp; a &lt; x &lt; b \\ &amp; 1 \quad &amp; x \ge b, x \le a \end{cases}\]</span></p><p>s则称<span class="math inline">\(X\)</span>服从<span class="math inline">\((a,b)\)</span>上的均匀分布, 记作<span class="math inline">\(X \sim U(a,b)\)</span>. 当参数<span class="math inline">\(a=0, b=1\)</span>时, <span class="math inline">\(U(a,b)\)</span>成为标准分布.</p><p>容易得到<span class="math inline">\(X\)</span>的分布函数为</p><p><span class="math display">\[f(x)=\begin{cases} 0 &amp; x&lt;a \\ \frac{x-a}{b-a} &amp; a \le x &lt; b \\ 1 &amp; x \ge b \end{cases}\]</span></p><h4 id="指数分布">指数分布</h4><p>若随机变量<span class="math inline">\(X\)</span>具有概率密度</p><p><span class="math display">\[f(x)=\begin{cases} \alpha e^{-\alpha x} &amp; x&gt;0 \\ 0 &amp; x \le 0 \end{cases}\]</span></p><p>其中参数<span class="math inline">\(\alpha &gt; 0\)</span>, 则称随机变量<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\alpha\)</span>的指数分布, 记为<span class="math inline">\(X \sim Z(\alpha)\)</span>.</p><p>其分布函数为</p><p><span class="math display">\[F(x)=\begin{cases} 1-e^{-\alpha x} &amp; x &gt; 0 \\ 0 &amp; x \le 0 \end{cases}\]</span></p><h4 id="正态分布">正态分布</h4><p>若随机变量<span class="math inline">\(X\)</span>具有概率密度</p><p><span class="math display">\[f(x)=\frac{1}{\sqrt{2 \pi \sigma}} e^{-\frac{(x-\mu)^2}{2 \sigma^2}}\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\sigma^2(\sigma &gt; 0)\)</span>的正态分布,记作<span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, 此时称<span class="math inline">\(X\)</span>为正态变量.</p><p><span class="math inline">\(X\)</span>的分布函数为</p><p><span class="math display">\[F(x)=\int _{-\infty}^x \frac{1}{\sqrt{2 \pi \sigma}} e^{-\frac{(t-\mu)^2}{2 \sigma^2}} dt \qquad -\infty &lt; x &lt; +\infty\]</span></p><p>当<span class="math inline">\(\mu =0, \sigma = 1\)</span>时, <span class="math inline">\(X \sim N(0,1)\)</span>, 称<span class="math inline">\(X\)</span>服从标准正态分布,称<span class="math inline">\(X\)</span>为标准正态变量. 它的概率密度和分布函数分布标记为</p><p><span class="math display">\[\varphi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \qquad -\infty&lt;x&lt;+\infty \]</span></p><p><span class="math display">\[\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}dt \qquad -\infty&lt;x&lt;+\infty \]</span></p><p>若<span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, 其分布函数为<span class="math inline">\(F(x)\)</span>, 则标准化变量</p><p><span class="math display">\[Z=\frac{X-\mu}{\sigma} \sim N(0,1)\]</span></p><p>且</p><p><span class="math display">\[F(x)=\Phi(\frac{x-\mu}{\sigma})\]</span></p><p>设随机变量<span class="math inline">\(X\)</span>的分布函数<span class="math inline">\(F(x)\)</span>,对于任一正数<span class="math inline">\(\alpha(0&lt;\alpha&lt;1)\)</span>, 若<span class="math inline">\(X\)</span>大于等于某实数<span class="math inline">\(z_\alpha\)</span>, 即</p><p><span class="math display">\[1-F(z_\alpha)=P\{X \ge z_\alpha\} = \alpha \qquad 0 &lt; \alpha &lt; 1\]</span></p><p>则称此实数<span class="math inline">\(z_\alpha\)</span>为分布<span class="math inline">\(F(x)\)</span>的上<span class="math inline">\(\alpha\)</span>分为点.</p><h2 id="随机变量的函数的分布">随机变量的函数的分布</h2><h3 id="离散型随机变量的函数的分布">离散型随机变量的函数的分布</h3><p>离散型随机变量的函数<span class="math inline">\(Y=g(X)\)</span>仍是离散型随机变量.计算离散型随机变量的函数的分布律,首先找出它的一切可能值,然后计算它取各个值的概率.</p><h3 id="连续型随机变量的函数的分布">连续型随机变量的函数的分布</h3><p>如果<span class="math inline">\(X\)</span>是连续型随机变量,函数<span class="math inline">\(g(x)\)</span>是连续函数,这时<span class="math inline">\(Y=g(X)\)</span>也是一个连续型随机变量.</p><p>设连续型随机变量<span class="math inline">\(X\)</span>的概率密度为<span class="math inline">\(f_X(s)\)</span>, 当<span class="math inline">\(a&lt;x&lt;b\)</span>时, <span class="math inline">\(f_X(x)&gt;0;y=g(x)\)</span>处处可导, 且恒有<span class="math inline">\(g&#39;(x)&gt;0\)</span>(或<span class="math inline">\(g&#39;(x)&lt;0\)</span>),则随机变量<span class="math inline">\(X\)</span>的函数<span class="math inline">\(Y=g(X)\)</span>的概率密度为</p><p><span class="math display">\[f_Y(y)=\begin{cases} f_X(h(y))|h&#39;(y)| &amp; c&lt;y&lt;d \\ 0 &amp; y\ge d, y &lt; c \end{cases}\]</span></p><p>其中<span class="math inline">\(x=h(y)\)</span>为<span class="math inline">\(y=g(x)\)</span>的反函数, <span class="math inline">\(c=min\{g(a), g(b)\}, d=max\{g(a),g(b)\}\)</span></p><p>设随机变量<span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, <span class="math inline">\(X\)</span>的线性函数<span class="math inline">\(Y=aX+b(a\neq 0)\)</span>也服从正态分布.</p><h1 id="多维随机变量">多维随机变量</h1><h2 id="二维随机变量">二维随机变量</h2><p>设<span class="math inline">\(E\)</span>为一个随机试验,它的样本空间为<span class="math inline">\(S=\{e\}\)</span>, 并设<span class="math inline">\(X=X(e)\)</span>和<span class="math inline">\(Y=Y(e)\)</span>是定义在<span class="math inline">\(S\)</span>上的随机变量,由它们两个构成的联合变量<span class="math inline">\((X,Y)\)</span>,称为二维随机变量或二维随机向量.</p><p>设<span class="math inline">\((X,Y)\)</span>是定义在样本空间<span class="math inline">\(S=\{e\}\)</span>上的二维随机变量, 对于任意实数<span class="math inline">\(x,y\)</span>, 二元函数</p><p><span class="math display">\[F(x,y)=P\{(X\le x) \cap (Y\le y)\} \triangleq P\{X\le x, Y\le y\}\]</span></p><p>称为二维随机变量<span class="math inline">\((X,Y)\)</span>的分布函数, 或称为随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的联合分布函数.</p><p>二维随机变量的分布函数的性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(F(x,y)\)</span>是变量<span class="math inline">\(x\)</span>和<span class="math inline">\(y\)</span>的不减函数.</p></li><li><p><span class="math inline">\(0 \le F(x,y) \le 1\)</span>, 且对于任意固定的<span class="math inline">\(y, F(-\infty,y)=0\)</span>;对于固定的<span class="math inline">\(x\)</span>,有<span class="math inline">\(F(x,-\infty)=0\)</span>; 且<span class="math inline">\(F(-\infty, +\infty)=0;F(+\infty,-\infty)=1\)</span>.</p></li><li><p><span class="math inline">\(F(x,y)=F(x+0,y)=F(x, y+0)\)</span>, 即<span class="math inline">\(F(x,y)\)</span>关于<span class="math inline">\(x\)</span>右连续,关于<span class="math inline">\(y\)</span>右连续.</p></li><li><p>对于任意的<span class="math inline">\(x_1&lt;x_2, y_1&lt;y_2\)</span>, 下述不等式成立</p></li></ol><p><span class="math display">\[F(x_2,y_2)-F(x_2,y_1)-F(x_1,y_2)-F(x_1,y_1) \ge 0\]</span></p><p><span class="math inline">\(X,Y\)</span>的边缘分布函数<span class="math inline">\(F_X(x),F_Y(y)\)</span>:</p><p><span class="math display">\[F_X(x)=P\{X \le x\} = P\{X \le x, Y &lt; +\infty\}=F(x,+\infty)\]</span></p><p><span class="math display">\[F_Y(y)=P\{Y \le y\} = P\{X &lt; +\infty, Y \le y\}=F(+\infty, y)\]</span></p><h3 id="二维离散型随机变量">二维离散型随机变量</h3><p>如果二维随机变量<span class="math inline">\((X,Y)\)</span>的所有可能取的值是有限对或可列多对,则称<span class="math inline">\((X,Y)\)</span>是二维离散想随机变量.</p><p>设二维离散型随机变量<span class="math inline">\((X,Y)\)</span>所有可能取的值为<span class="math inline">\((x_i,y_j)(i,j=1,2,...)\)</span>, 其概率记为<span class="math inline">\(P\{X=x_i,Y=y_j\} = p_{ij}(i,j=1,2,...)\)</span>,则由概率的定义有</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(p_{ij} \ge 0\)</span></p></li><li><p><span class="math inline">\(\sum_{i=1}^\infty \sum_{j=1}^\infty p_{ij} = 1\)</span></p></li></ol><p><span class="math inline">\((X,Y)\)</span>的分布函数为</p><p><span class="math display">\[F(x,y)=P\{X \le x, Y\le y\}=\sum_{x_i\le x}\sum_{y_j\le y}P\{X=x_i, Y=y_j\}=\sum_{x_i\le x}\sum_{y_j\le y}p_{ij}\]</span></p><p><span class="math inline">\(X\)</span>的分布律:</p><p><span class="math display">\[P\{X=x_i\}=\sum_{j=1}^\infty p_{ij} \triangleq p_{i\cdot} \qquad i=1,2,...\]</span></p><p><span class="math inline">\(Y\)</span>的分布律:</p><p><span class="math display">\[P\{Y=y_j\}=\sum_{i=1}^\infty p_{ij} \triangleq p_{\cdot i} \qquad j=1,2,...\]</span></p><h3 id="二维连续型随机变量">二维连续型随机变量</h3><p>如果二维随机变量<span class="math inline">\((X,Y)\)</span>的分布函数<span class="math inline">\(F(x,y)\)</span>, 存在一个非负可积的二元函数<span class="math inline">\(f(x,y)\)</span>,使它对应任意实数<span class="math inline">\(x,y\)</span>, 都有</p><p><span class="math display">\[F(x,y)=\int_{-\infty}^x \int_{-\infty}^y f(s,t)dsdt\]</span></p><p>则称<span class="math inline">\((X,Y)\)</span>是二维连续型随机变量,函数<span class="math inline">\(f(x,y)\)</span>称为二维随机变量<span class="math inline">\((X,Y)\)</span>的概率密度,或称为随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的联合概率密度.</p><p>概率密度<span class="math inline">\(f(x,y)\)</span>具有以下性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(f(x,y) \ge 0\)</span></p></li><li><p><span class="math inline">\(\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f(x,y)dxdy = 1\)</span></p></li><li><p>若<span class="math inline">\(f(x,y)\)</span>在点<span class="math inline">\((x,y)\)</span>连续, 则有</p></li></ol><p><span class="math display">\[\frac{\partial^2 F(x,y)}{\partial x \partial y}=f(x,y)\]</span></p><ol start="4" style="list-style-type: decimal"><li>随机点<span class="math inline">\((X,Y)\)</span>落在平面区域<span class="math inline">\(D\)</span>上的概率为</li></ol><p><span class="math display">\[P\{(X,Y) \in D\}=\int \int_D f(x,y) dxdy\]</span></p><p><span class="math inline">\(X\)</span>为连续型变量,其概率密度为</p><p><span class="math display">\[f_X(x)=\int_{-\infty}^{+\infty}f(x,y)dy\]</span></p><p><span class="math inline">\(Y\)</span>为连续型变量,其概率密度为</p><p><span class="math display">\[f_Y(y)=\int_{-\infty}^{+\infty}f(x,y)dx\]</span></p><p><span class="math inline">\(X,Y\)</span>的联合分布可以确定<span class="math inline">\(X,Y\)</span>的边缘分布函数, 反过来,有<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的边缘分布,一般不能确定<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的联合分布.</p><h2 id="条件分布">条件分布</h2><h3 id="条件分布律">条件分布律</h3><p>设<span class="math inline">\((X,Y)\)</span>是离散型随机变量, 可能取值为<span class="math inline">\((x_i,y_j)(i,j=1,2,...)\)</span>, 其分布律及边缘分布律分别为<span class="math inline">\(P\{X=x_i,Y=y_j\}=p_{ij}, P\{X=x_i\}=p_{i\cdot}, P\{Y=y_j\}=p_{\cdot j}\)</span>.</p><p>若对于固定的<span class="math inline">\(i, P\{X=x_i\} &gt; 0\)</span>,则称</p><p><span class="math display">\[P\{Y=y_j|X=x_i\}=\frac{P\{X=x_i,Y=y_j\}}{P\{X=x_i\}}=\frac{p_{ij}}{p_{i\cdot}} \triangleq p_{j|i}\]</span></p><p>为在<span class="math inline">\(X=x_i\)</span>条件下<span class="math inline">\(Y\)</span>的条件分布律.</p><p>若对于固定的<span class="math inline">\(j, P\{Y=y_j\}&gt;0\)</span>,则称</p><p><span class="math display">\[P\{X=x_i|Y=y_j\}=\frac{P\{X=x_i,Y=y_j\}}{P\{Y=y_j\}}=\frac{p_{ij}}{p_{\cdot j}} \triangleq p_{i|j}\]</span></p><p>为在<span class="math inline">\(Y=y_j\)</span>条件下<span class="math inline">\(X\)</span>的条件分布律.</p><h3 id="条件分布函数与条件概率密度">条件分布函数与条件概率密度</h3><p>由离散型分布函数定义可得条件分布函数为</p><p><span class="math display">\[F_{Y|X}(y|x_i)=P\{Y \le y | X=x_i\}=\sum_{y_j\le y} p_{j|i}\]</span></p><p><span class="math display">\[F_{X|Y}(x|y_j)=P\{X \le x | Y=y_j\}=\sum_{x_i\le x} p_{i|j}\]</span></p><p>给定<span class="math inline">\(y\)</span>, 设对于任意固定的正数<span class="math inline">\(\varepsilon, P\{y-\varepsilon &lt; Y \le y+\varepsilon \} &gt; 0\)</span>, 且若对于任意实数<span class="math inline">\(x\)</span>,极限</p><p><span class="math display">\[\lim_{\varepsilon \rightarrow 0^+} P\{X \le x | y-\varepsilon &lt; Y \le y+\varepsilon \} = \lim_{\varepsilon \rightarrow 0^+} \frac{P\{X \le x , y-\varepsilon &lt; Y \le y+\varepsilon \}}{P\{y-\varepsilon &lt; Y \le y+\varepsilon \}}\]</span></p><p>存在,则称此极限在条件<span class="math inline">\(Y=y\)</span>下<span class="math inline">\(X\)</span>的条件分布函数,记为<span class="math inline">\(P\{X \le x | Y=y\}\)</span>, 或记为<span class="math inline">\(F_{X|Y}(x|y)\)</span>.s</p><p>设<span class="math inline">\((X,Y)\)</span>的分布函数为<span class="math inline">\(F(x,y)\)</span>,概率密度为<span class="math inline">\(f(x,y)\)</span>, 若在点<span class="math inline">\((x,y)\)</span>处<span class="math inline">\(f(x,y)\)</span>连续,边缘概率密度<span class="math inline">\(f_Y(y)\)</span>连续,且<span class="math inline">\(f_Y(y) &gt; 0\)</span>,则有</p><p><span class="math display">\[F_{X|Y}(x|y)=\int_{-\infty}^x \frac{f(u,y)}{f_Y(y)} du\]</span></p><p><span class="math display">\[f_{X|Y}(x|y)=\frac{f(x,y)}{f_Y(y)}\]</span></p><p>同理</p><p><span class="math display">\[F_{Y|X}(y|x)=\int_{-\infty}^y \frac{f(x,v)}{f_X(x)} dv\]</span></p><p><span class="math display">\[f_{Y|X}(y|x)=\frac{f(x,y)}{f_X(x)}\]</span></p><h2 id="相互独立的随机变量">相互独立的随机变量</h2><p>设<span class="math inline">\(F(x,y)\)</span>及<span class="math inline">\(F_X(x),F_Y(y)\)</span>分别是二维随机变量<span class="math inline">\((X,Y)\)</span>的分布函数及边缘分布函数,若对于所有<span class="math inline">\(x,y\)</span>有</p><p><span class="math display">\[P\{X\le x, Y\le y\}=P\{X\le x\}P\{Y\le y\}\]</span></p><p>即<span class="math inline">\(F(x,y)=F_X(x)F_Y(y)\)</span>, 则称随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>是相互独立的.</p><h3 id="离散型随机变量-1">离散型随机变量</h3><p>离散型随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>相互独立的充要条件是它们的联合分布函数等于两个边缘分布绿的乘积,即</p><p><span class="math display">\[P\{X=x_i,Y=y_j\}=P\{X=x_i\}P\{Y=y_j\}\]</span> 即<span class="math inline">\(p_{ij}=p_{i\cdot} \cdot p_{\cdot j}\)</span></p><h3 id="连续型随机变量-1">连续型随机变量</h3><p>连续型随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>相互独立的充要条件是它们的联合概率密度<span class="math inline">\(f(x,y)\)</span>等于边缘概率密度<span class="math inline">\(f_X(x)\)</span>和<span class="math inline">\(f_Y(y)\)</span>的乘积,即</p><p><span class="math display">\[f(x,y)=f_X(x)f_Y(y)\]</span></p><h2 id="两个随机变量的函数的分布">两个随机变量的函数的分布</h2><h3 id="两个离散型随机变量的函数的分布">两个离散型随机变量的函数的分布</h3><p><span class="math inline">\(Z=g(X,Y)\)</span>的概率分布的一般求法</p><p>设<span class="math inline">\((X,Y)\)</span>为离散型随机变量,其概率分布为</p><p><span class="math display">\[P\{X=x_i,Y=y_j\} = p_{ij} \qquad i,j=1,2,...\]</span></p><p>则<span class="math inline">\(Z=g(X,Y)\)</span>的概率分布的一般求法是:先确定函数<span class="math inline">\(Z=g(X,Y)\)</span>的全部可能取值<span class="math inline">\(z=g(x_i,y_j)(i,j=1,2,...)\)</span>;再确定相应概率</p><p><span class="math display">\[P\{Z=g(x_i,y_j)\}=P\{X=x_i,Y=y_j\}=p_{ij}\]</span></p><p>然后将<span class="math inline">\(z=g(x_i,y_j)(i,j=1,2,...)\)</span>中相同的值合并,相应的概率相加,并将<span class="math inline">\(z\)</span>值按从小到大的顺序重新排列,且与其概率对应,即可写出<span class="math inline">\(Z=g(X,Y)\)</span>的概率分布.</p><p>两个离散型随机变量的和的概率公式</p><p><span class="math display">\[P\{Z=k\}=\sum_{i=0}^k P\{X=i\}P\{Y=k-i\}=\sum_{j=0}^k P\{Y=j\}P\{X=k-j\}\]</span></p><h3 id="两个连续型随机变量的函数的分布">两个连续型随机变量的函数的分布</h3><h4 id="随机变量的和的分布">随机变量的和的分布</h4><p><span class="math display">\[f_Z(z)=\int_{-\infty}^{+\infty}f(z-y,y)dy\]</span></p><p>或</p><p><span class="math display">\[f_Z(z)=\int_{-\infty}^{+\infty}f(x,z-x)dx\]</span></p><h4 id="随机变量的商的分布">随机变量的商的分布</h4><p><span class="math display">\[f_Z(z)=\int_{-\infty}^{+\infty}|y|f(yz,y)dy\]</span></p><h4 id="随机变量的极值的分布">随机变量的极值的分布</h4><p>设<span class="math inline">\(X,Y\)</span>是两个相互独立的随机事件,称<span class="math inline">\(M=max(X,Y)\)</span>为最大值变量, <span class="math inline">\(N=min(X,Y)\)</span>为最小值变量, 统称为极值变量.</p><p><span class="math display">\[F_{max}(z)=P\{M \le z\}=P\{X\le z\}P\{Y\le z\}=F_X(z)F_Y(z)\]</span></p><p><span class="math display">\[\begin{aligned} F_{min}(z) &amp;=P\{N\le z\} \\ &amp;=1-P\{N&gt;z\} \\ &amp;=1-P\{Y&gt;z,X&gt;z\} \\ &amp;=1-P\{X&gt;z\}P\{Y&gt;z\} \\ &amp;=1-[1-F_X(z)][1-F_Y(z)] \end{aligned} \]</span></p><h2 id="nnge-2维随机变量"><span class="math inline">\(n(N\ge 2)\)</span>维随机变量</h2><h3 id="nnge-2维随机变量及其分布"><span class="math inline">\(n(N\ge 2)\)</span>维随机变量及其分布</h3><p>设<span class="math inline">\(E\)</span>是一个随机变量,其样本空间为<span class="math inline">\(S=\{e\}\)</span>, 设<span class="math inline">\(X_i=X_i(e),(i=1,2,...,n)\)</span>是定义在<span class="math inline">\(S\)</span>上的<span class="math inline">\(n\)</span>个随机变量,由它们构成的一个向量</p><p><span class="math display">\[(X_1,X_2,...,X_n)=(X_1(e),X_2(e),...X_n(e)) \qquad e \in S\]</span></p><p>称为<span class="math inline">\(n\)</span>维随机向量或<span class="math inline">\(n\)</span>维随机变量.</p><p>设<span class="math inline">\((X_1,X_2,...,X_n)\)</span>是<span class="math inline">\(n\)</span>维随机变量,对于任意实数<span class="math inline">\(x_1,x_2,...,x_n\)</span>,<span class="math inline">\(n\)</span>元函数</p><p><span class="math display">\[F(x_1,x_2,...,x_n)=P\{X_1\le x_1, X_2\le x_2, ..., X_n \le x_n\}\]</span></p><p>称为<span class="math inline">\(n\)</span>维随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的分布函数,或称为随机变量<span class="math inline">\(X_1,X_2,...X_n\)</span>的联合分布函数.</p><p>若存在非负函数<span class="math inline">\(f(x_1,x_2,...x_n)\)</span>, 使对于任意实数<span class="math inline">\(x_1,x_2,...,x_n\)</span>,有</p><p><span class="math display">\[F(x_1,x_2,...,x_n)=\int_{-\infty}^{x_n}\int_{-\infty}^{x_{n-1}}...\int_{-\infty}^{x_1}f(x_1,x_2,...,x_n)dx_1dx_2...dx_n\]</span></p><p>则称<span class="math inline">\(f(x_1,x_2,...x_n)\)</span>为<span class="math inline">\(n\)</span>维连续型随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的概率密度函数.</p><p>设<span class="math inline">\(X_i\)</span>可能取值为<span class="math inline">\(x_{ij_i}(i=1,2,...,n, \quad j_i=1,2,...)\)</span>, 则记</p><p><span class="math display">\[P\{X_1=x_{1j_1},X_2=x_{2j_2},...,X_n=x_{nj_n}\}=p_{j_1j_2...j_ns}\]</span></p><p>为<span class="math inline">\(n\)</span>为离散型随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的概率分布或分布律,或随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的联合分布律.</p><p>对于<span class="math inline">\(n\)</span>维空间中任一区域<span class="math inline">\(D, \{X_1,X_2,...,X_n\} \in D\)</span> 为一随机事件,若<span class="math inline">\(X_1,X_2,...,X_n\)</span>具有概率密度<span class="math inline">\(f(x_1,x_2,...,x_n\)</span>, 则概率</p><p><span class="math display">\[P\{(X_1,X_2,...,X_n) \in D\}=\int \int ... \int _D f(x_1,x_2,...,x_n)dx_1dx_2...dx_n\]</span></p><h3 id="n个随机变量的相互独立性"><span class="math inline">\(n\)</span>个随机变量的相互独立性</h3><p>若对于所有实数<span class="math inline">\(x_1,x_2,...,x_n\)</span>有</p><p><span class="math display">\[F(x_1,x_2,...,x_n)=F_{X_1}(x_1)F_{X_2}(x_2)...F_{X_n}(x_n)\]</span></p><p>则称<span class="math inline">\(n\)</span>个随机变量<span class="math inline">\(X_1,X_2,...,X_n\)</span>是相互独立的.</p><p>并且</p><p><span class="math display">\[f(x_1,x_2,...,x_n)=f_{X_1}(x_1)f_{X_2}(x_2)...f_{X_n}(x_n)\]</span></p><p>若对所有的实数<span class="math inline">\(x_1,x_2,...,x_m,y_1,y_2,...,y_n\)</span>,随机变量<span class="math inline">\((X_1,X_2,...,X_n,Y_1,Y_2,...,Y_n)\)</span>的分布函数<span class="math inline">\(F(x_1,x_2,...,x_m,y_1,y_2,...,y_n)\)</span>与关于<span class="math inline">\((X_1,X_2,...,X_m)\)</span>及<span class="math inline">\((Y_1,Y_2,...,Y_n)\)</span>的边缘分布函数<span class="math inline">\(F_1(x_1,x_2,...,x_m), F_2(y_1,y_2,...,y_n)\)</span>满足下述等式:</p><p><span class="math display">\[F(x_1,x_2,...,x_m,y_1,y_2,...,y_n)=F_1(x_1,x_2,...,x_m)F_2(y_1,y_2,...,y_n)\]</span></p><p>则称随机变量<span class="math inline">\((X_1,X_2,...,X_m)\)</span>与<span class="math inline">\((Y_1,Y_2,...,Y_n)\)</span>是相互独立的.</p><p>设<span class="math inline">\((X_1,X_2,...,X_m)\)</span>和<span class="math inline">\((Y_1,Y_2,...,Y_n)\)</span>相互独立,则<span class="math inline">\(X_i(i=1,2,...,m)\)</span>与<span class="math inline">\(Y_j(j=1,2,...,n)\)</span>相互独立.又若<span class="math inline">\(h,g\)</span>是连续函数,则<span class="math inline">\(h(X_1,X_2,...,X_m)\)</span>与<span class="math inline">\(g(Y_1,Y_2,...,Y_n)\)</span>相互独立.</p><h3 id="n维随机变量的函数的分布"><span class="math inline">\(n\)</span>维随机变量的函数的分布</h3><p>设<span class="math inline">\((X_1,X_2,...,X_n)\)</span>为<span class="math inline">\(n\)</span>维随机变量,其概率密度为<span class="math inline">\(f(x_1,x_2,...,x_n)\)</span>,<span class="math inline">\(g(x_1,x_2,...,x_n)\)</span>为<span class="math inline">\(n\)</span>元连续函数,则对任意实数<span class="math inline">\(z \in R, Z=g(X_1,X_2,...,X_n)\)</span>的分布函数为</p><p><span class="math display">\[F_Z(z)=P\{g(X_1,X_2,...,X_n) \le z\}=\int \int ... \int_{D_Z}f(x_1,x_2,...,x_n)dx_1dx_2...dx_n\]</span></p><p>其中<span class="math inline">\(D_Z=\{(x_1,x_2,...,x_n)|g(x_1,x_2,...,x_n) \le z\}\)</span>.</p><h1 id="随机变量的数字特征">随机变量的数字特征</h1><h2 id="数学期望">数学期望</h2><h3 id="数学期望的概念">数学期望的概念</h3><p>设离散型随机变量<span class="math inline">\(X\)</span>的分布律为</p><p><span class="math display">\[P\{X=x_k\}=p_k \qquad k=1,2,...\]</span></p><p>若级数<span class="math inline">\(\sum_{k=1}^{\infty}x_kp_k\)</span>绝对收敛,则称级数<span class="math inline">\(\sum_{k=1}^{\infty}x_kp_ks\)</span>的值为离散型随机变量<span class="math inline">\(X\)</span>的数学期望,记为<span class="math inline">\(E(X)\)</span>, 即</p><p><span class="math display">\[E(X)=\sum_{k=1}^{\infty}x_kp_k\]</span></p><p>数学期望可简称为期望或均值.</p><p>设连续型随机变量<span class="math inline">\(X\)</span>的概率密度为<span class="math inline">\(f(x)\)</span>,若积分</p><p><span class="math display">\[f_{-\infty}^{+\infty}xf(x)dx\]</span></p><p>绝对收敛,则称积分<span class="math inline">\(f_{-\infty}^{+\infty}xf(x)dx\)</span>的值为随机变量<span class="math inline">\(X\)</span>的数学期望,记为<span class="math inline">\(E(X)\)</span>,即</p><p><span class="math display">\[E(X)=f_{-\infty}^{+\infty}xf(x)dx\]</span></p><h3 id="随机变量的函数的数学期望">随机变量的函数的数学期望</h3><p>设<span class="math inline">\(Y\)</span>是随机变量<span class="math inline">\(X\)</span>的函数:<span class="math inline">\(Y=g(X)\)</span>(<span class="math inline">\(g\)</span>是连续函数)</p><ol style="list-style-type: decimal"><li><span class="math inline">\(X\)</span>是离散型随机变量,它的分布律为<span class="math inline">\(p_K=P\{X=x_k\}(k=1,2,...)\)</span>,若<span class="math inline">\(\sum_{k=1}^{\infty}g(x_k)p_k\)</span>绝对收敛,则有</li></ol><p><span class="math display">\[E(Y)=E[g(X)]=\sum_{k=1}^{\infty}g(x_k)p_k\]</span></p><ol start="2" style="list-style-type: decimal"><li><span class="math inline">\(X\)</span>是连续型随机变量,它的概率密度为<span class="math inline">\(f(x)\)</span>,若<span class="math inline">\(\int_{-\infty}^{+\infty}g(x)f(x)dx\)</span>绝对收敛,则有</li></ol><p><span class="math display">\[E(Y)=E[g(X)]=\int_{-\infty}^{+\infty}g(x)f(x)dx\]</span></p><h3 id="数学期望的简单性质">数学期望的简单性质</h3><ol style="list-style-type: decimal"><li>(线性法则)设<span class="math inline">\(X\)</span>为随机变量,其期望为<span class="math inline">\(E(X)\)</span>,对于任意常数<span class="math inline">\(a,b\)</span>有</li></ol><p><span class="math display">\[E(aX+b)=aE(X)+b\]</span></p><ol start="2" style="list-style-type: decimal"><li>(加法法则) 设<span class="math inline">\(X,Y\)</span>为随机变量,则有</li></ol><p><span class="math display">\[E(X+Y)=E(X)+E(Y)\]</span></p><ol start="3" style="list-style-type: decimal"><li>(乘法法则) 设<span class="math inline">\(X,Y\)</span>为两个相互独立的随机变量,则</li></ol><p><span class="math display">\[E(XY)=E(X)E(Y)\]</span></p><ol start="4" style="list-style-type: decimal"><li><p>(柯西-许瓦兹不等式)</p><p>设<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>是两个随机变量,则</p></li></ol><p><span class="math display">\[|E(XY)|^2 \le E(X^2)E(Y^2)\]</span></p><h2 id="方差">方差</h2><h3 id="概念-2">概念</h3><p>设<span class="math inline">\(X\)</span>是一个随机变量,若<span class="math inline">\(E\{[X-E(X)]^2\}\)</span>存在,则乘<span class="math inline">\(E\{[X-E(X)]^2\}\)</span>称为<span class="math inline">\(X\)</span>的方差,记为<span class="math inline">\(D(X)\)</span>或<span class="math inline">\(Var(X)\)</span>,即</p><p><span class="math display">\[D(X)=Var(X)=E\{[X-E(X)]^2\}\]</span></p><p>显然<span class="math inline">\(D(X) \ge 0\)</span>, 故在应用中引入与随机变量<span class="math inline">\(X\)</span>具有相同量纲的量<span class="math inline">\(\sqrt{D(X)}\)</span>, 记为<span class="math inline">\(\sigma(X)\)</span>,称为标准差或均方差.</p><p>由方差的定义可知,随机变量<span class="math inline">\(X\)</span>的方差实际上就是<span class="math inline">\(X\)</span>的函数<span class="math inline">\(Y=g(X)=(X-E(X))^2\)</span>. 故</p><p>若<span class="math inline">\(X\)</span>为离散型随机变量,其分布律为<span class="math inline">\(p_k=P\{X=x_k\}(k=1,2,...)\)</span>,其方差为</p><p><span class="math display">\[D(X)=\sum_{k=1}^{\infty}[x_k-E(X)]^2p_k\]</span></p><p>若<span class="math inline">\(X\)</span>为连续型随机变量,其概率密度为<span class="math inline">\(f(x)\)</span>,则<span class="math inline">\(X\)</span>的方差为</p><p><span class="math display">\[D(X)=\int_{-\infty}^{+\infty}[x-E(X)]^2f(x)dx\]</span></p><p>并且具有公式</p><p><span class="math display">\[D(X)=E[X^2]-[E(X)]^2\]</span></p><h3 id="方差的简单性质">方差的简单性质</h3><ol style="list-style-type: decimal"><li>设<span class="math inline">\(X\)</span>为随机变量,对于任意的常数<span class="math inline">\(a,b\)</span></li></ol><p><span class="math display">\[D(aX+b)=a^2D(X)\]</span></p><ol start="2" style="list-style-type: decimal"><li>设<span class="math inline">\(X,Y\)</span>为两个相互独立的随机变量,则有</li></ol><p><span class="math display">\[D(X+Y)=D(X)+D(Y)\]</span></p><ol start="3" style="list-style-type: decimal"><li>(契比雪夫不等式) 设<span class="math inline">\(X\)</span>为一随机变量,其均值<span class="math inline">\(E(X)=\mu\)</span>,方差<span class="math inline">\(D(X)=\sigma^2\)</span>,则对任意正数<span class="math inline">\(\sigma &gt; 0\)</span>,有</li></ol><p><span class="math display">\[P\{|X-\mu|\ge \varepsilon \} \le \frac{\sigma^2}{\varepsilon^2}\]</span></p><ol start="4" style="list-style-type: decimal"><li><span class="math inline">\(D(X)=0\)</span>的充要条件是<span class="math inline">\(X\)</span>以概率1取常数<span class="math inline">\(\mu =E(X)\)</span>,即</li></ol><p><span class="math display">\[P\{X=\mu \} = 1\]</span></p><p>### 几种重要随机变量的数学期望及方差</p><ol style="list-style-type: decimal"><li><p>二项分布<span class="math inline">\(B(n,p)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(n,p\)</span>的二项分布,其分布律为:</p></li></ol><p><span class="math display">\[P\{X=k\}=\left( \begin{matrix} n \\ k \end{matrix} \right) p^k(1-p)^{n-k}\]</span></p><p><span class="math inline">\(E(X)=np, \quad D(X)=np(1-p)\)</span></p><ol start="2" style="list-style-type: decimal"><li><p>泊松分布<span class="math inline">\(\pi(\lambda)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\lambda\)</span>的泊松分布,其 分布律为:</p></li></ol><p><span class="math display">\[P\{X=k\}=\frac{\lambda^ke^{-\lambda}}{k!} \qquad k=0,1,2,...; \lambda&gt;0\]</span></p><p><span class="math inline">\(E(X)=\lambda \qquad D(X)=\lambda\)</span></p><ol start="3" style="list-style-type: decimal"><li><p>几何分布<span class="math inline">\(Ge(p)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p\)</span>的几何分布,其分布律为</p></li></ol><p><span class="math display">\[P\{X=k\}=pq^{k-1} \quad k=1,2,.., \quad 0&lt;p&lt;1, q=1-p\]</span></p><p><span class="math inline">\(E(X)=\frac{1}{p} \qquad D(X)=\frac{q}{p^2}\)</span></p><ol start="4" style="list-style-type: decimal"><li>均匀分布<span class="math inline">\(U(a,b)\)</span></li></ol><p>设在区间<span class="math inline">\((a,b)\)</span>上服从均匀分布, 其概率密度为</p><p><span class="math display">\[f(x)=\begin{cases} \frac{1}{b-q} &amp; a&lt;x&lt;b \\ 0 &amp; other \end{cases}\]</span></p><p><span class="math inline">\(E(X)=\frac{a+b}{2} \qquad D(x)=\frac{(b-a)^2}{12}\)</span></p><ol start="5" style="list-style-type: decimal"><li><p>指数分布<span class="math inline">\(Z(\alpha)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\alpha\)</span>的指数分布,其概率密度为</p></li></ol><p><span class="math display">\[f(x)=\begin{cases} \alpha e^{-\alpha x} &amp; x&gt;0, \alpha &gt; 0 \\ 0 &amp; x \le 0 \end{cases}\]</span></p><p><span class="math inline">\(E(X)=\frac{1}{\alpha} \qquad D(X)=\frac{1}{\alpha ^2}\)</span></p><ol start="6" style="list-style-type: decimal"><li><p>正态分布<span class="math inline">\(N(\mu, \sigma ^2)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\mu, \sigma ^2\)</span>的正态分布,其概率密度为</p></li></ol><p><span class="math display">\[f(X)=\frac{1}{\sqrt{2\pi \sigma}} e ^{-\frac{(x-\mu)^2}{2\sigma ^2}} \qquad \sigma &gt; 0, -\infty &lt; x &lt; +\infty\]</span></p><p><span class="math inline">\(E(X)=\mu, \qquad D(X)=\sigma ^2\)</span></p><h2 id="协方差与相关系数">协方差与相关系数</h2><h3 id="概念-3">概念</h3><p>设<span class="math inline">\((X,Y)\)</span>为二维随机变量,量<span class="math inline">\(E\{[X-E(X)][Y-E(Y)]\}\)</span>称为<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>的协方差, 记为<span class="math inline">\(Cov(X,Y)\)</span>,即</p><p><span class="math display">\[Cov(X,Y)=E\{[X-E(X)][Y-E(Y)]\}\]</span></p><p>而量</p><p><span class="math display">\[\rho _{_{XY}}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}\]</span></p><p>称为随机变量<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>的相关系数, <span class="math inline">\(\rho _{_{XY}}\)</span>是一个无量纲的量.</p><p>特别的,当<span class="math inline">\(Y=X\)</span>时, <span class="math inline">\(Cov(X,X)=D(X)\)</span>,此时<span class="math inline">\(\rho _{_{XY}}=1\)</span>. 并且</p><p><span class="math display">\[D(X+Y)=D(X)+D(Y)+2Cov(X,Y)\]</span></p><p><span class="math display">\[Cov(X,Y)=E(XY)-E(X)E(Y)\]</span></p><p>设<span class="math inline">\(X,Y\)</span>为随机变量,<span class="math inline">\(a,b\)</span>为任意常数,则协方差<span class="math inline">\(Cov(X,Y)\)</span>具有一下性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(Cov(X,Y)=Cov(Y,X)\)</span></p></li><li><p><span class="math inline">\(Cov(X+a,Y+b)=Cov(X,Y)\)</span></p></li><li><p><span class="math inline">\(Cov(aX,bY)=abCov(X,Y)\)</span></p></li><li><p><span class="math inline">\(Cov(X_1+X_2, Y)=Cov(X_1,Y)+Cov(X_2,Y)\)</span></p></li><li><p><span class="math inline">\(|Cov(X,Y)| \le \sqrt{D(X)} \sqrt{D(Y)}\)</span></p></li></ol><h3 id="相关系数的性质">相关系数的性质</h3><ol style="list-style-type: decimal"><li><p><span class="math inline">\(|\rho _{_{XY}}| \le 1\)</span></p></li><li><p>若<span class="math inline">\(X,Y\)</span>相互独立,且<span class="math inline">\(D(X),D(Y)\)</span>存在,则</p></li></ol><p><span class="math display">\[Cov(X,Y)=\rho _{_{XY}}=0\]</span></p><p>如果随机变量<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>的相关系数<span class="math inline">\(\rho _{_{XY}}\)</span>,则<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>不相关.</p><h2 id="矩及协方差矩阵">矩及协方差矩阵</h2><h3 id="概念-4">概念</h3><p>设<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>是随机变量, <span class="math inline">\(k,l\)</span>为任一正整数:</p><ol style="list-style-type: decimal"><li><p>若<span class="math inline">\(E(X^k)\)</span>存在,则称<span class="math inline">\(\mu_k=E(X^k)\)</span>为<span class="math inline">\(X\)</span>的<span class="math inline">\(k\)</span>阶原点矩,简称<span class="math inline">\(k\)</span>阶距.</p></li><li><p>若<span class="math inline">\(E[X-E(X)]^k\)</span>存在,则称<span class="math inline">\(\sigma_k=E[X-E(X)]^k\)</span>为<span class="math inline">\(X\)</span>的<span class="math inline">\(k\)</span>阶中心矩.</p></li><li><p>若<span class="math inline">\(E(X^kY^l)\)</span>存在,则称<span class="math inline">\(\mu_{kl}=E(X^kY^l)\)</span>为<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的<span class="math inline">\(k+l\)</span>阶混合原点矩.</p></li><li><p>若<span class="math inline">\(E\{[X-E(X)]^k[Y-E(Y)]^l\}\)</span>存在,则称<span class="math inline">\(\sigma_{kl}=E\{[X-E(X)]^k[Y-E(Y)]^l\}\)</span>为<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的<span class="math inline">\(k+l\)</span>阶混合中心矩.</p></li></ol><p>显然,<span class="math inline">\(X\)</span>的一阶原点矩<span class="math inline">\(E(X)\)</span>就是<span class="math inline">\(X\)</span>的数学期望,<span class="math inline">\(X\)</span>的一阶中心矩<span class="math inline">\(E[X-E(X)]\)</span>为<span class="math inline">\(X\)</span>的偏差的数学期望,其恒等于0,即</p><p><span class="math display">\[E[X-E(X)] = E(X)-E(X)=0\]</span></p><p>而<span class="math inline">\(X\)</span>的二阶中心矩<span class="math inline">\(E\{[X-E(X)]^2\}\)</span>就是<span class="math inline">\(X\)</span>的方差.<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的二阶混合中心矩就是<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的协方差<span class="math inline">\(Cov(X,Y)\)</span>.</p><h3 id="协方差矩阵">协方差矩阵</h3><p>设<span class="math inline">\(n\)</span>维随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的二阶混合中心矩</p><p><span class="math display">\[C_{ij}=Cov(X_i,Y_j)=E\{[X_i-E(X_i)][Y_j-E(Y_j)]\} \qquad i,j=1,2,...n\]</span></p><p>都存在,则称矩阵</p><p><span class="math display">\[C=\left \lgroup \begin{matrix} C_{11} &amp; C_{12} &amp; \cdots &amp; C_{1n} \\ C_{21} &amp; C_{22} &amp; \cdots &amp; C_{2n} \\ \vdots &amp; \vdots &amp; \cdots &amp; \vdots \\ C_{n1} &amp; C_{n2} &amp; \cdots &amp; C_{nn} \end{matrix} \right \rgroup\]</span></p><p>为<span class="math inline">\(n\)</span>维随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的协方差矩阵.由于<span class="math inline">\(C_{ij}=C_{ji}(i,j=1,2,...n)\)</span>,因而矩阵<span class="math inline">\(C\)</span>为一对称矩阵.</p><h1 id="大数定律及中心极限定理">大数定律及中心极限定理</h1><h2 id="大数定律lln">大数定律<span class="math inline">\((LLN)\)</span></h2><p>设<span class="math inline">\(X_1,X_2,...,X_n,...,\)</span>是随便变量序列,<span class="math inline">\(E(X_k)(k=1,2,...)\)</span>存在. 令<span class="math inline">\(\bar{X}_n=\frac{1}{n}\sum_{k=1}^{n}X_k\)</span>,若对于任意给定正数<span class="math inline">\(\varepsilon &gt; 0\)</span>, 有</p><p><span class="math display">\[\lim_{n \rightarrow \infty}P\{|\bar{X}_n-E(\bar{X}_n)| \ge \varepsilon \} = 0\]</span></p><p>或</p><p><span class="math display">\[\lim_{n \rightarrow \infty}P\{|\bar{X}_n-E(\bar{X}_n)| &lt; \varepsilon \} =1 \]</span></p><p>则称<span class="math inline">\(\{X_n\}\)</span>服从大数定律或称大数法成立.</p><p>(贝努利定理)设<span class="math inline">\(n_A\)</span>是<span class="math inline">\(n\)</span>次独立重复试验中事件<span class="math inline">\(A\)</span>发生的次数,<span class="math inline">\(p\)</span>是事件<span class="math inline">\(A\)</span>在每次试验中发送的概率,则对于任意的正数<span class="math inline">\(\varepsilon &gt; 0\)</span>, 有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{|\frac{n_A}{n}-p| &lt; \varepsilon \} = 1 \]</span></p><p>或</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{|\frac{n_A}{n}-p| \ge \varepsilon \} = 0 \]</span></p><p>契比雪夫特殊情况: 设<span class="math inline">\(X_1,X_2,\cdots,X_n,\cdots\)</span>相互独立(即对于任意的<span class="math inline">\(n\ge 1, X_1,X_2,\cdots,X_n\)</span>是相互独立的), 且具有相同的数学期望和方差<span class="math inline">\(E(X_k)=\mu, D(X_k)=\sigma ^2(k=1,2,\cdots)\)</span>, 则对任意正数<span class="math inline">\(\varepsilon &gt; 0\)</span>, 有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P \{|\bar{X}_n - \mu | &lt; \varepsilon \} = 1\]</span></p><p>辛钦定理: 设随机变量序列<span class="math inline">\(X_1,X_2,\cdots,X_n,\cdots\)</span>相互独立,服从同一分布,且具有数学期望<span class="math inline">\(E(X_k)=\mu(k=1,2,...)\)</span>,则对于任意正数<span class="math inline">\(\varepsilon\)</span>有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{|\bar{X}_n - \mu| &lt; \varepsilon \} = 1\]</span></p><p>即</p><p><span class="math display">\[\bar{X}_n \stackrel{P} \longrightarrow \mu \]</span></p><h2 id="中心极限定理clt">中心极限定理<span class="math inline">\((CLT)\)</span></h2><p>凡是在一定条件下,断定随机变量序列<span class="math inline">\(X_1,X_2,\cdots\)</span>的部分和<span class="math inline">\(Y_n=\sum_{k=1}^{n}X_k\)</span>的极限分布为正态分布的定理,均称为中心极限定理.</p><p>即中心极限定理应当说明,在何种条件下,下式成立:对任意的<span class="math inline">\(x\)</span>,有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{\frac{Y_n - E(Y_n)}{\sqrt{D(Y_n)}} \le x \} = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}}dt=\Phi(x)\]</span></p><p>隶莫佛-拉普拉斯定理</p><p>设随机变量列<span class="math inline">\(Y_n(n=1,2,\cdots)\)</span>服从参数为<span class="math inline">\(n,p\)</span>的二项分布<span class="math inline">\(B(n,p)(0&lt;p&lt;1)\)</span>,则对于任意的<span class="math inline">\(x\)</span>,恒有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{\frac{Y_n - np}{\sqrt{np(1-p)}} \le x \} = \Phi(x)\]</span></p><p>独立同分布中极限定理</p><p>设<span class="math inline">\(X_1,X_2,\cdots,X_n,\cdots\)</span>相互独立,且服从同一分布,具有数学期望及方差:<span class="math inline">\(E(X_k)=\mu, D(X_k)=\sigma^2 \neq 0(k=1,2,\cdots)\)</span>,则随机变量<span class="math inline">\(Y_n=\sum_{k=1}{n}X_k\)</span>近似服从正态分布<span class="math inline">\(N(n\mu,n\sigma^2)\)</span>,即对于任意的<span class="math inline">\(x\)</span>,有</p><p><span class="math display">\[\lim_{n\rightarrow \infty}P\{\frac{Y_n - n\mu}{\sqrt{n}\sigma} \le x \} = \Phi(x)\]</span></p><p>李雅普诺夫定理</p><p>设随机变量<span class="math inline">\(X_1,X_2,\cdots,X_n\)</span>相互独立,它们具有数学期望和方差:</p><p><span class="math display">\[E(X_k)=\mu_k, D(X_k)=\sigma_k^2 \neq 0 \qquad k=1,2,\cdots\]</span></p><p>记<span class="math inline">\(B_n^2=\sum_{k=1}^n\sigma_k^2\)</span>,若存在正数<span class="math inline">\(\delta\)</span>,使得当<span class="math inline">\(n \rightarrow \infty\)</span>时,</p><p><span class="math display">\[\frac{1}{B_n^{2+\delta}} \sum_{k=1}^nE\{|X_k-\mu_k|^{2+\delta} \} \rightarrow 0\]</span></p><p>则随机变量<span class="math inline">\(Y_n=\sum_{k=1}^nX_k\)</span>近似服从正态分布<span class="math inline">\(N(\sum_{k=1}^n\mu_k,B_n^2)\)</span>, 即对于任意的<span class="math inline">\(x\)</span>,有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{\frac{Y_n-\sum_{k=1}^n \mu_k}{B_n} \le x \} = \Phi(x)\]</span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本概念&quot;&gt;基本概念&lt;/h1&gt;
&lt;h2 id=&quot;古典概型&quot;&gt;古典概型&lt;/h2&gt;
&lt;h3 id=&quot;古典改型的特点&quot;&gt;古典改型的特点:&lt;/h3&gt;
&lt;ol style=&quot;list-style-type: decimal&quot;&gt;
&lt;li&gt;试验的样本空间中的元素个数只有有限个,
      
    
    </summary>
    
      <category term="数学" scheme="https://mejhwu.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>二叉搜索树</title>
    <link href="https://mejhwu.github.io/2017/10/22/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"/>
    <id>https://mejhwu.github.io/2017/10/22/二叉搜索树/</id>
    <published>2017-10-21T16:00:00.000Z</published>
    <updated>2018-09-05T14:20:08.563Z</updated>
    
    <content type="html"><![CDATA[<p>二叉搜索树是一种被用于查找的二叉树。其要求是：每个节点都大于其左子树，小于或等于右子树。</p><div class="figure"><img src="../images/binary_search_tree/binary_search_tree.png"></div><h3 id="查找">1. 查找</h3><p>从根节点开始查找。如果关键值等于当前节点值，说明查找成功。如果关键值小于当前节点值，则在当前节点的左子树上查找。如果关键值大于当前节点，则在当前节点的右子树上查找。</p><div class="figure"><img src="../images/binary_search_tree/binary_search_tree_search.png"></div><h3 id="插入">2. 插入</h3><p>插入的节点一定是叶子节点。二叉搜索树插入前需要先进行查找，最后查找到的叶子节点即为插入节点的位置。</p><div class="figure"><img src="../images/binary_search_tree/binary_search_tree_insert.png"></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;二叉搜索树是一种被用于查找的二叉树。其要求是：每个节点都大于其左子树，小于或等于右子树。&lt;/p&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src=&quot;../images/binary_search_tree/binary_search_tree.png&quot;&gt;

&lt;/
      
    
    </summary>
    
      <category term="算法" scheme="https://mejhwu.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
</feed>
