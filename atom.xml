<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>个人博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://mejhwu.github.io/"/>
  <updated>2018-11-13T13:48:09.255Z</updated>
  <id>https://mejhwu.github.io/</id>
  
  <author>
    <name>jhwu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>熵</title>
    <link href="https://mejhwu.github.io/2018/11/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%86%B5/"/>
    <id>https://mejhwu.github.io/2018/11/05/机器学习/熵/</id>
    <published>2018-11-04T16:00:00.000Z</published>
    <updated>2018-11-13T13:48:09.255Z</updated>
    
    <content type="html"><![CDATA[<h1 id="熵">熵</h1><h2 id="定义">定义</h2><p>如果<span class="math inline">\(X\)</span>是一个离散型随机变量，取值空间为<span class="math inline">\(\mathbb{R}\)</span>，其概率分布为<span class="math inline">\(p(x)=P(X=x), x \in R\)</span>。那么，<span class="math inline">\(X\)</span>的熵<span class="math inline">\(H(X)\)</span>定义为： <span class="math display">\[H(X)=-\sum_{x \in \mathbb{R}}p(x)\mathrm{log}_2p(x)\]</span> 其中，约定<span class="math inline">\(0log0=0\)</span>。<span class="math inline">\(H(x)\)</span>可以写为<span class="math inline">\(H(p)\)</span>。</p><p>熵又称为自信息(self-information)，可以视为描述一个随机变量的不确定性的数量。它表示信源<span class="math inline">\(X\)</span>每发出一个符号（不论发什么符号）所提供的平均信息量。一个随机变量的熵越大，它的不确定性越大，那么正确估计其值的可能性就越小。越不确定的随机变量越需要大的信息量用以确定其值。</p><h2 id="联合熵">联合熵</h2><p>如果<span class="math inline">\(X,Y\)</span>是一对离散型随机变量<span class="math inline">\(X,Y \sim p(x,y), XY\)</span>的联合熵(joint entropy)<span class="math inline">\(H(X,Y)\)</span>定义为： <span class="math display">\[H(X,Y)=-\sum_{x \in X} \sum_{y \in Y}p(x,y)\mathrm{log}p(x,y)\]</span> 联合熵实际熵就是描述一对随机变量平均所需要的信息量。</p><h2 id="条件熵">条件熵</h2><p>给定随机变量<span class="math inline">\(X\)</span>的情况下，随机变量<span class="math inline">\(Y\)</span>的条件熵(conditional entropy)定义为： <span class="math display">\[\begin{align}H(X|Y) &amp;=\sum_{x \in X}p(x)H(Y|X=x) \\&amp; = \sum_{x \in X}p(x)[-\sum_{y \in Y}p(y|x)\mathrm{log}p(y|x)] \\&amp; =-\sum_{x \in X} \sum_{y \in Y}p(x,y)\mathrm{log}p(y|x)\end{align}\]</span></p><h2 id="相对熵">相对熵</h2><p>相对熵(relative entropy)又称为Kullback_leibler差异（KL散度，Kullback-Leibler divergence），或简称KL距离，是衡量相同事件空间里两个概率分布相对差距的测度。两个概率分布<span class="math inline">\(p(x)\)</span>和<span class="math inline">\(q(x)\)</span>的相对熵定义为： <span class="math display">\[D(p||q)=\sum_{x \in X}p(x)\mathrm(log)\frac{p(x)}{q(x)}\]</span> 该定义中约定<span class="math inline">\(0\mathrm{log(x/q)}=0, p\mathrm{log(p/0)}=\infty\)</span>。表示成期望值为 <span class="math display">\[D(p||q)=E_p(\mathrm{log}\frac{p(X)}{q(X)}\]</span> 当两个随机分布完全相同时，即<span class="math inline">\(p=q\)</span>，其相对熵为0。当两个随机分布的差别增加时，其相对熵期望值也增大。</p><h2 id="交叉熵">交叉熵</h2><p>交叉熵的概念是用来衡量估计模型与真实概率分布之间的差异情况的。如果一个随机变量<span class="math inline">\(X \sim p(x), q(x)\)</span>为用于近似<span class="math inline">\(p(x)\)</span>的概率分布，那么，随机变量<span class="math inline">\(X\)</span>和模型<span class="math inline">\(q\)</span>之间的交叉熵(cross entropy)定义为： <span class="math display">\[\begin{align}H(X,q) &amp;=H(X)+D(p||q) \\&amp; = -\sum_xp(x)\mathrm{log}q(x) \\&amp; = E_p(\mathrm{log}\frac{1}{q(x)})\end{align}\]</span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;熵&quot;&gt;熵&lt;/h1&gt;
&lt;h2 id=&quot;定义&quot;&gt;定义&lt;/h2&gt;
&lt;p&gt;如果&lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;是一个离散型随机变量，取值空间为&lt;span class=&quot;math inline&quot;&gt;\(\mathbb{R}\)&lt;
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>深度学习参数优化</title>
    <link href="https://mejhwu.github.io/2018/10/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
    <id>https://mejhwu.github.io/2018/10/19/机器学习/深度学习参数优化/</id>
    <published>2018-10-18T16:00:00.000Z</published>
    <updated>2018-11-14T03:29:22.038Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习参数优化">深度学习参数优化</h1><p>深度学习效果不好的话需要判断是在训练集上效果不好还是在测试集上效果不好，这两种情况有不同的优化方法。</p><p>在训练集上效果不好有两种常用的优化方法：1. 调整学习率；2. 采用新的激活函数。</p><p>在测试集上效果不好有3种常用方法：（1）提前停止，（2）正则化，（3）Dropout</p><h2 id="训练优化">训练优化</h2><h3 id="调整学习率">调整学习率</h3><p>如果采用固定学习率，会出现Vanishing Gradient的问题，在靠近输出层的参数已经有很大的改变，但是在靠近输入层的参数改变还很小。</p><div class="figure"><img src="images/深度学习参数优化/vanishing_gradient.png" alt="vanishing_gradient"><p class="caption">vanishing_gradient</p></div><h4 id="adagrad">Adagrad</h4><p>adagrad是利用前一次的梯度和学习率来估算下一次的学习率。其公式为 <span class="math display">\[w^{t+1} \gets w^t - \frac{\eta}{\sqrt{\sum_{i=0}^t(g^i)^2}}g^t\]</span></p><div class="figure"><img src="images/深度学习参数优化/adagrad.png"></div><h4 id="rmsprop">RMSProp</h4><p>在训练神经网络的时候，其梯度结构会非常复杂。RMSProp公式如下： <span class="math display">\[w^{t+1} \gets w^t - \frac{\eta}{ \sqrt{\alpha (\sigma^{t-1})^2 + (1-\alpha)(g^t)^2}}g^t\]</span> <img src="images/深度学习参数优化/rmsprop.png"></p><h4 id="momentum">Momentum</h4><p>在进行梯度下降的时候，很难找到最优解，因为在计算梯度的时候会存在梯度近似为0的点、鞍点和局部最小的点。</p><div class="figure"><img src="images/深度学习参数优化/hard_to_fin_optimal_params.png"></div><p>梯度的下降过程，可以类比为物理世界中的坡度的下降，在物理世界的坡度下降时会有动能的作用，导致下降的时候可以跳过鞍点甚至局部最小点。momentum方法就是在计算梯度的过程中，引入前一次计算的梯度的“动能”。</p><div class="figure"><img src="images/深度学习参数优化/momentum1.png"></div><div class="figure"><img src="images/深度学习参数优化/momentum2.png"></div><h4 id="adamrmsprop-momentum">Adam(RMSProp + Momentum)</h4><p>adam就是采用rmsprop和momentum相结合的方法。</p><div class="figure"><img src="images/深度学习参数优化/adam.png"></div><h3 id="采用新的激活函数">采用新的激活函数</h3><h4 id="relu">ReLU</h4><p>relu的全称是Rectified Linear Unit，其公式为： <span class="math display">\[\sigma(z) = max(0, z)\]</span> <img src="images/深度学习参数优化/reLu.png"></p><p>relu还拥有不同变体，比如Leaky ReLU和Parametric ReLU。</p><div class="figure"><img src="images/深度学习参数优化/relu_variant.png"></div><h4 id="maxout">maxout</h4><p>maxout就是将同一层中的节点进行分组，然后将分组中的最大的一个节点输出进入下一层网络。</p><div class="figure"><img src="images/深度学习参数优化/maxout.png"></div><p>ReLu可看作是Maxout中的一种特殊的格式，即增加了一个参数为0的输出，然后将正常输出与参数为0的输出做maxout。!</p><div class="figure"><img src="images/深度学习参数优化/maxout_relu.png"></div><p>利用Maxout可以得到任意类似于折线图的激活函数。</p><div class="figure"><img src="images/深度学习参数优化/maxout_more1.png"></div><div class="figure"><img src="images/深度学习参数优化/maxout_more2.png"></div><p>在利用Maxout进行训练的时候，每次训练的时候只会训练完整网络的一个子集。因为训练数据很多，所以所有的参数都是可以被训练到的。</p><h2 id="测试优化">测试优化</h2><p>当在训练集上表现很好，但是在测试集上效果不好的最主要的原因就是过拟合。防止过拟合主要又一下几种方法。</p><h3 id="提前停止">提前停止</h3><p>顾名思义，提前停止，就是在训练的时候可以不用将神经网络训练到最好，达到一个在训练集和测试集上都表现不错的结果就可以了。</p><h3 id="正则化">正则化</h3><p>正则化是在损失函数中添加正则项，正则的主要作用是添加最参数的限制。常用的正则项又L2正则和L1正则。</p><div class="figure"><img src="images/深度学习参数优化/regularization.png"></div><p>L2正则就是在损失函数中加入参数的L2范数：<span class="math inline">\(||\theta||_2=(w_1)^2+(w_2)^2+\cdots\)</span></p><div class="figure"><img src="images/深度学习参数优化/regularization_l2.png"></div><p>L2正则就是在损失函数中加入参数的L2范数：<span class="math inline">\(||\theta||_1=|w_1|+|w_2|+\cdots\)</span></p><div class="figure"><img src="images/深度学习参数优化/regularization_l1.png"></div><h3 id="dropout">Dropout</h3><p>Dropout是在训练时常用的一种技术，Dropout指在训练中以一定的概率去掉每一层的一些节点。这样可以加快训练速度，并且可以防止过拟合。</p><div class="figure"><img src="images/深度学习参数优化/dropout.png"></div><div class="figure"><img src="images/深度学习参数优化/dropout1.png"></div><div class="figure"><img src="images/深度学习参数优化/dropout2.png"></div><p>参考：<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17.html" target="_blank" rel="noopener">李宏毅-机器学习2017</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;深度学习参数优化&quot;&gt;深度学习参数优化&lt;/h1&gt;
&lt;p&gt;深度学习效果不好的话需要判断是在训练集上效果不好还是在测试集上效果不好，这两种情况有不同的优化方法。&lt;/p&gt;
&lt;p&gt;在训练集上效果不好有两种常用的优化方法：1. 调整学习率；2. 采用新的激活函数。&lt;/p&gt;
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>深度学习调参建议</title>
    <link href="https://mejhwu.github.io/2018/10/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B0%83%E5%8F%82%E5%BB%BA%E8%AE%AE/"/>
    <id>https://mejhwu.github.io/2018/10/19/机器学习/深度学习调参建议/</id>
    <published>2018-10-18T16:00:00.000Z</published>
    <updated>2018-11-13T14:29:41.079Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参数调优">参数调优</h1><ol style="list-style-type: decimal"><li>Grid Search v.s. Random Search</li></ol><div class="figure"><img src="../../images/深度学习调参建议/gridserach.png"></div><p>Assumption: top K results are good enough.</p><p>if there are N points, probability K/N that your sample is in top K Sample x times: <span class="math display">\[   1 - (1 - K /N )^x &gt; 90 \%   \]</span> If N = 1000, K = 10 ———–-&gt; x = 230</p><p>​ K = 100 ————&gt; x = 22</p><ol start="2" style="list-style-type: decimal"><li>Model-based Hyperparameter</li></ol><div class="figure"><img src="../../images/深度学习调参建议/mode-base%20.png"></div><ol start="3" style="list-style-type: decimal"><li>learn to learn</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;参数调优&quot;&gt;参数调优&lt;/h1&gt;
&lt;ol style=&quot;list-style-type: decimal&quot;&gt;
&lt;li&gt;Grid Search v.s. Random Search&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img s
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>凸优化</title>
    <link href="https://mejhwu.github.io/2018/10/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%87%B8%E4%BC%98%E5%8C%96/"/>
    <id>https://mejhwu.github.io/2018/10/19/机器学习/凸优化/</id>
    <published>2018-10-18T16:00:00.000Z</published>
    <updated>2018-11-13T14:12:05.561Z</updated>
    
    <content type="html"><![CDATA[<h1 id="凸优化">凸优化</h1><h2 id="介绍">介绍</h2><p>机器学习中的大部分的情况都是优化一些函数的值。例如，给定一个函数<span class="math inline">\(f: \mathbb{R}^n \to \mathbb{R}\)</span>，我们想要找到<span class="math inline">\(x \in \mathbb{R}\)</span>使得<span class="math inline">\(f(x)\)</span>的值最小 （或最大）。最小二乘法，logistics回归，支持向量机都是最优化问题。</p><p>在大部分案例中，想要找到一个函数的全局最优值是非常困难的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;凸优化&quot;&gt;凸优化&lt;/h1&gt;
&lt;h2 id=&quot;介绍&quot;&gt;介绍&lt;/h2&gt;
&lt;p&gt;机器学习中的大部分的情况都是优化一些函数的值。例如，给定一个函数&lt;span class=&quot;math inline&quot;&gt;\(f: \mathbb{R}^n \to \mathbb{R}\)&lt;
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Java 8 新特性</title>
    <link href="https://mejhwu.github.io/2018/09/21/Java/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93/"/>
    <id>https://mejhwu.github.io/2018/09/21/Java/代码整洁之道/</id>
    <published>2018-09-20T16:00:00.000Z</published>
    <updated>2018-09-21T13:58:18.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="命名">命名</h2><p>代码命名应该名副其实，每一个命名都应该有意义。应避免留下掩藏代码本意的错误线索，应避免使用与本意相悖的词。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;命名&quot;&gt;命名&lt;/h2&gt;
&lt;p&gt;代码命名应该名副其实，每一个命名都应该有意义。应避免留下掩藏代码本意的错误线索，应避免使用与本意相悖的词。&lt;/p&gt;

      
    
    </summary>
    
      <category term="java" scheme="https://mejhwu.github.io/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>工厂模式</title>
    <link href="https://mejhwu.github.io/2018/09/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
    <id>https://mejhwu.github.io/2018/09/09/设计模式/工厂模式/</id>
    <published>2018-09-08T16:00:00.000Z</published>
    <updated>2018-09-09T03:04:02.441Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    <summary type="html">
    
      
      
        

      
    
    </summary>
    
      <category term="设计模式" scheme="https://mejhwu.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="https://mejhwu.github.io/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>https://mejhwu.github.io/2018/09/05/机器学习/线性回归/</id>
    <published>2018-09-04T16:00:00.000Z</published>
    <updated>2018-09-06T15:12:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性回归">线性回归</h1><h2 id="基本线性模型">基本线性模型</h2><p>给定有<span class="math inline">\(d\)</span>个属性描述的实例<span class="math inline">\(\boldsymbol{x}=(x_1; x_2; ...; x_d)\)</span>，其中<span class="math inline">\(x_i\)</span>是<span class="math inline">\(\boldsymbol{x}\)</span>在第<span class="math inline">\(i\)</span>个属性上的取值，线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数，即 <span class="math display">\[f(\boldsymbol{x})=w_1x_1 + w_2x_2 + \cdot\cdot\cdot + w_dx_d + b\]</span> 一般用向量形式写成 <span class="math display">\[f(\boldsymbol{x})=\boldsymbol{w}^T \boldsymbol{x} + b\]</span> 其中<span class="math inline">\(\boldsymbol{w}=(w_1; w_2; ...; w_d)\)</span>. <span class="math inline">\(\boldsymbol{w}\)</span>和<span class="math inline">\(b\)</span>学得之后，模型就可以确定。</p><h2 id="线性回归-1">线性回归</h2><p>给定数据集<span class="math inline">\(D=\{(\boldsymbol{x_1}, y_1), (\boldsymbol{x_2}, y_2), \cdots, (\boldsymbol{x_m}, y_m),\}\)</span>，其中<span class="math inline">\(\boldsymbol{x_i}=(x_{i1}, x_{i2}, \cdots, x_{id}), y_i \in \mathbb{R}\)</span>. “线性回归”试图学的一个线性模型尽可能准确的预测实值输出标记。</p><p>对于离散值，若属性之间存在“序”关系，可通过连续化将其转化为连续值，如三属性值“高度”的取值为“高” “中” “矮”,可转化为{1.0, .0.5, 0.0}；若属性值之间不存在序关系，假定有<span class="math inline">\(k\)</span>个属性值，则通常转化为<span class="math inline">\(k\)</span>为向量。</p><p>线性回归试图学得<span class="math inline">\(f(x_i) = \boldsymbol{w^T} \boldsymbol{x}_i + b\)</span>，使得<span class="math inline">\(f(\boldsymbol{x}_i) \simeq y_i\)</span>。</p><p>回归问题中常用的损失函数（性能度量）是均方误差，令<span class="math inline">\(\boldsymbol{\theta}=(\boldsymbol{w}, b)\)</span>, 则均方误差可表示为： <span class="math display">\[\mathrm{J(\boldsymbol{\theta})}=\frac{1}{2}\sum_{i=1}^{m}(f(\boldsymbol{x}_i) - y_i)^2\]</span></p><h3 id="梯度下降">梯度下降</h3><p>最小化<span class="math inline">\(\mathrm{J}(\boldsymbol{\theta})\)</span>是一个最优化问题，可以采用梯度下降算法或牛顿法求解。</p><h3 id="最小二乘法">最小二乘法</h3><p>首先考虑<span class="math inline">\(x\)</span>只有一个属性，可以试图让均方误差最小化，即 <span class="math display">\[\begin{align}(w^*, b^*) &amp; =  \arg\min_{(w, b)}\sum_{i=1}^{m}(f(x_i) - y_i)^2  \\                   &amp; = \arg\min_{(w,b)}\sum_{i=1}^m(y_I - wx_i -b)^2\end{align}\]</span> 基于均方误差最小化来进行模型求解的的方法称为“最小二乘法”（least square method). 在线性回归中，最小二乘法就是找到一条直线，使得所有样本到直线上的欧式距离之和最小。</p><p>求解<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>使<span class="math inline">\(E_{(w,b)}=\sum_{i=1}^m(y_i-wx_i-b)^2\)</span>最小化的过程，称为线性回归模型的最小二乘“参数估计“(parameter estimation). 将<span class="math inline">\(E_{(w,b)}\)</span>分别对<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>求导，得到 <span class="math display">\[\frac{\partial E_{(w,b)}}{\partial w} = 2(w\sum_{i=1}^mx_i^2 - \sum_{i=1}^m (y_i - b)x_i)\]</span></p><p><span class="math display">\[\frac{\partial E_{(w,b)}}{\partial b} = 2(mb - \sum_{i=1}^m(y_i-wx_i))\]</span></p><p>令是（6）和式（7）分别等于0，可得到<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>的最优解的闭式解 <span class="math display">\[w=\frac{\sum_{i=1}^m y_i(x_i - \bar{x})}{\sum_{i=1}^mx_i^2 - \frac{1}{m}(\sum_{i=1}^mx_i)^2}\]</span></p><p><span class="math display">\[b=\frac{1}{m}\sum_{i=1}^m(y_i - wx_i)\]</span></p><p>当<span class="math inline">\(\boldsymbol{x}\)</span>由<span class="math inline">\(d\)</span>个属性描述时，把数据集<span class="math inline">\(D\)</span>表示为一个<span class="math inline">\(m \times (d + 1)\)</span>大小的矩阵<span class="math inline">\(\mathrm{X}\)</span>，每一行的前<span class="math inline">\(d\)</span>个属性对应于样本的<span class="math inline">\(d\)</span>个属性值，最后一个元素恒置为1，即 <span class="math display">\[\mathrm{X} =   \left[ \begin{matrix}             x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} &amp; 1 \\                      x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} &amp; 1 \\                      \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\                      x_{m1} &amp; x_{m2} &amp; \cdots &amp; x_{md} &amp; 1            \end{matrix} \right]        =   \left[ \begin{matrix}             \boldsymbol{x}_1^T &amp; 1 \\                      \boldsymbol{x}_2^T  &amp; 1 \\                      \vdots &amp; \vdots \\                      \boldsymbol{x}_m^T  &amp; 1            \end{matrix} \right]\]</span> 将标记写为向量形式<span class="math inline">\(\boldsymbol{y}=(y_1, y_2, \cdots, y_m)\)</span>， 则有 <span class="math display">\[\boldsymbol{\theta}^* = \arg\min_{\boldsymbol{\theta}}(\boldsymbol{y}-\mathrm{X}\boldsymbol{\theta})^T(\boldsymbol{y}-\mathrm{X}\boldsymbol{\theta})\]</span> 令<span class="math inline">\(E_{\boldsymbol{\theta}}=(\boldsymbol{y}-\mathrm{X}\boldsymbol{\theta})^T(\boldsymbol{y}-\mathrm{X}\boldsymbol{\theta})\)</span>，对<span class="math inline">\(\boldsymbol{\theta}\)</span>求导得到 <span class="math display">\[\frac{\partial{E_{\boldsymbol{\theta}}}}{\partial{\boldsymbol{\theta}}}=2 \mathrm{X}^T(\mathrm{X}\boldsymbol{\theta}-\boldsymbol{y})\]</span> 令上式等于零，即可求得<span class="math inline">\(\boldsymbol{\theta}\)</span>的最优解的闭式解。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性回归&quot;&gt;线性回归&lt;/h1&gt;
&lt;h2 id=&quot;基本线性模型&quot;&gt;基本线性模型&lt;/h2&gt;
&lt;p&gt;给定有&lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt;个属性描述的实例&lt;span class=&quot;math inline&quot;&gt;\(\boldsym
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://mejhwu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>EM算法</title>
    <link href="https://mejhwu.github.io/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/"/>
    <id>https://mejhwu.github.io/2018/09/05/机器学习/EM算法/</id>
    <published>2018-09-04T16:00:00.000Z</published>
    <updated>2018-09-05T15:35:45.148Z</updated>
    
    <content type="html"><![CDATA[<h1 id="em算法">EM算法</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;em算法&quot;&gt;EM算法&lt;/h1&gt;

      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Java 8 新特性</title>
    <link href="https://mejhwu.github.io/2018/09/05/Java/java8%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    <id>https://mejhwu.github.io/2018/09/05/Java/java8新特性/</id>
    <published>2018-09-04T16:00:00.000Z</published>
    <updated>2018-09-11T14:51:23.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="java-8-新特性">Java 8 新特性</h1><h2 id="lambda表达式">Lambda表达式</h2><p>lambda表达式可理解为简洁地表示可传递的匿名函数的一种方式：没有名称，有参数列表、函数主体、返回类型。</p><p>lambda表达式有3个部分：</p><ol style="list-style-type: decimal"><li>参数列表</li><li>箭头(-&gt;)</li><li>lambda主体</li></ol><p>下面是一个lambda表达式的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">int</span> a, <span class="keyword">int</span> b) -&gt; a + b;</span><br></pre></td></tr></table></figure><p>在上面的例子中，<code>(int a, int b)</code>是参数列表，参数类型可省略<code>（a, b)</code>。lambda主体为<code>a + b</code>。</p><h3 id="函数式接口">函数式接口</h3><p>函数式接口就是只定义了一个抽象方法的接口，比如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Comparator</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">compare</span><span class="params">(T o1, T o2)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Runnable</span> </span>&#123;Su</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>lambda表达式允许直接以内联的形式为函数式接口的抽象方法提供实现，并把整个表达式作为函数式接口的实例。类似与匿名内部类，lambda表达式相对与匿名内部类而言更加简洁：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Runnable r1 = () -&gt; System.out.println(<span class="string">"Hello World 1"</span>);</span><br><span class="line"></span><br><span class="line">Runnable r2 = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Hello World 2"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数式接口的抽象方法的签名就是lambda表达式的签名，这种抽象方法叫做函数描述符。在将lambda表达式作为参数传递或赋值给变量的时候需要做类型检测，要求lambda表达式的签名与函数式接口的抽象方法的签名一致。</p><p>常见的函数时接口有：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Predicate</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">test</span><span class="params">(T t)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FuncationInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Consumer</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">accept</span><span class="params">(T t)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FuncationInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Function</span>&lt;<span class="title">T</span>, <span class="title">R</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function">R <span class="title">apply</span><span class="params">(T t)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p><code>@FunctionInterface</code>用于标注该接口会设计为一个函数式接口，如果使用<code>@FunctionInterface</code>定义了一个接口，但它不是函数式接口的时候编译器就会返回一个提示原因的错误。</p><p>除了以上3个通用的函数式接口外，java8还提供了一些专为特定类型设计的接口。</p><table><thead><tr class="header"><th align="left">函数式接口</th><th>函数描述符</th><th>原始类型特化</th></tr></thead><tbody><tr class="odd"><td align="left"><code>Predicate&lt;T&gt;</code></td><td><code>T -&gt; boolean</code></td><td><code>IntPredicate, LongPredicate, DoublePredicate</code></td></tr><tr class="even"><td align="left"><code>Consumer&lt;T&gt;</code></td><td><code>T -&gt; void</code></td><td><code>IntConsumer, LongConsumer, DoubleConsumer</code></td></tr><tr class="odd"><td align="left"><code>Functino&lt;T,R&gt;</code></td><td><code>T -&gt; R</code></td><td><code>IntFuncation&lt;R&gt;, IntToDoubleFunction, ...</code></td></tr><tr class="even"><td align="left"><code>Supplier&lt;T&gt;</code></td><td><code>() -&gt; T</code></td><td><code>BooleanSupplier, IntSupplier, ...</code></td></tr><tr class="odd"><td align="left"><code>UnaryOperator&lt;T&gt;</code></td><td><code>T -&gt; T</code></td><td><code>IntUnaryOperator, LongUnaryOperator, ...</code></td></tr><tr class="even"><td align="left"><code>BinaryOperator&lt;T&gt;</code></td><td><code>(T, T) -&gt; T</code></td><td><code>IntBinaryOperator, LongBinaryOperator, ...</code></td></tr><tr class="odd"><td align="left"><code>BiPredicate&lt;L, R&gt;</code></td><td><code>(L, R) -&gt; boolean</code></td><td></td></tr><tr class="even"><td align="left"><code>BiConsumer&lt;T, U&gt;</code></td><td><code>(T, U) -&gt; void</code></td><td><code>ObjIntConsumer&lt;T&gt;, ObjLongConsumer&lt;T&gt;, ...</code></td></tr><tr class="odd"><td align="left"><code>BiFunction&lt;T,U,R&gt;</code></td><td><code>(T, U) -&gt; R</code></td><td><code>ToIntBiFunction&lt;T, U&gt;, ...</code></td></tr></tbody></table><h3 id="类型检测">类型检测</h3><p>Lambda的类型是从使用Lambda的上下文中推断出来的，上下文中Lambda表达式需要的类型称为目标类型。统一个Lambda表达式可以与不同的函数式接口联系起来，只要它们的抽象方法的签名能够兼容。比如<code>Callable</code>和<code>PrivilegeAction</code>的抽象方法的方法签名都是无参数并返回一个T。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Callable&lt;Integer&gt; c = () -&gt; <span class="number">42</span>;</span><br><span class="line">PrevilegedAction&lt;Integer&gt; p = () -&gt; <span class="number">42</span>;</span><br></pre></td></tr></table></figure><h3 id="方法引用">方法引用</h3><p>方法引用就是让你可以重复使用现有的方法定义，并可以想Lambda表达式一样传递。</p><p>方法引用主要有三类：</p><p>（1） 只想静态方法的方法引用（如<code>Interger</code>的<code>parseInt</code>方法，写作<code>Integer::parseInt</code>）</p><p>（2） 指向任意类型实例方法的方法引用（如<code>String</code>的<code>length</code>方法，写作<code>String::length</code>）</p><p>（3） 指向现有对象的的实例方法。</p><p>方法引用可以与Lambda相对应。</p><p>（1） Lambda ——— <code>(args) -&gt; ClassName.staticMethod(args)</code></p><p>​ 方法引用 ——— <code>ClassName::staticMethod</code></p><p>（2） Lambda ——— <code>(arg0, arg1) -&gt; arg0.instanceMethod(arg1)</code></p><p>​ 方法引用 ——— <code>ClassName::instanceMethod</code></p><p>（3） Lambda ——— <code>(args) -&gt; expr.instanceMethod(args)</code></p><p>​ 方法引用 ——— <code>expr::instanceMethod</code></p><p>对于一个现有的构造函数，可以利用它的名称和关键字<code>new</code>来创建一个引用：<code>ClassName::new</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Supplier&lt;Apple&gt; s = Apple::<span class="keyword">new</span>;</span><br><span class="line">Apple a = s.get();</span><br><span class="line"></span><br><span class="line">等价于</span><br><span class="line"></span><br><span class="line">Supplier&lt;Apple&gt; s = () -&gt; <span class="keyword">new</span> Apple();</span><br><span class="line">Apple a = s.get();</span><br></pre></td></tr></table></figure><h2 id="流">流</h2><p>流简单来说就是“从支持数据处理操作的源生成的元素序列”。流操作的两个重要特点：</p><ol style="list-style-type: decimal"><li>流水线 —— 很多流操作本身会返回一个流，这样多个操作就可以链接起来，形成一个大的流水线。</li><li>内部迭代 —— 与使用迭代器显示迭代不同，流的迭代操作是在背后进行的。</li></ol><p>流中的数据只能遍历一次，遍历完后，这个流就已经被消费掉了。</p><p><code>java.util.stream.Stream</code>接口中定义了许多操作，可以大致分为两类，中间操作和终端操作。中间操作会返回另外一个流，终端操作会从流的流水线生成结果。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line"><span class="keyword">long</span> res = numbers.stream()</span><br><span class="line">    .filter(n -&gt; n &gt; <span class="number">3</span>)</span><br><span class="line">    .map(n -&gt; n * n)</span><br><span class="line">    .count();</span><br></pre></td></tr></table></figure><table><thead><tr class="header"><th>操作</th><th>类型</th><th>返回类型</th><th>函数描述符</th></tr></thead><tbody><tr class="odd"><td>filter</td><td>中间</td><td>Stream<t></t></td><td>T -&gt; boolean</td></tr><tr class="even"><td>map</td><td>中间</td><td>Stream<r></r></td><td>T -&gt; R</td></tr><tr class="odd"><td>limit</td><td>中间</td><td>Stream<t></t></td><td></td></tr><tr class="even"><td>sorted</td><td>中间</td><td>Stream<t></t></td><td>(T, T) -&gt; int</td></tr><tr class="odd"><td>distinct</td><td>中间</td><td>Stream<t></t></td><td></td></tr><tr class="even"><td></td><td></td><td></td><td></td></tr></tbody></table><table><thead><tr class="header"><th>操作</th><th>类型</th><th>目的</th></tr></thead><tbody><tr class="odd"><td>forEach</td><td>终端</td><td>消费流中的每个元素并对其应用Lambda。返回void。</td></tr><tr class="even"><td>count</td><td>终端</td><td>返回流中元素的个数。返回long。</td></tr><tr class="odd"><td>collect</td><td>终端</td><td>把流归约成一个集合，比如List、Map、Integer。</td></tr></tbody></table><h3 id="筛选和切片">筛选和切片</h3><p><code>Stream</code>接口支持<code>filter</code>，该操作会接受一个谓词（一个返回<code>boolean</code>的函数）作为参数，并返回一个包括所有符合谓词的元素的流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">List&lt;Integer&gt; odds = numbers.stream()</span><br><span class="line">    .filter(n -&gt; n % <span class="number">2</span> == <span class="number">1</span>).collect(toList());</span><br></pre></td></tr></table></figure><p><code>distinct()</code>方法会返回一个元素各异（根据流锁生成元素的<code>hashCode</code>和<code>equals</code>方法是实现）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>);</span><br><span class="line">numbers.stream().filter(i -&gt; i % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">    .distinct().forEach(System.out::println);</span><br></pre></td></tr></table></figure><p><code>limit(n)</code>方法会返回一个不超过给定长度的流，所需的长度作为参数传递给<code>limit</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>);</span><br><span class="line">numbers.stream().filter(i -&gt; i % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">    .limit(<span class="number">3</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure><p><code>skip(n)</code>方法返回一个扔掉了前n个元素的流，如果流中元素不足n个，则返回一个空流。<code>limit(n)</code>和<code>skip(n)</code>是互补的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>);</span><br><span class="line">numbers.stream().filter(i -&gt; i % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">    .skip(<span class="number">2</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure><h3 id="映射">映射</h3><p><code>map</code>方法接受一个函数作为参数，这个函数会被应用到每个元素上，并将其映射成一个新的元素，返回一个新元素的流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; words = Arrays.asList(<span class="string">"Java 8"</span>, <span class="string">"Lambdas"</span>, <span class="string">"In"</span>, <span class="string">"Actions"</span>);</span><br><span class="line">List&lt;Integer&gt; wordLengths = words.stream()</span><br><span class="line">    .map(String::length).collect(toList());</span><br></pre></td></tr></table></figure><p><code>flatMap</code>方法将一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流。简而言之，就是把流中的函数参数所产生的流中的元素提取出来后组合为一个新的流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; words = Arrays.asList(<span class="string">"Java 8"</span>, <span class="string">"Lambdas"</span>, <span class="string">"In"</span>, <span class="string">"Actions"</span>);</span><br><span class="line">List&lt;String&gt; uniqueCharacters = </span><br><span class="line">    words.stream()</span><br><span class="line">    .map(w -&gt; w.split(<span class="string">""</span>))   <span class="comment">// 返回Stream&lt;String[]&gt;</span></span><br><span class="line">    <span class="comment">// Array::stream将String[]转换为Stream&lt;String&gt;, flatMap将所                             // 有Stream中的String提取出来并合成为一个新的Stream&lt;String&gt;</span></span><br><span class="line">    .flatMap(Arrays::stream)  </span><br><span class="line">    .distinct()</span><br><span class="line">    .collect(toList())</span><br></pre></td></tr></table></figure><h3 id="查找和匹配">查找和匹配</h3><p><code>anyMatch</code>可以检查流中是否有一个元素能匹配给定的谓词。</p><p><code>allMatch</code>检查流中的元素是否都能匹配给定谓词。</p><p><code>noneMatch</code>确保流中没有任何元素与给定谓词匹配。</p><p><code>findAny</code>方法将返回当前流中的任意元素。</p><p><code>findFirst</code>方法查找流中第一个元素。</p><h3 id="归约">归约</h3><p><code>reduce</code>操作可以将流中所有元素反复结合起来，得到一个值，这样的查询操作被称为归约操作（将流归约为一个值）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 元素求和</span></span><br><span class="line"><span class="keyword">int</span> sum = numbers.stream().reduce(<span class="number">0</span>, (a ,b) -&gt; a + b);</span><br></pre></td></tr></table></figure><p><code>reduce</code>接受两个参数：</p><ol style="list-style-type: decimal"><li>一个是初始值。</li><li>一个<code>BinaryOperator&lt;T&gt;</code>来将两个元素结合起来产生一个新值。</li></ol><p><code>reduce</code>还有一个重载变体，它不接受初始值，但是会返回一个<code>Opetional</code>对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Opetional&lt;Integer&gt; sum = numbers.stream().reduce((a, b) -&gt; a + b);</span><br></pre></td></tr></table></figure><h3 id="构建流">构建流</h3><p>可直接使用静态方法<code>Stream.of</code>方法，通过显示值创建一个流，它接受任意数量的参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; stream = Stream.of(<span class="string">"Java 8"</span>, <span class="string">"Lambdas"</span>, <span class="string">"In"</span>, <span class="string">"Action"</span>);</span><br><span class="line">stream.map(String::toUpperCase).forEach(System.out::println);</span><br></pre></td></tr></table></figure><p>可以使用<code>empty</code>得到一个空流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; emptySteam = Stream.empty();</span><br></pre></td></tr></table></figure><p>可以使用静态方法<code>Arrays.stream</code>从数组创建一个流，它接受一个数组作为参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>[] numbers = &#123;<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> sum = Arrays.stream(numbers);</span><br></pre></td></tr></table></figure><p><code>Stream API</code>提供了两个静态方法来从函数生成流：<code>Stream.iterate</code>和<code>Stream.generate</code>。这两个操作可以创建无限流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Stream.iterate(<span class="number">0</span>, n -&gt; n + <span class="number">2</span>).limit(<span class="number">10</span>).forEach(System.out::println);</span><br><span class="line">Stream.generate(Math::random).limit(<span class="number">5</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure><h3 id="收集器">收集器</h3><h4 id="归约和汇总">归约和汇总</h4><p><code>Collectors.maxBy和Collectors.minBy</code>用于计算流中的最大或最小值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">Optional&lt;Integer&gt; max = numbers.stream()</span><br><span class="line">    .collect(Collectors.maxBy(Integer::compare));</span><br><span class="line">Optional&lt;Integer&gt; max = numbers.stream()</span><br><span class="line">    .collect(Collectors.minBy(Integer::compare));</span><br></pre></td></tr></table></figure><p><code>Collectors.summingInt</code>接受一个把对象映射为求和所需的<code>int</code>的函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Double&gt; doubles = Arrays.asList(<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>);</span><br><span class="line"><span class="keyword">int</span> total = doubles.stream()</span><br><span class="line">    .collect(Collectors.summingInt(d -&gt; (<span class="keyword">int</span>)d.longValue()));</span><br></pre></td></tr></table></figure><p><code>Collectors</code>还是提供了求和<code>long</code>字段的<code>summingLong</code>和求和<code>double</code>字段的<code>summingDouble</code>，还有求和平均数：<code>Collectors.averagingInt、Collectors.averagingLong和Collectors.averagingDouble</code>。<code>summarizing</code>操作可以同时求出总和、平均值、最大值和最小值，其返回类型为<code>IntSummaryStatistics</code>。</p><p><code>joinging</code>工厂方法返回的收集器会把对流中每一个对象应用<code>toString</code>方法得到的所有字符串连接成一个字符串。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String shortMenu = menu.stream().map(Dish::getName).collect(joining());</span><br></pre></td></tr></table></figure><p><code>joining</code>在内部使用了<code>StringBuilder</code>来把生成的字符串逐个追加起来。此外，如果流中元素实现了<code>toString()</code>，可以直接使用对象流执行<code>collect</code>，无需对元素进行<code>map</code>操作。<code>joining</code>工厂具有一个重载版本可以接受元素之间的分界符。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String shortMenu = menu.stream().map(Dish::getName).collect(joining(<span class="string">", "</span>));</span><br></pre></td></tr></table></figure><p>广义上的归约操作可以用<code>reducing</code>工厂方法定义，<code>reducing</code>接受3个参数。</p><p>（1）第一个参数是归约操作的起始值，页就是流中没有元素时的返回值。</p><p>（2）第二个参数就是得到归约元素的函数。</p><p>（3）第三个参数是一个<code>BinaryOperator</code>，将两个项目累积成一个同类型的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> totalCalories = menu.stream().collect(reducing(</span><br><span class="line"><span class="number">0</span>, Dish::getCalories, (i, j) -&gt; i + j));</span><br></pre></td></tr></table></figure><p>同样，<code>reducing</code>也接受单参数形式。可以版单参数<code>reducing</code>工厂方法创建的收集器看作三参数方法的特殊情况，它把流中的第一个项目作为起点，把恒等函数（即一个函数仅仅是返回其输入参数）作为一个转换函数。</p><h4 id="分组">分组</h4><p><code>Collectors.groupingBy</code>工厂方法返回的收集器可以轻松实现分组任务。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Dish.Type, List&lt;Dish&gt; dishesByType = </span><br><span class="line">    menu.stream().collect(groupingBy(Dish::getType));</span><br></pre></td></tr></table></figure><p>多级分组可以使用由双参数版本的<code>Collectors.groupingBy</code>工厂方法创建的收集器，可以接受<code>Collector</code>类型的第二个参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Dish.Type, Map&lt;CaloricLevel, List&lt;Dish&gt;&gt;&gt; dishesByTypeCaloricLevel = </span><br><span class="line">    menu.stream().collect(</span><br><span class="line">groupingBy(Dish::getType, </span><br><span class="line">                   groupingBy(dish -&gt; &#123;</span><br><span class="line">                       <span class="keyword">if</span> (dish.getCalories() &lt;= <span class="number">400</span>)</span><br><span class="line">                           <span class="keyword">return</span> CaloricLevel.DIET;</span><br><span class="line">                       <span class="keyword">else</span> <span class="keyword">if</span> (dish.getCalories() &lt;= <span class="number">700</span>)</span><br><span class="line">                           <span class="keyword">return</span> CaloricLevel.NORMAL;</span><br><span class="line">                       <span class="keyword">else</span></span><br><span class="line">                           <span class="keyword">return</span> CaloricLevel.FAT;</span><br><span class="line">                   &#125;))</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="分区">分区</h4><p>分区是分组的特殊情况：由一个谓词（返回一个布尔值的函数）作为分类函数，称为分区函数。分区函数返回一个布尔值，这意味这得到的分组<code>Map</code>的键值类型是<code>Boolean</code>，于是最多可以分为两组——<code>true</code>为一组，<code>false</code>是一组。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Boolean, List&lt;Dish&gt;&gt; partitionedMenu = </span><br><span class="line">    menu.stream().collect(partioningBy(Dish::isVegetarian));</span><br></pre></td></tr></table></figure><p><code>partitioningBy</code>工厂方法有一个重载版本，可以传递第二个收集器。</p><table><thead><tr class="header"><th>工厂方法</th><th>返回类型</th><th>用于</th></tr></thead><tbody><tr class="odd"><td><code>toList</code></td><td><code>List&lt;T&gt;</code></td><td>把流中所有项目收集到一个<code>List</code></td></tr><tr class="even"><td><code>toSet</code></td><td><code>Set&lt;T&gt;</code></td><td>把流中所有项目收集到一个<code>Set</code>，删除重复项</td></tr><tr class="odd"><td><code>toCollection</code></td><td><code>Collection&lt;T&gt;</code></td><td>把流中所有项目收集到给定的供应源创建的集合</td></tr><tr class="even"><td><code>counting</code></td><td><code>Long</code></td><td>计算流中元素的个数</td></tr><tr class="odd"><td><code>summingInt</code></td><td><code>Integer</code></td><td>对流中项目的一个整数属性求和</td></tr><tr class="even"><td><code>averagingInt</code></td><td><code>Double</code></td><td>计算流中项目<code>Integer</code>属性的平均值</td></tr><tr class="odd"><td><code>joining</code></td><td><code>String</code></td><td>连接对流中每个项目调用<code>toString</code>方法所生成的字符串</td></tr><tr class="even"><td><code>maxBy</code></td><td><code>Optional&lt;T&gt;</code></td><td>一个包裹了流中按照给定比较器选出最大元素的<code>Optional</code>，或如果流为空则为<code>Optional.empty()</code></td></tr><tr class="odd"><td><code>minBy</code></td><td><code>Optional&lt;T&gt;</code></td><td>一个包裹了流中按照给定比较器选出最小元素的<code>Optional</code>，或如果流为空则为<code>Optional.empty()</code></td></tr><tr class="even"><td><code>reducing</code></td><td>归约操作产生的类型</td><td>从一个作为累加器的初始值开始，利用<code>BinaryOperator</code>与流中的元素逐个结合，从而将流归约为单个值</td></tr><tr class="odd"><td><code>collectingAndThen</code></td><td>转换函数返回的类型</td><td>包裹另一个收集器，对其结果应用转换函数</td></tr><tr class="even"><td><code>groupingBy</code></td><td><code>Map&lt;K, List&lt;T&gt;&gt;</code></td><td>根据项目的一个属性值对流中的项目作分组，并将属性值作为结果<code>Map</code>的键</td></tr><tr class="odd"><td><code>partitioningBy</code></td><td><code>Map&lt;Boolean, List&lt;T&gt;&gt;</code></td><td>根据对流中每个项目应用谓词的结果来对项目进行分区</td></tr></tbody></table><h4 id="收集器接口">收集器接口</h4><p><code>Collector</code>接口包含了一系列方法，为实现具体的归约操作（即收集器）提供了范本。<code>Collector</code>接口定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Collector</span>&lt;<span class="title">T</span>, <span class="title">A</span>, <span class="title">R</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function">Supplier&lt;A&gt; <span class="title">supplier</span><span class="params">()</span></span>;</span><br><span class="line">    BiConfumer(A, T) accumulator();</span><br><span class="line">    <span class="function">Function&lt;A, R&gt; <span class="title">finisher</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">BinaryOperator&lt;A&gt; <span class="title">combiner</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">Set&lt;Characteristics&gt; <span class="title">characteristics</span><span class="params">()</span></span>;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中：</p><p>（1）T是流中要收集的项目的泛型。</p><p>（2）A是累加器的类型，累加器是在收集过程中用于累积部分结果的对象。</p><p>（3）R是收集操作得到的对象（通常单并不一定是集合）的类型。</p><p>理解<code>Collector</code>接口声明的方法。</p><ol style="list-style-type: decimal"><li>建立新的结果容器：<code>supplier</code>方法</li></ol><p><code>supplier</code>方法必须返回一个结果为空的<code>Supplier</code>，也就就是一个无参函数，在调用是它会创建一个空的累加器实例，供数据收集过程使用。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Supplier&lt;List&lt;T&gt;&gt; supplier() &#123;</span><br><span class="line">    <span class="keyword">return</span> ArrayList::<span class="keyword">new</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2" style="list-style-type: decimal"><li>将元素添加到结果容器：<code>accumulator</code>方法</li></ol><p><code>accumulator</code>方法会返回执行归约方法的元素。当遍历到流中第<span class="math inline">\(n\)</span>个元素时，这个函数执行时会有两个参数：保存归约结果的累加器（已收集了流中的前<span class="math inline">\(n-1\)</span>个项目），还有第<span class="math inline">\(n\)</span>个元素本身。该函数返回<code>void</code>，因为累加器是原味更新，即函数的执行改变了它的内部状态以体现遍历元素的效果。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> BiConsumer&lt;List&lt;T&gt;, T&gt; accumulator() &#123;</span><br><span class="line">    <span class="keyword">return</span> List::add;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3" style="list-style-type: decimal"><li>对结果容器应用最终转换：<code>finisher</code>方法</li></ol><p>在遍历完流后，<code>finisher</code>方法必须返回在累积过程的最后要调用的一个函数，以便将累加器对象转换为整个集合操作的最终结果。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Function&lt;List&lt;T&gt;, List&lt;T&gt;&gt; finisher() &#123;</span><br><span class="line">    <span class="keyword">return</span> Function.identity();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="4" style="list-style-type: decimal"><li>合并两个结果容器：<code>combiner</code>方法</li></ol><p><code>combiner</code>方法会返回一个供归约操作使用的函数，它定义了对流的各个子部分并行处理时，各个子部分归约所得的累加器要如何合并。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> BinaryOperator&lt;List&lt;T&gt;&gt; combiner() &#123;</span><br><span class="line">    <span class="keyword">return</span> (list1, list2) -&gt; &#123;</span><br><span class="line">        list1.addAll(list2);</span><br><span class="line">        <span class="keyword">return</span> list1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="5" style="list-style-type: decimal"><li><code>characteristic</code>方法</li></ol><p><code>characteristics</code>会返回一个不可变的<code>Characteristic</code>集合，它定义了收集器的行为——尤其是关于流是否可以并行归约，以及可以用哪些优化的体式。<code>Characteristic</code>是一个包含三个项目的枚举。</p><p><code>UNORDERED</code>——归约结果不受流中项目的遍历和累积顺序的影响。</p><p><code>CONCURRENT</code>——<code>accumulator</code>函数可以从多个线程同时调用，且该收集器可以并行归约流。</p><p><code>IDENTITY——FINISH</code>表明完成器是放回的函数是一个恒等函数，可以跳过。</p><h3 id="并行数据处理">并行数据处理</h3><h4 id="并行流">并行流</h4><p>并行流就是将内容分成多个数据块，并用不同的线程分布处理每个数据块的流。<code>parrallel</code>方法可以把顺序流变换为并行流，<code>sequential</code>可以把并行流转换为顺序流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">stream.parallel()</span><br><span class="line">      .filter(...)</span><br><span class="line">      .sequential()</span><br><span class="line">      .map(...)</span><br><span class="line">      .parallel()</span><br><span class="line">      .reduce();</span><br></pre></td></tr></table></figure><h4 id="分支合并框架">分支/合并框架</h4><p>分支/合并框架的目的是以递归方式将并行任务拆分为更小的任务，然后将每个子任务的结果合并起来生成整体结果。它是<code>ExecutorService</code>接口的一个实现，它把子任务分配给线程池（称为<code>ForkJoinPool</code>）中的工作线程。</p><p>要把任务提交到线程池，必须创建<code>RecursiveTask&lt;R&gt;</code>的一个子类，其中<code>R</code>是并行化任务（以及所有子任务）产生的结果，或者如果任务不返回结果，则是<code>RecursiveAction</code>类型（当然它可能会更新其他非局部机构）。要定义<code>RecursiveTask</code>，只需要实现它唯一的抽象方法<code>compute</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> R <span class="title">compute</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure><p>工作窃取：在实际应用中，任务差不多被平均分配到<code>ForkJoinPool</code>中的所有线程上。每个线程都为分配给它的任务保持一个双向队列，每完成一个任务，就会从队列头上取下一个任务开始执行。当有线程很早就完成了分配的所有任务，就开始随机选择一个别的线程，从队尾取下一个任务执行。</p><h4 id="spliterator"><code>Spliterator</code></h4><p><code>Spliterator</code>接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Spliterator</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">tryAdvance</span><span class="params">(Consumer&lt;? <span class="keyword">super</span> T&gt; action)</span></span>;</span><br><span class="line">    <span class="function">Spliterator&lt;T&gt; <span class="title">trySplit</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">estimateSize</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">characteristics</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>tryAdvance</code>方法会顺序使用<code>Spliterator</code>中的元素。<code>trySplit</code>可以将一些元素划分出去分给第二个<code>Spliterator</code>（由该方法返回），让它们两个并行处理。<code>estimateSize</code>方法估计还剩下多少元素要遍历。<code>characteristics</code>方法将返回一个int，代表<code>Spliterator</code>本身特性集的编码。</p><p><code>spliterator</code>的特性</p><table><thead><tr class="header"><th>特性</th><th>含义</th></tr></thead><tbody><tr class="odd"><td><code>ORDERED</code></td><td>元素有既定的顺序（例如List），因此<code>Spliterator</code>在遍历和划分式也会遵循这一顺序</td></tr><tr class="even"><td><code>DISTINCT</code></td><td>对于任意一对遍历过的元素x和y，<code>x.equals(y)</code>返回false</td></tr><tr class="odd"><td><code>SORTED</code></td><td>遍历的元素安装一定的预定义的顺序排序</td></tr><tr class="even"><td><code>SIEZED</code></td><td>该<code>Spliterator</code>由一个已知大小的源建立（例如<code>Set</code>），因此，<code>estimateSize()</code>返回的是准确值</td></tr><tr class="odd"><td><code>NONNULL</code></td><td>保证遍历的元素不会为<code>null</code></td></tr><tr class="even"><td><code>IMMUTABLE</code></td><td><code>Spliterator</code>的数据源不能修改，这意味这在遍历时不能添加、删除或修改任何元素</td></tr><tr class="odd"><td><code>CONCURRENT</code></td><td>该<code>Spliterator</code>的数据源可以被其他线程同时修改和无需 同步</td></tr><tr class="even"><td><code>SUBSIZED</code></td><td>该<code>Spliterator</code>和所有从它拆分处理的<code>Spliterator</code>都是<code>SIZED</code></td></tr></tbody></table><h2 id="默认方法">默认方法</h2><p>默认方法由<code>default</code>修饰符修饰，并像类中声明的其他方法一样包含方法体。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Sized</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> size() == <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时<code>implements</code>多个接口时冲突解决的方法：</p><ol style="list-style-type: decimal"><li>类中的方法优先级最高，类或父类中声明的方法的优先级高于任何声明为默认方法的优先级。</li><li>如果无法依据第一条件进行判断，那么子接口的优先级更高：函数签名相同时，优先选择拥有最具体的默认方法的接口，即如果B继承了A，那么B就比A更加具体。</li><li>最后，如果还是无法判断，继承了多个接口的类必须通过显示覆盖和调用期望的方法。</li></ol><h2 id="optional">Optional</h2><p>变量存在时，<code>Optional</code>类只是对类简单封装。变量不存在时，缺失值会被建模成一个“空”的<code>Optional</code>对象，有方法<code>Optional.empty()</code>返回。<code>Optional.emtpy()</code>方法是一个静态工厂方法，它返回<code>Optional</code>类的特定单一实例。<code>Optional</code>对象可执行与流类似的操作，如<code>filter、map、flatMap</code>等。</p><p><code>Optional</code>类的方法</p><table><thead><tr class="header"><th>方法</th><th>描述</th></tr></thead><tbody><tr class="odd"><td><code>empty</code></td><td>返回一个空的<code>Optional</code>实例</td></tr><tr class="even"><td><code>filter</code></td><td>如果值存在并且满足提供的谓词，就放回包含该值的<code>Optional</code>对象；否则返回一个空的<code>Optional</code>对象</td></tr><tr class="odd"><td><code>flatMap</code></td><td>如果值存在，就对该值执行提供的mapping函数，返回一个<code>Optional</code>类型的值，否则返回一个空的<code>Optional</code>对象</td></tr><tr class="even"><td><code>get</code></td><td>如果该值存在，将该值用<code>Optional</code>封装返回，否则抛出一个<code>NoSuchElementException</code>异常</td></tr><tr class="odd"><td><code>ifPresent</code></td><td>如果值存在，就执行使用该值的方法调用，否则什么也不做</td></tr><tr class="even"><td><code>isPresent</code></td><td>如果值存在就返回true，否则返回false</td></tr><tr class="odd"><td><code>map</code></td><td>如果值存在，就对该值执行mapping操作</td></tr><tr class="even"><td><code>of</code></td><td>将指定值用<code>Optional</code>封装之后返回，如果该值为null，则抛出一个<code>NullPointerException</code>异常</td></tr><tr class="odd"><td><code>ofNullable</code></td><td>将指定值用<code>Optional</code>封装之后返回，如果该值为null，则返回一个空的<code>Optional</code>对象</td></tr><tr class="even"><td><code>orElse</code></td><td>如果有值就将其返回，否则返回一个默认值</td></tr><tr class="odd"><td><code>orElseGet</code></td><td>如果有值则将其返回，否则返回一个由指定的<code>Supplier</code>接口生成的值</td></tr><tr class="even"><td><code>orElseThrow</code></td><td>如果有值则将其返回，否则抛出一个有指定的<code>Supplier</code>接口生成的异常</td></tr></tbody></table><h2 id="组合式异步编程">组合式异步编程</h2><h3 id="future"><code>Future</code></h3><p><code>Future</code>的设计初衷是对将来某个时刻会发生的结果进行建模，它建模了一种异步计算，返回一个执行运输结果的引用，当运算结束后，这个引用被返回给调用方。要使用<code>Future</code>，只需要将耗时的操作封装在一个<code>Callalbe</code>对象中，再将它提交给<code>ExecutorService</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService executor = Executors.newCachedThreadPool();</span><br><span class="line">Future&lt;Double&gt; future = executor.submit(<span class="keyword">new</span> Callable&lt;Double&gt; &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Double <span class="title">call</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> doSomeLongComputation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">doSomethingElse();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    Double result = future.get(<span class="number">1</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125; <span class="keyword">catch</span>(ExecutionException ee) &#123;</span><br><span class="line">    <span class="comment">// 计算抛出一个异常</span></span><br><span class="line">&#125; <span class="keyword">catch</span>(InterruptedException ie) &#123;</span><br><span class="line">    <span class="comment">// 当前线程在等待过程中被中断</span></span><br><span class="line">&#125; <span class="keyword">catch</span>(TimeoutException te) &#123;</span><br><span class="line">    <span class="comment">// 在Future对象完成之前超过已过期</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="completablefuture"><code>CompletableFuture</code></h3><p><code>complete</code>方法可以结束<code>CompletableFuture</code>对象的运行，并设置变量的值。</p><p><code>CompletableFuture</code>提供的工厂方法<code>supplyAsync</code>创建<code>CompletableFuture</code>对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;Double&gt; <span class="title">getPriceAsync</span><span class="params">(String product)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.supplyAsync(() -&gt; calculaterPrice(product));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>supplyAsync</code>方法接受一个生成者（Supplier）作为参数，返回一个<code>CompletableFuture</code>对象，该对象完成异步执行后会读取调用生产者方法的返回值。生产者方法会交由<code>ForkJoinPool</code>池中的某个执行线程（<code>Executor</code>）运行。</p><h2 id="时间和日期">时间和日期</h2><p>java8提供了新的时间和日期库。</p><p><code>LocalDate</code>只提供了简单的日期，不包含当天的时间信息，也不附带任何与时区相关的信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">LocalDate date = localDate.of(<span class="number">2014</span>, <span class="number">3</span>, <span class="number">18</span>);</span><br><span class="line"><span class="keyword">int</span> year = date.getYear();</span><br><span class="line">Month month = daet.getMonth();</span><br><span class="line"><span class="keyword">int</span> day = date.getDayOfMonth();</span><br><span class="line">DayOfWeek dow = date.getDayOfWeek();</span><br><span class="line"><span class="keyword">int</span> len = date.lengthOfMonth();</span><br><span class="line"><span class="keyword">boolean</span> leap = date.isLeapYear();</span><br><span class="line"></span><br><span class="line">LocalDate today = LocalDate.now();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用TemporalField读取LocalDate的值</span></span><br><span class="line"><span class="keyword">int</span> year = date.get(ChronoField.YEAR);</span><br><span class="line"><span class="keyword">int</span> month = date.get(ChronoField.MONTH_OF_YEAR);</span><br><span class="line"><span class="keyword">int</span> day = date.get(ChronoFiled.DAY_OF_MONTH);</span><br></pre></td></tr></table></figure><p><code>LocalTime</code>类表示一天中的时间，比如<code>13:45:20</code>。可以使用<code>of</code>重载的两个工厂方法创建<code>LocalTime</code>的实例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">LocalTime time = LocalTime.of(<span class="number">13</span>,<span class="number">45.20</span>);</span><br><span class="line"><span class="keyword">int</span> hour = time.getHour();</span><br><span class="line"><span class="keyword">int</span> minute = time.getMinute();</span><br><span class="line"><span class="keyword">int</span> second = time.getSecond();</span><br><span class="line"></span><br><span class="line">LocalDate date = LocalDate.parse(<span class="string">"2014-03-18"</span>);</span><br><span class="line">LocalTime time = LocalTime.parse(<span class="string">"13:45:20"</span>);</span><br></pre></td></tr></table></figure><p>可以向<code>parse</code>方法传递一个<code>DateTimeFormatter</code>，该类的实例定义了如何格式化一个日期或时间对象。</p><p><code>LocalDateTime</code>是<code>LocalDate</code>和<code>LocalTime</code>的合体。它同时表示了日期和时间，但不带有时区信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">LocalDateTime dt1 = LocalDateTime.of(<span class="number">2014</span>, Month.MARCH, <span class="number">18</span>, <span class="number">13</span>, <span class="number">45</span>, <span class="number">20</span>);</span><br><span class="line">LocalDateTime dt2 = LocalDateTime.of(date, time);</span><br><span class="line">LocalDateTime dt3 = date.atTime(<span class="number">13</span>, <span class="number">45</span>, <span class="number">20</span>);</span><br><span class="line">LocalDateTime dt4 = date.atTime(time);</span><br><span class="line">LocalDateTime dt5 = time.atDate(date);</span><br><span class="line"></span><br><span class="line">LocalDate date1 = dt1.toLocalDate();</span><br><span class="line">LocalTime time2 = dt1.toLocalTime();</span><br></pre></td></tr></table></figure><p><code>Instant</code>是以Unix元年时间（传统的设定为UTC时区1970-1-1:00:00:00）开始所经历的秒数建模。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Instant.ofEpochSecond(<span class="number">3</span>);</span><br><span class="line">Instant.ofEpochSecond(<span class="number">3</span>, <span class="number">0</span>);</span><br><span class="line">Instant.ofEpochSecond(<span class="number">2</span>, <span class="number">1_000_000_000</span>);</span><br><span class="line">Instant.ofEpochSecond(<span class="number">4</span>, -<span class="number">1_000_000_000</span>);</span><br></pre></td></tr></table></figure><p>可以通过<code>Duration</code>和<code>Period</code>使用<code>Instant</code>。</p><p><code>Temporal</code>接口定义了如何读取和操纵为时间建模的对象的值。</p><p><code>Duration</code>主要以秒和纳秒衡量时间的长短。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Duration d1 = Duration.between(time1, time2);</span><br><span class="line">Duration d2 = Duration.between(dateTime1, dateTime2);</span><br><span class="line">Duration d3 = Duration.between(instant1, instant2);</span><br></pre></td></tr></table></figure><p><code>Period</code>以年、月或日的方式对时间单位建模。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Period tenDays = Period.between(LocalDate.of(<span class="number">2014</span>, <span class="number">3</span>, <span class="number">8</span>),</span><br><span class="line">                               LocalDate.of(<span class="number">2014</span>, <span class="number">3</span>, <span class="number">18</span>));</span><br></pre></td></tr></table></figure><p>创建<code>Duration</code>和<code>Period</code>对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Duration threeMiniutes = Duration.ofMinutes(<span class="number">3</span>);</span><br><span class="line">Duration threeMinutes = Duration.of(<span class="number">3</span>, ChronoUnit.MINUTES);</span><br><span class="line"></span><br><span class="line">Period tenDays = Period.ofDays(<span class="number">10</span>);</span><br><span class="line">Period threeWeeks = PeriodofWeeks(<span class="number">3</span>);</span><br><span class="line">Period twoYearsSixMonthsOneDay = Period(<span class="number">2</span>, <span class="number">6</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p><code>DateTimeFormatter</code>类用于解析日期-时间对象。创建日期格式最简单的方法是通过它的静态工厂方法以及常量。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">LocalDate date = LocalDate.of(<span class="number">2014</span>, <span class="number">3</span>, <span class="number">18</span>);</span><br><span class="line">String s1 = date.format(DateTimeFormatter.BASIC_ISO_DATE); <span class="comment">// 20140318</span></span><br><span class="line">String s2 = date.format(DateTimeFormatter.ISO_LOCAL_DATE); <span class="comment">// 2014-03-18</span></span><br><span class="line"></span><br><span class="line">LocalDate date1 = LocalDate.parse(<span class="string">"20140318"</span>, </span><br><span class="line">                                 DateTimeFormatter.BASIC_ISO_DATE);</span><br><span class="line">LocalDate date2 = LocalDate.parse(<span class="string">"2014-03-18"</span>,</span><br><span class="line">                                 DateTimeFormatter.ISO_LOCAL_DATE);</span><br></pre></td></tr></table></figure><p>创建<code>DateTimeFormatter</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DateTimeFormatter formatter = DateTimeFormatter.ofPattern(<span class="string">"dd/MM/yyyy"</span>);</span><br><span class="line">LocalDate date1 = LocalDate.of(<span class="number">2014</span>, <span class="number">3</span>, <span class="number">18</span>);</span><br><span class="line">String formattedDate = date1.format(formatter);</span><br><span class="line">LocalDate date2 = LocalDate.parse(formattedDate, formatter);</span><br><span class="line"></span><br><span class="line">DateTimeFormatter italianFormatter = </span><br><span class="line">    DateTimeFormatter.ofPattern(<span class="string">"d. MMMM yyyy"</span>, Locale.ITALIAN);</span><br><span class="line">LocalDate date3 = LocalDate.of(<span class="number">2014</span>, <span class="number">3</span>, <span class="number">18</span>);</span><br><span class="line">String formattedDate2 = date3.format(italianFormatter);</span><br><span class="line">LocalDate date4 = LocalDate.parse(formattedDate2, italianFormatter);</span><br></pre></td></tr></table></figure><p>参考 《java 8 实战》</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;java-8-新特性&quot;&gt;Java 8 新特性&lt;/h1&gt;
&lt;h2 id=&quot;lambda表达式&quot;&gt;Lambda表达式&lt;/h2&gt;
&lt;p&gt;lambda表达式可理解为简洁地表示可传递的匿名函数的一种方式：没有名称，有参数列表、函数主体、返回类型。&lt;/p&gt;
&lt;p&gt;lam
      
    
    </summary>
    
      <category term="java" scheme="https://mejhwu.github.io/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="https://mejhwu.github.io/2018/06/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://mejhwu.github.io/2018/06/27/机器学习/神经网络/</id>
    <published>2018-06-27T12:41:46.000Z</published>
    <updated>2018-06-28T03:56:14.926Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络">神经网络</h1><h2 id="神经元模型">神经元模型</h2><p>神经网络中最基本的单元是神经元，类似与生物神经网络中的神经元，当某个神经元的的点位超过某个“阈值”时，那么它被激活并像其他神经元发送信号。</p><p>神经元模型中，神经元接受<span class="math inline">\(n\)</span>个其他神经元传递来的信号，这些信号通过带权重的连接进行传递，神经元接受到的总输入值与阈值进行比较，然后通过激活函数处理产生神经元输出。</p><p>常用的激活函数为<span class="math inline">\(sigmoid(x)\)</span>函数。</p><p><span class="math display">\[sigmoid(x)=\frac{1}{1+e^{-x}}\]</span></p><h2 id="感知机与多层网络">感知机与多层网络</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;神经网络&quot;&gt;神经网络&lt;/h1&gt;
&lt;h2 id=&quot;神经元模型&quot;&gt;神经元模型&lt;/h2&gt;
&lt;p&gt;神经网络中最基本的单元是神经元，类似与生物神经网络中的神经元，当某个神经元的的点位超过某个“阈值”时，那么它被激活并像其他神经元发送信号。&lt;/p&gt;
&lt;p&gt;神经元模型中，神经元
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://mejhwu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>决策树</title>
    <link href="https://mejhwu.github.io/2018/06/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    <id>https://mejhwu.github.io/2018/06/27/机器学习/决策树/</id>
    <published>2018-06-26T16:00:00.000Z</published>
    <updated>2018-09-05T14:19:36.543Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树">决策树</h1><h2 id="基本概念">1. 基本概念</h2><p>决策树是一种常见的机器学习方法,一般一棵决策树为一颗多叉树. 每一个叶子节点就对应于一个决策结果.决策树的生成过程类似于数据结构中的树的生成过程.</p><hr><p>输入:</p><p>训练集<span class="math inline">\(D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\)</span></p><p>属性集<span class="math inline">\(A=\{a_1,a_2,...,a_d\}\)</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">西瓜书基本算法:</span><br><span class="line">过程: 函数TreeGenerate(D, A)</span><br><span class="line">生成节点node</span><br><span class="line"><span class="keyword">if</span> D中样本全属于同一类别C then</span><br><span class="line">    将node标记为C类叶节点; <span class="keyword">return</span></span><br><span class="line">end <span class="keyword">if</span></span><br><span class="line"><span class="keyword">if</span> A为空 OR D中样本在A上的取值相同 then</span><br><span class="line">    将node标记为叶节点,其分类标记为D中样本数最多的类; <span class="keyword">return</span></span><br><span class="line">end <span class="keyword">if</span></span><br><span class="line">从A中选择最优的划分属性a;</span><br><span class="line"><span class="keyword">for</span> a 的每一个值av do</span><br><span class="line">    为node生成一个分支;令Dv表示D中在a上取值为av的样本集;</span><br><span class="line">    <span class="keyword">if</span> Dv 为空 then</span><br><span class="line">        将分支标记为叶节点,其类别标记为D中样本最多的类; <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        以TreeGenerate(Dv, A-&#123;a*&#125;)为分支节点</span><br><span class="line">    end <span class="keyword">if</span></span><br><span class="line">end <span class="keyword">for</span></span><br></pre></td></tr></table></figure><p>输出: 以node为根节点的一颗决策树 ________________________________________</p><p>以下为python代码的伪代码, 参考&lt;<机器学习实战>&gt;</机器学习实战></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(data_set, labels)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> D中样本全输入同一类别C:</span><br><span class="line">        <span class="keyword">return</span> 类别C</span><br><span class="line">    <span class="keyword">if</span> A为空:</span><br><span class="line">        <span class="keyword">return</span> D中样本数最多的类</span><br><span class="line">    从A中选取最优划分属性a</span><br><span class="line">    node = &#123;label: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> a的每一个属性值av:</span><br><span class="line">        node[label][av] = &#123;&#125;</span><br><span class="line">        令Dv表示D在属性a上取值av的样本子集</span><br><span class="line">        <span class="keyword">if</span> Dv为空:</span><br><span class="line">            node[label][av] = D中样本最多的类</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            node[label][av] = create_tree(Dv, labels)</span><br><span class="line">    <span class="keyword">return</span> node</span><br></pre></td></tr></table></figure><p>在&lt;<西瓜书>&gt;中有三种情况导致递归返回:(1)当前节点包含的样本全属于同一类别, 无需划分;(2)当前属性集为空,或是所有样本在所有属性上取值相同,无法划分;(3)当前节点包含的样本集合为空,不能划分</西瓜书></p><p>在&lt;<机器学习实战>&gt;没有判断&quot;所有样本在所有属性上取值相同&quot;这个条件,个人认为原因有两个: 其一, 判断的难度比较大,代码复杂,耗费时间长; 其二, 在满足条件&quot;所有样本在所有属性上取值相同&quot;这个条件时, 其所有样本类别有很大概率是属于同一类, 再者继续训练也只会形成一个单叉树.</机器学习实战></p><h2 id="划分选择">2. 划分选择</h2><p>在以上的算法流程中,最重要的步骤就是在属性集A中选择最优的划分属性a, 一般在划分的过程中,希望划分出来的样本子集尽量属于同一类别, 即节点的&quot;纯度&quot;越来越高.</p><h3 id="信息增益">2.1 信息增益</h3><p><a href="https://zh.wikipedia.org/wiki/%E7%86%B5_%E4%BF%A1%E6%81%AF%E8%AE%BA" target="_blank" rel="noopener">&quot;信息熵&quot;</a>是度量样本集合纯度最常用的一种指标. 假定当前样本集合D中第<span class="math inline">\(k\)</span>类样本的比例为<span class="math inline">\(p_k(k=1,2,...,|\mathcal{Y}|)\)</span>, 则<span class="math inline">\(D\)</span>的信息熵定义为</p><p><span class="math display">\[Ent(D)= \sum ^{|\mathcal{Y}|}_{k=1}p_klog_2p_k\]</span></p><p><span class="math inline">\(Ent(D)\)</span>的值越小,则<span class="math inline">\(D\)</span>的纯度越高.</p><p>计算信息熵时约定:若<span class="math inline">\(p=0\)</span>, 则<span class="math inline">\(plog_2p=0\)</span>. <span class="math inline">\(Ent(D)\)</span>的最小值为0,最大值为<span class="math inline">\(log_2|\mathcal{Y}|\)</span></p><p>下面给出信息增益的计算公式</p><p><span class="math display">\[Gain(D, a)=Ent(D)- \sum ^V_{v=1} \frac {|D|}{|D^v|}Ent(D^v)\]</span></p><p><span class="math inline">\(V\{a^1,a^2,...,a^v\}\)</span>为属性<span class="math inline">\(a\)</span>的属性值集合; <span class="math inline">\(D^v\)</span>为使用属性<span class="math inline">\(a\)</span>在<span class="math inline">\(D\)</span>中进行划分,<span class="math inline">\(D\)</span>中属性<span class="math inline">\(a\)</span>的属性值为<span class="math inline">\(a^v\)</span>的样本子集; <span class="math inline">\(\frac{|D|}{|D^v|}\)</span>为每个分支节点上的权重.</p><p>一般而言, 信息增益越大, 则意味着使用属性<span class="math inline">\(a\)</span>来进行划分所获得的&quot;纯度提升&quot;越大. 所有在算法中选择属性<span class="math inline">\(a_*=arg_{a \in A} maxGain(D, a)\)</span></p><p>python代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain.py" target="_blank" rel="noopener">tree_gain.py</a></p><h3 id="增益率">2.2 增益率</h3><p>信息增益准则对可取值较多的属性有所偏好,为减少这种偏好可能带来的不利影响,可使用&quot;增益率&quot;来选择最优划分属性, 增益率定义为</p><p><span class="math display">\[Gain_ratio(D,a)=\frac{Grain(D,a)}{IV(a)}\]</span></p><p>其中</p><p><span class="math display">\[IV(a)=-\sum_{v=1}^{V}\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}\]</span></p><p><span class="math inline">\(IV(a)\)</span>称为属性<span class="math inline">\(a\)</span>的&quot;固有值&quot;(intrinsic value). 属性<span class="math inline">\(a\)</span>的可能取值数目越多(即V越大), 则<span class="math inline">\(IV(a)\)</span>的值通常会越大.</p><p>需要注意的是, 增益率准则对可取值数目较少的属性所有偏好, 因此根据C4.5算法, 可先从候选划分属性中找出信息增益高于平均水平的属性,再从中选择增益率最高的.</p><p>python代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain_ratio.py" target="_blank" rel="noopener">tree_gain_ratio.py</a></p><h3 id="基尼指数">2.3 基尼指数</h3><p>CART决策树使用&quot;基尼指数&quot;(Gini index)来选择划分属性. 数据集<span class="math inline">\(D\)</span>的纯度可以用基尼值来度量:</p><p><span class="math display">\[Gini(D)=\sum_{k=1}^{|\mathcal{Y}|}\sum_{k{&#39;}\ne k}p_kp_{k^{&#39;}}=1-\sum_{k=1}^{|\mathcal{Y}|}p_k^2\]</span></p><p>直观来说,<span class="math inline">\(Gini(D)\)</span>反映了从数据集<span class="math inline">\(D\)</span>中随机抽取两个样本,其类别不一致的概率. 因此, <span class="math inline">\(Gini(D)\)</span>越小, 则数据集<span class="math inline">\(D\)</span>的纯度越高.</p><p>属性<span class="math inline">\(a\)</span>的基尼指数定义为</p><p><span class="math display">\[Gini\_index(D,a)=\sum_{k=1}^{|\mathcal{Y}|}\frac{|D^v|}{|D|}Gini(D^v)\]</span></p><p>于是,在候选属性集<span class="math inline">\(A\)</span>中选取使划分后基尼指数最小的属性作为最优划分属性,即<span class="math inline">\(a_*=arg_{a\in A}min\ Gini\_index(D,a)\)</span></p><p>python代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gini.py" target="_blank" rel="noopener">tree_gini.py</a></p><h2 id="剪枝处理">3. 剪枝处理</h2><p>剪枝(pruning)是决策树学习算法中对付&quot;过拟合&quot;的主要手段. 决策树剪枝的基本策略有&quot;预剪枝&quot;(prepruning)和&quot;后剪枝&quot;(postpruning).</p><h3 id="预剪枝">3.1 预剪枝</h3><p>预剪枝是指在决策树生成过程中,对每个节点在划分前先进行估计, 若当前节点的划分不能带来决策树泛化性能提升, 则停止划分并讲当前节点标记为页节点.</p><p>预剪枝的决策树生成过程类似于二叉树的先序遍历, 划分前先进行判断是否剪枝, 如果不需要剪枝再生成下一个节点.</p><p>预剪枝基于&quot;贪心&quot;本质禁止这些分支展开,给预剪枝决策树带来了欠拟合的风险.</p><p>预剪枝python伪代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verity_divide</span><span class="params">(train_data_set, train_data_set)</span>:</span></span><br><span class="line">    <span class="comment"># 验证集为空不进行划分</span></span><br><span class="line">    <span class="keyword">if</span> 验证集为空:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    选取最优划分属性a</span><br><span class="line">    划分后节点divide_node = &#123;a: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> a的每一个属性值av:</span><br><span class="line">        令TDv表示训练样本train_data_set中属性a上取值为av的样本子集</span><br><span class="line">        divide_node[a][av] = TDv中类别最多的类</span><br><span class="line">    divide_count表示划分后验证的正确数量</span><br><span class="line">    <span class="keyword">for</span> train_data_set中的每一个样本:</span><br><span class="line">        <span class="keyword">if</span> 验证正确:</span><br><span class="line">            divide_cout += <span class="number">1</span></span><br><span class="line">    not_divide_count表示train_data_set中样本最多的类的数量</span><br><span class="line">    <span class="keyword">if</span> divide_count &gt; not_divide_count:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(train_data_set, verity_data_set, labels)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> train_data_set中样本全输入同一类别C:</span><br><span class="line">        <span class="keyword">return</span> 类别C</span><br><span class="line">    <span class="keyword">if</span> A为空:</span><br><span class="line">        <span class="keyword">return</span> train_data_set中样本数最多的类</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> verity_divide(train_data_set, verity_data_set):</span><br><span class="line">        <span class="keyword">return</span> D中样本最多的类</span><br><span class="line">    <span class="comment"># 此处可优化, 可先获取最优属性后传入verity_divide()</span></span><br><span class="line">    从A中选取最优划分属性a</span><br><span class="line">    node = &#123;label: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> a的每一个属性值av:</span><br><span class="line">        node[label][av] = &#123;&#125;</span><br><span class="line">        令TDv表示train_data_set在属性a上取值av的样本子集</span><br><span class="line">        令TVv表示verity_data_set在属性a上取值为av的样本子集</span><br><span class="line">        <span class="keyword">if</span> TDv为空:</span><br><span class="line">            node[label][av] = train_data_set中样本最多的类</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            node[label][av] = create_tree(TDv, TVv,  labels)</span><br><span class="line">    <span class="keyword">return</span> node</span><br></pre></td></tr></table></figure><p>完整代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain_prepruning.py" target="_blank" rel="noopener">tree_gain_prepruning.py</a></p><h3 id="后剪枝">3.2 后剪枝</h3><p>后剪枝是先从训练集生成一颗完整的决策树, 然后自底向上地对非叶子节点进行考察, 若将该节点对应的子树替换为叶节点能带来决策树的泛化性能提升,则将该子树替换为叶节点.</p><p>后剪枝决策树的生成过程类似于二叉树的后续遍历; 即先生成决策树, 在判断是否需要剪枝, 如果需要剪枝则放弃子树, 直接将节点标记为叶节点.</p><p>后剪枝的过程是在完全决策树之后进行的,并且要自底向上地对决策树中的所有非叶节点进行逐一考察, 因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多.</p><p>后剪枝python伪代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verity_divide</span><span class="params">(tree, train_data_set, verity_data_set)</span>:</span></span><br><span class="line">    <span class="comment"># 验证集为空不剪枝</span></span><br><span class="line">    <span class="keyword">if</span> 验证集为空:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    not_divide_right_rate = 不划分的验证正确率</span><br><span class="line">    divide_right_rate = 划分后的验证正确率</span><br><span class="line">    <span class="comment"># 不划分的验证正确率大于划分的验证正确率时剪枝</span></span><br><span class="line">    <span class="keyword">if</span> not_divide_right_rate &gt; divide_right_rate:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(train_data_set, verity_data_set, labels)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> train_data_set中样本全输入同一类别C:</span><br><span class="line">        <span class="keyword">return</span> 类别C</span><br><span class="line">    <span class="keyword">if</span> A为空:</span><br><span class="line">        <span class="keyword">return</span> train_data_set中样本数最多的类</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> verity_divide(train_data_set, verity_data_set):</span><br><span class="line">        <span class="keyword">return</span> train_data_set中样本最多的类</span><br><span class="line">    从A中选取最优划分属性a</span><br><span class="line">    node = &#123;label: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> a的每一个属性值av:</span><br><span class="line">        node[label][av] = &#123;&#125;</span><br><span class="line">        令TDv表示train_data_set在属性a上取值av的样本子集</span><br><span class="line">        令TVv表示verity_data_set在属性a上取值av的样本子集</span><br><span class="line">        <span class="keyword">if</span> TDv为空:</span><br><span class="line">            node[label][av] = train_data_set中样本最多的类</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            node[label][av] = create_tree(TDv, TVv, labels)</span><br><span class="line">    <span class="keyword">if</span> verity_divide(node, train_data_set, verity_data_set):</span><br><span class="line">        node = train_data_set中样本最多的类</span><br><span class="line">    <span class="keyword">return</span> node</span><br></pre></td></tr></table></figure><p>完整代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain_postpruning.py" target="_blank" rel="noopener">tree_gain_postpruning</a></p><h2 id="连续与缺失值">4. 连续与缺失值</h2><h3 id="连续值处理">4.1 连续值处理</h3><p>由于连续属性的可取值数目不再有限, 因此,不能直接根据连续属性的可取值来对节点进行划分, 需要将连续属性离散化, 最简单的策略是采用二分法对连续属性进行处理.</p><p>给定样本集<span class="math inline">\(D\)</span>和连续属性<span class="math inline">\(a\)</span>, 假定<span class="math inline">\(a\)</span>在<span class="math inline">\(D\)</span>上出现了n个不同的取值, 将这些值从小到大进行排序, 记为<span class="math inline">\(\{a^1,a^1,...,a^n\}\)</span>. 基于划分点<span class="math inline">\(t\)</span>可将D分为子集<span class="math inline">\(D_t^-\)</span>和<span class="math inline">\(D_t^+\)</span>, 其中<span class="math inline">\(D_t^-\)</span>包含那行属性a上取值不大于t的样本, 而<span class="math inline">\(D_t^+\)</span>则包含那些在属性<span class="math inline">\(a\)</span>上取值大于<span class="math inline">\(t\)</span>的样本. 显然, 对相邻的属性取值<span class="math inline">\(a^i\)</span>和<span class="math inline">\(a^{i+1}\)</span>来说, <span class="math inline">\(t\)</span>在区间<span class="math inline">\([a^i,a^{i+1})\)</span>中取任何值产生的划分结果相同. 因此, 对连续属性<span class="math inline">\(a\)</span>, 我们可考察包含<span class="math inline">\(n-1\)</span>个元素的候选划分点集合</p><p><span class="math display">\[T_a=\{\frac{a^i+a^{i+1}}{2}|i\le i\le n-1|\}\]</span></p><p>即把区间<span class="math inline">\([a^i,a^{i+1})\)</span>的中位点<span class="math inline">\(\frac{a^i+a^{i+1}}{2}\)</span>作为候选划分点. 然后就可像离散属性一样来考察这些划分点, 选取最优的划分点进行样本集合的划分.</p><p><span class="math display">\[Gain(D,a)=\max\limits_{t\in T_a} Ent(D) - \sum_{\lambda\in \{-,+\}} \frac{|D|}{|D_t^\lambda|}Ent(D_t^\lambda)\]</span></p><p>其中<span class="math inline">\(Gain(D,a,t)\)</span>是样本集<span class="math inline">\(D\)</span>基于划分点<span class="math inline">\(t\)</span>二分后的信息增益. 于是,可选择<span class="math inline">\(Gain(D,a,t)\)</span>最大化的划分点.</p><p>需要注意, 与离散值不同, 若当前节点划分属性为连续属性, 连续属性还可作为其后代节点的划分属性.</p><p>在写代码的时候需要注意在离散属性和连续属性的<span class="math inline">\(gain(D,a)\)</span>时需要分开处理. 在构建决策树时, 离散属性和连续属性也需要分开处理, 因为划分连续属性时,不需要在数据集中去除连续属性.</p><p>完整python代码<a href="https://github.com/mejhwu/machine_learning/blob/master/decision_tree/tree_gain_continuous_value.py" target="_blank" rel="noopener">tree_gain_continuous_value.py</a></p><h3 id="缺失值处理">4.2 缺失值处理</h3><p>面对缺失值需要解决的两个问题: (1)如何在属性值缺失的情况下进行划分属性选择? (2)给定划分属性,若样本在改属性上的值缺失,如何对样本进行划分?</p><p>给定训练集<span class="math inline">\(D\)</span>和属性<span class="math inline">\(a\)</span>, 令<span class="math inline">\(\tilde{D}\)</span>表示<span class="math inline">\(D\)</span>中在属性<span class="math inline">\(a\)</span>上没有缺失值的样本子集. 对问题(1), 显然仅可根据<span class="math inline">\(\tilde{D}\)</span>来判断属性<span class="math inline">\(a\)</span>的优劣. 假定属性<span class="math inline">\(a\)</span>有<span class="math inline">\(V\)</span>个可取值<span class="math inline">\(\{a^1,a^2,...,a^V\}\)</span>, 令<span class="math inline">\(\tilde{D}^v\)</span>表示<span class="math inline">\(\tilde{D}\)</span>在属性<span class="math inline">\(a\)</span>上的取值为<span class="math inline">\(a^v\)</span>的样本子集, <span class="math inline">\(\tilde{D}_k\)</span>表示<span class="math inline">\(\tilde{D}\)</span>属性第<span class="math inline">\(k\)</span>类<span class="math inline">\((k=1,2,...,|\mathcal{Y}|)\)</span>的样本子集, 则显然有<span class="math inline">\(\tilde{D}=\cup_{k=1}^{|\mathcal{Y}|}\tilde{D}_k\)</span>, <span class="math inline">\(\tilde{D}=\cup_{v=1}^V\tilde{D}^v\)</span>. 假定我们为每个样本<span class="math inline">\(\boldsymbol{x}\)</span>赋予一个权重<span class="math inline">\(w_{\boldsymbol{x}}\)</span>, 并定义</p><p><span class="math display">\[\rho=\frac{\sum_{\boldsymbol{x}\in \tilde{D}}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in D}w_{\boldsymbol{x}}}\]</span></p><p><span class="math display">\[\tilde{p}_k=\frac{\sum_{\boldsymbol{x}\in \tilde{D}_k}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in \tilde{D}}w_{\boldsymbol{x}}} \ \ \ \ \ (1\le k\le |\mathcal{Y}|)\]</span></p><p><span class="math display">\[\tilde{r}_v=\frac{\sum_{\boldsymbol{x}\in \tilde{D}^v}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in \tilde{D}}w_{\boldsymbol{x}}} \ \ \ \ \ (1\le v\le V)\]</span></p><p>对属性<span class="math inline">\(a\)</span>, <span class="math inline">\(\rho\)</span>表示无缺失值样本所占的比例, <span class="math inline">\(\tilde{p}_k\)</span>表示无缺失值样本中第<span class="math inline">\(k\)</span>类所占的比例, <span class="math inline">\(\tilde{r}_v\)</span>则表示无缺失值样本中属性a上取值<span class="math inline">\(a^v\)</span>的样所占的比例. 显然<span class="math inline">\(\sum_{k=1}^{|\mathcal{Y}|}\tilde{p}_k=1\)</span>, <span class="math inline">\(\sum_{v=1}^V\tilde{r}_v=1\)</span></p><p>基于上述定义, 可将信息增益的计算式推广为</p><p><span class="math display">\[Gian(D,a)=\rho \times Gain(\tilde{D},a)=\rho \times (Ent(\tilde{D}) - \sum_{v=1}^V \tilde{r}_v Ent(\tilde{D}^v))\]</span></p><p>其中</p><p><span class="math display">\[Ent(\tilde{D}) = - \sum_{k=1}^{|\mathcal{Y}|}\tilde{p}_k log_2 \tilde{p}_k\]</span></p><p>对问题(2), 若样本<span class="math inline">\(\boldsymbol{x}\)</span>在划分属性<span class="math inline">\(a\)</span>上的取值已知, 则将<span class="math inline">\(\boldsymbol{x}\)</span>划入与其取值对应的子节点, 且样本权值在子节点中保持<span class="math inline">\(w_{\boldsymbol{x}}\)</span>. 若样本<span class="math inline">\(\boldsymbol{x}\)</span>在划分属性<span class="math inline">\(a\)</span>上的取值未知, 则将<span class="math inline">\(\boldsymbol{x}\)</span>同时划入所有子节点, 且样本权值在与属性<span class="math inline">\(a^v\)</span>对应的子节点中调整为<span class="math inline">\(\tilde{r}_v \cdot w_{\boldsymbol{x}}\)</span>; 直观地看, 就是让同一样本以不同的概率划入到不同的子节点中去.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;决策树&quot;&gt;决策树&lt;/h1&gt;
&lt;h2 id=&quot;基本概念&quot;&gt;1. 基本概念&lt;/h2&gt;
&lt;p&gt;决策树是一种常见的机器学习方法,一般一棵决策树为一颗多叉树. 每一个叶子节点就对应于一个决策结果.决策树的生成过程类似于数据结构中的树的生成过程.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;输入
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>数学基础</title>
    <link href="https://mejhwu.github.io/2018/06/12/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    <id>https://mejhwu.github.io/2018/06/12/数学基础/数学基础/</id>
    <published>2018-06-11T16:00:00.000Z</published>
    <updated>2018-09-06T14:02:54.542Z</updated>
    
    <content type="html"><![CDATA[<h4 id="泰勒展开式">泰勒展开式</h4><p><span class="math display">\[f(x) = f(a) + \frac{f^{&#39;}(a)}{1!} (x - a) + \frac{f^{(2)}(a)}{2!} (x-a)^2 + \cdots + \frac{f^{(n)}(a)}{n!} (x-a)^n + R_n(x)\]</span> 在一般工程应用中，只取泰勒展开式的前三项。</p><p>分布积分法 <span class="math display">\[\begin{gather}(u \cdot v)^{&#39;} = u^{&#39;}v + uv^{&#39;} \\\int u \cdot dv = u \cdot v - \int v \cdot du\end{gather}\]</span></p><h4 id="梯度">梯度</h4><p>函数<span class="math inline">\(z=f(x,y)\)</span>，则方向L的方向导数： <span class="math display">\[\frac{\partial f}{\partial l} = \frac{\partial f}{\partial x} cos \varphi + \frac{\partial f}{\partial y} sin \varphi\]</span></p><p><span class="math inline">\(\varphi\)</span>为<span class="math inline">\(x\)</span>轴到方向L的转向。</p><p>函数<span class="math inline">\(z=f(x,y)\)</span>，则向量<span class="math inline">\((\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y})\)</span>记为<span class="math inline">\(z\)</span>的梯度，记作<span class="math inline">\(grand f(x,y)\)</span>。</p><p>梯度的方向是函数在该点变化最快的方向。</p><h4 id="jensen不等式">Jensen不等式</h4><p><span class="math display">\[f(\theta x + (1 - \theta) y)  \le \theta f(x) + (1-\theta) f(y)\]</span> 若<span class="math inline">\(\theta_1,\theta_2,\cdots, \theta_n \ge 0; \theta_1 + \theta_2 + \cdot \cdot \cdot + \theta_n = 1\)</span>， 则 <span class="math display">\[f(\theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n ) \le \theta_1 f(x_1) + \theta_2 f(x_2) + \cdots + \theta_n f(x_n)\]</span> 若<span class="math inline">\(f^{&#39;&#39;}(x) \ge 0\)</span>，则<span class="math inline">\(f(E[x]) \le E[f(x)]\)</span>。</p><h4 id="gini系数">Gini系数</h4><p><span class="math display">\[H(x) \approx \sum_{k=1}^{n} p_k (1-P_k)\]</span></p><p><span class="math display">\[H(x) = -\sum_{k=1}^n p_k lnp_k\]</span></p><h4 id="hessian矩阵">Hessian矩阵</h4><p><strong>海森矩阵</strong>（Hessian matrix 或 Hessian）是一个多变量实值函数的二阶偏导数组成的方块矩阵，假设有一实值函数<span class="math inline">\(f(x_1,x_2,\cdot \cdot \cdot, x_n)\)</span>，如果<span class="math inline">\(f\)</span>所有的二阶倒数都存在，那么<span class="math inline">\(f\)</span>的Hessian矩阵的<span class="math inline">\(ij\)</span>项为： <span class="math display">\[H(f)_{ij} = D_i D_j f(x)\]</span> 其中<span class="math inline">\(x=(x_1,x_2,\cdot \cdot \cdot, x_n)\)</span>，即 <span class="math display">\[H(f) =\left[     \begin{matrix}    \frac{\partial ^2 f}{\partial x_1 ^2} &amp; \frac{\partial ^2 f}{\partial x_1 \partial x_2} &amp; \cdots &amp; \frac{\partial ^2 f}{\partial x_1 \partial x_n} \\    \frac{\partial ^2 f}{\partial x_2  \partial x_1} &amp; \frac{\partial ^2 f}{partial x_2 ^2} &amp; \cdots &amp; \frac{\partial ^2 f}{\partial x_2 \partial x_n} \\    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\    \frac{\partial ^2 f}{\partial x_m  \partial x_1} &amp; \frac{\partial ^2 f}{\partial x_m \partial x_2} &amp; \cdots &amp; \frac{\partial ^2 f}{\partial x_n ^2} \\    \end{matrix}    \right]\]</span></p><h4 id="正定矩阵">正定矩阵</h4><p>一个<em>n</em>×<em>n</em>的实对称矩阵是<strong>正定</strong>的，当且仅当对于所有的非零实系数<span class="math inline">\(z\)</span>，都有<span class="math inline">\(z^TMz &gt; 0\)</span>。其中<span class="math inline">\(z^T\)</span>表示<span class="math inline">\(z\)</span>的转置。当矩阵<span class="math inline">\(M\)</span>的所有特征值<span class="math inline">\(\lambda_i\)</span>大于0时，矩阵<span class="math inline">\(M\)</span>是正定的，反之亦然。</p><h4 id="牛顿法">牛顿法</h4><p>牛顿法用于求解零点，其迭代公式为： <span class="math display">\[x_{n+1} = x_n - \frac{f(x_n)}{f^{&#39;}(x_n)}\]</span> 牛顿法也被用于求函数的极值。由于函数取极值的点处的导数值为零，故可用牛顿法求导函数的零点，其迭代式为： <span class="math display">\[x_{n+1} = x_n - \frac{f^{&#39;}(x_n)}{f^{&#39;&#39;}(x_n)}\]</span></p><h4 id="大数定理">大数定理</h4><p><span class="math display">\[\lim_{n \to \infty } P\{ |Y_n - \mu| &lt; \varepsilon \} = 1\]</span></p><h4 id="中心极限定理">中心极限定理</h4><p><span class="math display">\[Y_n = \frac{\sum_{i=1}^n X_i - n\mu}{\sqrt{n} \sigma}\]</span></p><p>分布收敛于正态分布，<span class="math inline">\(\sum_{i=1}^nX_i\)</span>收敛到正态分布<span class="math inline">\(N(n\mu, n\sigma ^2)\)</span>。</p><h4 id="矩阵基础">矩阵基础</h4><p>矩阵正定：特征值大于0；</p><p>矩阵半正定：特征值大于等于0；</p><p><span class="math inline">\(n\)</span>元线性方程组<span class="math inline">\(Ax=b\)</span>.</p><ol style="list-style-type: decimal"><li>无解的充要条件：<span class="math inline">\(R(A) &lt; R(A, b)\)</span>.</li><li>有唯一解的充要条件：<span class="math inline">\(R(A) =R(A, b) = n\)</span>.</li><li>有无限多解的充要条件：<span class="math inline">\(R(A) = R(A, b) &lt; n\)</span>.</li></ol><p>正交阵：<span class="math inline">\(AA^T=I\)</span>.</p><p><span class="math inline">\(A\)</span>是正交阵，<span class="math inline">\(x\)</span>为向量，<span class="math inline">\(Ax\)</span>称为正交变换。</p><h4 id="特征值与特征向量">特征值与特征向量</h4><p><span class="math inline">\(A\)</span>是<span class="math inline">\(n\)</span>阶矩阵，数<span class="math inline">\(\lambda\)</span>和<span class="math inline">\(n\)</span>维非0向量<span class="math inline">\(x\)</span>满足<span class="math inline">\(Ax=\lambda x\)</span>，则数<span class="math inline">\(\lambda\)</span>称为<span class="math inline">\(A\)</span>的特征值，<span class="math inline">\(x\)</span>称为<span class="math inline">\(A\)</span>的对应于特征值<span class="math inline">\(\lambda\)</span>的特征向量。</p><p><span class="math inline">\((A-\lambda I) x = 0\)</span>，令<span class="math inline">\(|A-\lambda x| = 0\)</span>， 则方程<span class="math inline">\(|A-\lambda x| = 0\)</span>的根为<span class="math inline">\(A\)</span>的特征值。将根<span class="math inline">\(\lambda _0\)</span>带入方程组<span class="math inline">\((A-\lambda I) x = 0\)</span>，求得的非零解即为<span class="math inline">\(\lambda _0\)</span>对应的特征向量。 <span class="math display">\[\lambda _1 + \lambda _2 + \cdots + \lambda _n = a_{11} + a_{22} + \cdots + a_{nn}\]</span></p><p><span class="math display">\[\lambda _1 \cdot \lambda _2 \cdot \cdots \lambda _n = |A|\]</span></p><p>矩阵<span class="math inline">\(A\)</span>主行列式的元素和称作矩阵<span class="math inline">\(A\)</span>的迹。</p><p><span class="math inline">\(\lambda ^2\)</span> 是<span class="math inline">\(A ^2\)</span>的特征值。</p><p><span class="math inline">\(A\)</span>可逆时，<span class="math inline">\(\lambda ^{-1}\)</span>是<span class="math inline">\(A^{-1}\)</span>的特征值。</p><p><span class="math inline">\(\lambda _1, \lambda _2, \cdots \lambda _m\)</span>是方阵<span class="math inline">\(A\)</span>的<span class="math inline">\(m\)</span>个特征值，<span class="math inline">\(P_1, P_2, \cdots, P_m\)</span>是特征向量；若<span class="math inline">\(\lambda _1, \lambda _2, \cdots \lambda _m\)</span>各不相等，则<span class="math inline">\(P_1, P_2, \cdots, P_m\)</span>线性无关。</p><p>不同特征值对应的特征向量线性无关。</p><p>实对称矩阵的特征值是实数。</p><p>实对称阵的特征向量可以取实向量。</p><p>实对称阵不同特征值的特征向量正交。</p><p><span class="math inline">\(A\)</span>为<span class="math inline">\(n\)</span>阶对称阵，则必有正交阵<span class="math inline">\(P\)</span>使得<span class="math inline">\(P^{-1}AP=P^TAP=\Lambda\)</span>。<span class="math inline">\(\Lambda\)</span>是以<span class="math inline">\(A\)</span>的<span class="math inline">\(n\)</span>个特征值为对角元的对称阵，改变换称为合同变换，<span class="math inline">\(A\)</span>和<span class="math inline">\(\Lambda\)</span>为合同矩阵。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;泰勒展开式&quot;&gt;泰勒展开式&lt;/h4&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
f(x) = f(a) + \frac{f^{&amp;#39;}(a)}{1!} (x - a) + \frac{f^{(2)}(a)}{2!} (x-a)^2 + \
      
    
    </summary>
    
      <category term="数学" scheme="https://mejhwu.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>梯度下降</title>
    <link href="https://mejhwu.github.io/2018/04/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <id>https://mejhwu.github.io/2018/04/24/机器学习/梯度下降/</id>
    <published>2018-04-23T16:00:00.000Z</published>
    <updated>2018-06-27T12:57:51.014Z</updated>
    
    <content type="html"><![CDATA[<p>梯度下降就是在函数当前点梯度(偏导)的反方向的规定步长进行迭代,直至收敛(即到达局部最小值).</p><p>批量梯度下降</p><p>假设有损失函数</p><p><span class="math display">\[J(\theta)=\frac{1}{2}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2\]</span></p><p>其中<span class="math inline">\(h_\theta(x)=\theta_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n\)</span>.</p><p>那么</p><p><span class="math display">\[\theta_j:=\theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta)\]</span></p><p><span class="math display">\[\begin{aligned} \frac{\partial}{\partial \theta_j}J(\theta) = \sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \end{aligned}\]</span></p><p>所以</p><p><span class="math display">\[\theta_j:=\theta_j + \sum_{i=1}^{m}( y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}\]</span></p><p>以上公示就是批量梯度下降,每一次迭代<span class="math inline">\(\theta_j\)</span>时,都需要完全遍历整个输入集合.</p><p>随机梯度下降</p><p>假设只有一个输入样本,则</p><p><span class="math display">\[\theta_j:=\theta_j + ( y - h_\theta(x)x_j\]</span></p><p>以上就是随机梯度下降的公式.即每次更新<span class="math inline">\(\theta_j\)</span>只用一个样本.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;梯度下降就是在函数当前点梯度(偏导)的反方向的规定步长进行迭代,直至收敛(即到达局部最小值).&lt;/p&gt;
&lt;p&gt;批量梯度下降&lt;/p&gt;
&lt;p&gt;假设有损失函数&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[J(\theta)=\frac{1}{2}\su
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>常用激活函数</title>
    <link href="https://mejhwu.github.io/2018/04/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>https://mejhwu.github.io/2018/04/24/机器学习/常用激活函数/</id>
    <published>2018-04-23T16:00:00.000Z</published>
    <updated>2018-11-13T14:11:50.274Z</updated>
    
    <content type="html"><![CDATA[<p>常用激活函数</p><ol style="list-style-type: decimal"><li><p>sigmoid函数</p></li><li><p>relu</p></li></ol><div class="figure"><img src="/home/mejhwu/blogs/blog/source/_posts/机器学习/常用激活函数.assets/relu.png" alt="relu"><p class="caption">relu</p></div><ol start="3" style="list-style-type: decimal"><li>relu -variant</li></ol><div class="figure"><img src="/home/mejhwu/blogs/blog/source/_posts/机器学习/常用激活函数.assets/relu-variant.png"></div><ol start="4" style="list-style-type: decimal"><li>selu</li></ol><div class="figure"><img src="/home/mejhwu/blogs/blog/source/_posts/机器学习/常用激活函数.assets/selu.png"></div><p>在应用selu的时候需要注意初始化参数w的时候使用服从均值为0，方差为1的分布。</p><ol start="5" style="list-style-type: decimal"><li>swish</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;常用激活函数&lt;/p&gt;
&lt;ol style=&quot;list-style-type: decimal&quot;&gt;
&lt;li&gt;&lt;p&gt;sigmoid函数&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;relu&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src
      
    
    </summary>
    
      <category term="机器学习" scheme="https://mejhwu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>数理统计的基本概念</title>
    <link href="https://mejhwu.github.io/2018/04/22/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E6%80%BB%E7%BB%93/"/>
    <id>https://mejhwu.github.io/2018/04/22/数学基础/数理统计总结/</id>
    <published>2018-04-21T16:00:00.000Z</published>
    <updated>2018-09-05T14:24:32.127Z</updated>
    
    <content type="html"><![CDATA[<h1 id="总体与样本">总体与样本</h1><h2 id="总体-个体-样本">总体 个体 样本</h2><p>一般将研究对象的全体组成的集合成为<strong>总体</strong>,组成总体的每一个成员成为<strong>个体</strong>.</p><p>从总体中挑选一部分个体的过程叫<strong>样本</strong>, 样本所含的个体数称为<strong>样本容量</strong>.</p><h2 id="抽样方法">抽样方法</h2><p>抽样要保证对每一个个体&quot;机会均等&quot;,即总体中每一个体有同样机会被抽到,谁也不占优.凡是满足这个要求的抽样叫做<strong>随机抽样</strong>.</p><p>常用随机抽样方案:</p><p>(1)&quot;集团抽样&quot;.即先把总体中的全部个体,按某种考虑分成一些大集团,每个大集团内又可分为若干小集团,后者还可以再细分.抽样时,先用随机的方法抽取若干个大集团,再在抽出的每个大集团内分别抽出若干个小集团,<span class="math inline">\(\cdots \cdots\)</span>这样下去,最后在最低一级的集团中随机抽出若干个体.这样抽出的全部个体构成所需的样本.</p><p>(2)&quot;分层按比例抽样&quot;.必须有两个条件:一是分层的标准应合理.这主要是指层与层之间确实有较大差异,而每层内各个个体的差异较小.二是每层所含个体数在总体全部个体数所占的比例要能够比较确切地知道.</p><h1 id="样本分布和统计量">样本分布和统计量</h1><h2 id="样本分布">样本分布</h2><p>样本是按照一定的方法从总体中抽出的一部分个体所组成的集合.样本总所含的个体数称为<strong>样本容量</strong>或<strong>样本大小</strong>.</p><p>将<span class="math inline">\(n\)</span>个抽象的随机变量<span class="math inline">\(X_1,X_2,\cdots,X_n\)</span>称为样本,而把具体的观测数字<span class="math inline">\((x_1,x_2,\cdots,x_n)\)</span>看成该样本的一组取值.</p><p>样本<span class="math inline">\((X_1,X_2,\cdots,X_n)\)</span>既然是随机变量,也就有其概率分布.样本的概率分布称为<strong>样本分布</strong>.</p><p>作为随机变量的<span class="math inline">\(X_1,X_2,\cdots,X_n\)</span>可以认为是相互独立且有相同的分布,每一个<span class="math inline">\(X_i\)</span>的分布都与总体<span class="math inline">\(X\)</span>有相同的分布.</p><p>&quot;随机抽样&quot;的要求保证了样本分量<span class="math inline">\(X_1\)</span>与总体<span class="math inline">\(X\)</span>同分布的性质,&quot;每次抽取时,总体成分保持不变&quot;的要求保证了样本的各分量<span class="math inline">\(X_1,\cdots,X_n\)</span>相互独立且都与总体<span class="math inline">\(X\)</span>有相同分布的性质.</p><p>统计学中将&quot;每次抽取时,总体的成分保持不变的随机抽样&quot;称为<strong>简单随机抽样</strong>.</p><p>由简单随机抽样得到的样本称为<strong>随机样本</strong>.</p><h2 id="统计量">统计量</h2><p>对样本进行必要的加工和运算处理后得到的结果称为<strong>统计量</strong>.</p><p>常用统计量:</p><ol style="list-style-type: decimal"><li>样本均值</li></ol><p><span class="math display">\[\bar{X}=\frac{1}{n}\sum_{i=1}{n}X_k\]</span></p><ol start="2" style="list-style-type: decimal"><li>样本方差</li></ol><p><span class="math display">\[S^2=\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2\]</span></p><ol start="3" style="list-style-type: decimal"><li>样本标准差</li></ol><p><span class="math display">\[S=\sqrt{S}=\sqrt{\frac{1}{n-1}\sum_{i=1}{n}(X_i-\bar{X})^2}\]</span></p><ol start="4" style="list-style-type: decimal"><li>样本<span class="math inline">\(k\)</span>阶原点矩</li></ol><p><span class="math display">\[A_k=\frac{1}{n}\sum_{i=1}^nX_i^k\]</span></p><ol start="5" style="list-style-type: decimal"><li>样本<span class="math inline">\(k\)</span>阶中心矩</li></ol><p><span class="math display">\[B_k=\frac{1}{n}\sum_{i=1}{n}(X_i-\bar{X})^k\]</span></p><ol start="6" style="list-style-type: decimal"><li>从总体<span class="math inline">\(X\)</span>中抽取一容量为<span class="math inline">\(n\)</span>的样本<span class="math inline">\(X_1,X_2,\cdots,X_n\)</span>,设相应的观测值为<span class="math inline">\(x_1,\cdots,x_n\)</span>,将观测值按由小到大的次序重新排列为</li></ol><p><span class="math display">\[x_{(1)} \le x_{(2)} \le \cdots \le x_{(n)}\]</span></p><p>则称<span class="math inline">\(x_{(1)},\cdots,x_{(n)}\)</span>为原始样本观测值<span class="math inline">\(x_1,\cdots,x_n\)</span>的<strong>次序样本观测值</strong>.<span class="math inline">\(x_{(1)},\cdots,x_{(n)}\)</span>由<span class="math inline">\(x_1,\cdots,x_n\)</span>确定,<span class="math inline">\(x_1,\cdots,x_n\)</span>的值有一定随机性,导致<span class="math inline">\(x_{(1)},\cdots,x_{(n)}\)</span>的值也有一定随机性.为此,将次序样本观测值<span class="math inline">\(x_{(1)},\cdots,x_{(n)}\)</span>看成(想象成)某<span class="math inline">\(n\)</span>个随机变量<span class="math inline">\(X_{(1)},\cdots,X_{(n)}\)</span>(其分布可能与<span class="math inline">\(X_1,\cdots,X_n)\)</span>截然不同)的观测值,如此定义的<span class="math inline">\(n\)</span>为随机变量<span class="math inline">\((X_{(1)},\cdots,X_{(n)})\)</span>被称为原始样本<span class="math inline">\(X_1,\cdots,X_n)\)</span>的<strong>次序统计量</strong>.</p><ol start="7" style="list-style-type: decimal"><li>样本中位数</li></ol><p><span class="math display">\[\tilde{X}=\begin{cases} X_(k+1) &amp; \text{if} \quad n=2k+1 \\ \frac{1}{2}(X_{(k)} + X_{(k+1)}) &amp; \text{if} \quad n=2k \end{cases}\]</span></p><ol start="8" style="list-style-type: decimal"><li>样本极差</li></ol><p><span class="math display">\[R=X_{(n)}-X_{(1)}\]</span></p><p>统计量的实质在于:统计量只依赖与样本<span class="math inline">\(X_1,\cdots,X_n\)</span>,而不涉及任何其他未知的量,即它是样本的已知函数<span class="math inline">\(g(X_1,\cdots,X_n)\)</span>,且不能含有任何未知参数.</p><h2 id="统计量的分布">统计量的分布</h2><ol style="list-style-type: decimal"><li><span class="math inline">\(\chi^2\)</span>分布</li></ol><p>设<span class="math inline">\(X_1,\cdots,X_n\)</span>相互独立且都服从<span class="math inline">\(N(0,1)\)</span>分布,它们的平方和</p><p><span class="math display">\[\chi^2 \stackrel{def} = sX_1^2+ \cdots + X_n^2\]</span></p><p>的分布称为自由度为<span class="math inline">\(n\)</span>的<span class="math inline">\(\chi^2\)</span>分布,记为<span class="math inline">\(\chi^2 \sim \chi(n)\)</span>.</p><p>其概率密度</p><p><span class="math display">\[f(y)=\begin{cases} \frac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}y^{\frac{n}{2}-1} e^{-\frac{y}{2}}, &amp; y \ge 0 \\ 0, &amp; y &lt; 0 \end{cases}\]</span></p><p>其中<span class="math inline">\(\Gamma(z)=\int_0^{\infty}u^{z-1}e^{-u}du,(z\ge 0)\)</span>.</p><p>对任意给定的正数<span class="math inline">\(\alpha(0&lt;\alpha&lt;0)\)</span>,称满足条件</p><p><span class="math display">\[\int_{\chi_\alpha^2(n)}^{\infty}f(y)dy=\alpha\]</span></p><p>的点<span class="math inline">\(\chi_\alpha^2(n)\)</span>为<span class="math inline">\(\chi^2(n)\)</span>的上<span class="math inline">\(\alpha\)</span>分位点.</p><p><span class="math inline">\(\chi_\alpha^2(n)\)</span>的概率意义是:服从<span class="math inline">\(\chi_\alpha^2(n)\)</span>分布的随机变量<span class="math inline">\(\chi^2\)</span>,取值大于<span class="math inline">\(\chi_\alpha^2(n)\)</span>的概率正好等于<span class="math inline">\(\alpha\)</span>即</p><p><span class="math display">\[P\{\chi^2 &gt; \chi_\alpha^2(n)\}=\alpha\]</span></p><p>若<span class="math inline">\(\chi_1^2 \sim \chi^2(n_1), \chi_2^2 \sim \chi^2(n_2)\)</span>,且<span class="math inline">\(\chi_1^2\)</span>与<span class="math inline">\(\chi_2^2\)</span>独立,则</p><p><span class="math display">\[\chi_1^2+\chi_2^2=\chi^2(n_1+n_2)\]</span></p><ol start="2" style="list-style-type: decimal"><li><span class="math inline">\(t\)</span>分布</li></ol><p>设<span class="math inline">\(X\sim N(0,1), Y\sim \chi^2(n)\)</span>,且<span class="math inline">\(X,Y\)</span>相互独立,则随机变量</p><p><span class="math display">\[t\stackrel{def} =  \frac{X}{\sqrt{Y/n}}\]</span></p><p>的分布称为自由度<span class="math inline">\(n\)</span>的<span class="math inline">\(t\)</span>分布,记为<span class="math inline">\(t \sim t(n)\)</span>.</p><p><span class="math inline">\(t(n)\)</span>分布的概率密度为</p><p><span class="math display">\[f(x)=\frac{\Gamma(\frac{n+1}{2})}{\sqrt{n\pi}\Gamma(\frac{n}{2})}(1+\frac{t^2}{n})^{-\frac{n+1}{2}}, \qquad -\infty &lt; t &lt; +\infty\]</span></p><p>其中<span class="math inline">\(\Gamma(z)=\int_0^{\infty}u^{z-1}e^{-u}du,(z\ge 0)\)</span>.</p><ol start="3" style="list-style-type: decimal"><li><span class="math inline">\(F\)</span>分布</li></ol><p>设<span class="math inline">\(U\sim \chi^2(n_1), V\sim \chi^2(n_2)\)</span>,且<span class="math inline">\(U,V\)</span>相互独立,则随机变量</p><p><span class="math display">\[F \stackrel{def} =  \frac{U/n_1}{V/n_2}\]</span></p><p>的分布称为自由度<span class="math inline">\((n_1,n_2)\)</span>的<span class="math inline">\(F\)</span>分布,记为<span class="math inline">\(F\sim F(n_1,n_2)\)</span>. 其中<span class="math inline">\(n_1,n_2\)</span>分别称为第一,第二自由度.</p><p><span class="math inline">\(F(n_1,n_2)\)</span>分布的概率密度为</p><p><span class="math display">\[f(y)=\begin{cases} \frac{\Gamma(\frac{n_1+n_2}{2})}{\Gamma(\frac{n_1)}{2}\Gamma(\frac{n_2)}{2}} (\frac{n_1}{n_2})(\frac{n_1}{n_2}y)^{\frac{n_1}{2}-1}(1+\frac{n_1}{n_2}y)^{-\frac{n_1+n_2}{2}}, &amp; y \ge 0 \\ 0 &amp; y &lt; 0 \end{cases}\]</span></p><p><span class="math inline">\(F(n_1,n_2)\)</span>分布的上<span class="math inline">\(\alpha\)</span>分为点定义为满足条件</p><p><span class="math display">\[\int_{F_\alpha(n_1,n_2)}^{\infty}f(y)dy=\alpha\]</span></p><p>的点<span class="math inline">\(F_\alpha(n_1,n_2)\)</span>. 并且</p><p><span class="math display">\[F_{1-\alpha}(n_2,n_2)=\frac{1}{F_\alpha(n_1,n_2)}\]</span></p><h2 id="与正态总体统计量有关的分布">与正态总体统计量有关的分布</h2><ol style="list-style-type: decimal"><li>若<span class="math inline">\(X\)</span>服从一元正态分布<span class="math inline">\(N(\mu, \sigma^2)\)</span>,则<span class="math inline">\(X\)</span>的线性函数</li></ol><p><span class="math display">\[aX+b \sim N(a\mu+b, a^2 \sigma^2)\]</span></p><p>特别</p><p><span class="math display">\[\frac{X-\mu}{\sigma} \sim N(0,1)\]</span></p><ol start="2" style="list-style-type: decimal"><li>若<span class="math inline">\(X \sim N(\mu_1, \sigma_1^2), Y \sim N(\mu_2, \sigma_2^2)\)</span>,且<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>相互独立,则</li></ol><p><span class="math display">\[X \pm Y \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)\]</span></p><ol start="3" style="list-style-type: decimal"><li>如果随机变量<span class="math inline">\(\mathbf{X}\)</span>服从均值向量为<span class="math inline">\(\mathbf{\mu}\)</span>,协方差矩阵为<span class="math inline">\(\mathbf{\Sigma}\)</span>的<span class="math inline">\(n\)</span>元正态分布<span class="math inline">\(N(\mathbf{\mu, \Sigma}),\mathbf{A}\)</span>是<span class="math inline">\(m\)</span>行<span class="math inline">\(n\)</span>列的常数矩阵,则<span class="math inline">\(m\)</span>维随机向量</li></ol><p><span class="math display">\[\mathbf{AX} \sim N(\mathbf{A\mu,A\Sigma A&#39;})\]</span></p><ol start="4" style="list-style-type: decimal"><li>显然<span class="math inline">\(\frac{X_1-\mu}{\sigma},\frac{X_2-\mu}{\sigma},\cdots,\frac{X_n-\mu}{\sigma}\)</span>独立同<span class="math inline">\(N(0,1)\)</span>分布,由<span class="math inline">\(\chi^2\)</span>分布的定义可知它们的平方和</li></ol><p><span class="math display">\[\frac{1}{\sigma^2} \sum_{i=1}^{n}(X_1-\mu)^2 \sim \chi^2(n)\]</span></p><ol start="5" style="list-style-type: decimal"><li>由独立正态变量的线性运算性质得</li></ol><p><span class="math display">\[\sum_{i=1}^nX_i \sim N(n\mu, n\sigma^2)\]</span></p><p>所以</p><p><span class="math display">\[\bar{X}=\frac{\displaystyle \sum_{i=1}^nX_i}{n} \sim N(\mu, \frac{\sigma^2}{n})\]</span></p><p>标准化得</p><p><span class="math display">\[\frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)\]</span></p><ol start="6" style="list-style-type: decimal"><li></li></ol><p><span class="math display">\[\frac{1}{\sigma^2}\sum_{i=1}{n}(X_i-\bar{X})^2 \sim \chi^2(n-1)\]</span></p><p>亦即</p><p><span class="math display">\[\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)\]</span></p><ol start="7" style="list-style-type: decimal"><li><p><span class="math inline">\(\frac{\sqrt{n}{\bar{X}-\mu}}{\sigma}\)</span>与<span class="math inline">\(\frac{n-1)S^2}{\sigma^2}\)</span>相互独立.</p></li><li></li></ol><p><span class="math display">\[\frac{\sqrt{n}(\bar{x}-\mu)}{S} = \frac{\frac{\sqrt{n}(\bar{x}-\mu)}{\sigma}}{\sqrt{\frac{(n-1)S^2}{(n-1)\sigma^2}}} \sim t(n-1)\]</span></p><ol start="9" style="list-style-type: decimal"><li></li></ol><p><span class="math display">\[\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} \sim N(0,1)\]</span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;总体与样本&quot;&gt;总体与样本&lt;/h1&gt;
&lt;h2 id=&quot;总体-个体-样本&quot;&gt;总体 个体 样本&lt;/h2&gt;
&lt;p&gt;一般将研究对象的全体组成的集合成为&lt;strong&gt;总体&lt;/strong&gt;,组成总体的每一个成员成为&lt;strong&gt;个体&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;从总
      
    
    </summary>
    
      <category term="数学" scheme="https://mejhwu.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>概率论总结</title>
    <link href="https://mejhwu.github.io/2018/04/19/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%80%BB%E7%BB%93/"/>
    <id>https://mejhwu.github.io/2018/04/19/数学基础/概率论总结/</id>
    <published>2018-04-18T16:00:00.000Z</published>
    <updated>2018-06-27T12:58:09.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念">基本概念</h1><h2 id="古典概型">古典概型</h2><h3 id="古典改型的特点">古典改型的特点:</h3><ol style="list-style-type: decimal"><li>试验的样本空间中的元素个数只有有限个,不妨设为n个,记为<span class="math inline">\(e_1,e_2,...,e_n\)</span>;</li><li>每个基本事件<span class="math inline">\(\{e\}\)</span>出现的可能性相等,即有</li></ol><p><span class="math display">\[P(\{e_1\})=P(\{e_2\})=...=P(\{e_n\})\]</span></p><h3 id="古典概型类型">古典概型类型</h3><h4 id="随机取数问题">随机取数问题</h4><ol style="list-style-type: decimal"><li><p>有放回地随机取数: 若从<span class="math inline">\(n\)</span>个相异的数字中有放回地取<span class="math inline">\(m\)</span>个, 则试验样本空间的基本事件总数可按<span class="math inline">\(n\)</span>个不同数字中取<span class="math inline">\(m\)</span>个的重复排列计算,由乘法原理知为<span class="math inline">\(n*n*... *n=n^m\)</span></p></li><li><p>无放回地随机取数: 若取出的数不还原,则从n个不同的数中任取<span class="math inline">\(m\)</span>个试验样本空间所含基本事件总数要根据取数是计序或不计序,按不重复的排列或组合公式计算,即基本事件总数为:</p></li></ol><ol style="list-style-type: lower-alpha"><li><p>计序时为<span class="math inline">\(A_n^m=n(n-1)...(n-m+1)\)</span></p></li><li><p>不计序时为<span class="math inline">\(C_n^m= \left( \begin{matrix} n \\ m \end{matrix} \right)=\frac{n!}{m!(n-m)!}\)</span></p></li></ol><h4 id="抽球问题">抽球问题</h4><p>从<span class="math inline">\(n\)</span>个球中抽取<span class="math inline">\(m\)</span>个:</p><p>(1)有放回</p><p>(a)计序: <span class="math inline">\(n^m\)</span></p><p>(b)不计序: <span class="math inline">\(C_{n+m-1}^m\)</span>, 相当于在<span class="math inline">\(n+m-1\)</span>个球中无放回抽取<span class="math inline">\(m\)</span>个球</p><p>(2)无放回</p><p>(a)计序: <span class="math inline">\(A_n^m\)</span></p><p>(b)不计序: <span class="math inline">\(C_n^m\)</span></p><h4 id="分房问题">分房问题</h4><p>设有<span class="math inline">\(n\)</span>个人,每个人都等可能的被分配到<span class="math inline">\(N\)</span>个房间中的任意一间中去住<span class="math inline">\((n\le N)\)</span>, 且每个房间可容纳的人数不限.</p><h4 id="配对问题">配对问题</h4><h2 id="几何概型">几何概型</h2><ol style="list-style-type: decimal"><li><p>每次试验的可能有无限多个,且全部可能结果的集合可用一个有度量(如长,面积,体积等)的几何区域来表示.</p></li><li><p>每次试验中每个可能的出现是等可能的.</p></li></ol><h2 id="条件概率">条件概率</h2><p>设<span class="math inline">\(A, B\)</span>为两事件,且<span class="math inline">\(P(A) \gt 0\)</span>, 称</p><p><span class="math display">\[P(B|A)=\frac{P(AB)}{P(A)}\]</span></p><p>为在事件<span class="math inline">\(A\)</span>发生条件下事件<span class="math inline">\(B\)</span>发生的概率.</p><p>全概率公式</p><p>设试验<span class="math inline">\(E\)</span>的样本空间<span class="math inline">\(S\)</span>, <span class="math inline">\(A\)</span>为<span class="math inline">\(E\)</span>的事件, <span class="math inline">\(B_1,B_2,...,B_n\)</span>为<span class="math inline">\(S\)</span>的一个划分,且<span class="math inline">\(P(B_i)\gt 0(i=1,2,...,n)\)</span>, 则</p><p><span class="math display">\[P(A)=P(B_1)P(A|B_1)+P(B_2)P(A|B_2)+...+P(B_n)P(A|B_n)\]</span></p><p>贝叶斯公式</p><p>设试验<span class="math inline">\(E\)</span>的样本空间<span class="math inline">\(S\)</span>, <span class="math inline">\(A\)</span>为<span class="math inline">\(E\)</span>的事件, <span class="math inline">\(B_1,B_2,...,B_n\)</span>为<span class="math inline">\(S\)</span>的一个划分,且<span class="math inline">\(P(A)&gt;0, P(B_i)\gt 0(i=1,2,...,n)\)</span>, 则</p><p><span class="math display">\[P(B_i|A)=\frac{P(B_i)P(A|B_i)}{\sum_{j=1}^nP(B_j)P(A|B_js)}\]</span></p><h2 id="事件独立">事件独立</h2><p>设<span class="math inline">\(A\)</span>,<span class="math inline">\(B\)</span>是两事件,如果具有等式</p><p><span class="math display">\[P(AB)=P(A)P(B)\]</span></p><p>则称<span class="math inline">\(A\)</span>,<span class="math inline">\(B\)</span>为相互独立事件.</p><h1 id="随机变量">随机变量</h1><h2 id="概念">概念</h2><p>设<span class="math inline">\(E\)</span>是随机试验, 其样本空间<span class="math inline">\(S=\{e\}\)</span>. 如果对应每一个<span class="math inline">\(e \in S\)</span>, 均有一个实数<span class="math inline">\(X(e)\)</span>与之对应, 这样一个定义在样本空间<span class="math inline">\(S\)</span>上的单值实数<span class="math inline">\(X=X(e)\)</span>, 称为随机变量.</p><p>设<span class="math inline">\(X\)</span>是一个随机变量, <span class="math inline">\(x\)</span>是任意实数, 函数</p><p><span class="math display">\[F(s)=P\{X \le x\}\]</span></p><p>称为<span class="math inline">\(X\)</span>的分布函数.</p><p>分布函数的基本性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(F(x)\)</span>是一个不减函数.</p></li><li><p><span class="math inline">\(0 \le F(x) \le 1\)</span> 且 <span class="math inline">\(F(-\infty)= \lim_{x \rightarrow -\infty}F(x) = 0 \quad F(+\infty)= \lim_{x \rightarrow +\infty}F(x) = 1\)</span></p></li></ol><h2 id="离散型随机变量">离散型随机变量</h2><p>若随机变量<span class="math inline">\(X\)</span>的可能取值仅有有限个或可列多个,则称此随机变量为离散型随机变量.</p><h3 id="常见分布">常见分布</h3><h4 id="单点分布">单点分布</h4><p>设随机变量<span class="math inline">\(X\)</span>取一个常数值<span class="math inline">\(C\)</span>的概率为1, 即<span class="math inline">\(P\{X=C\}=1\)</span>, 则称<span class="math inline">\(X\)</span>服从单点分布或退化分布.</p><h4 id="分布两点分布">(0-1)分布(两点分布)</h4><p>设随机变量<span class="math inline">\(X\)</span>只可能取0和1两个值,它的分布律是</p><p><span class="math display">\[P\{X=k\}=p^k(1-p)^{1-k} \qquad k=0,1; 0 &lt; p &lt; 1\]</span></p><p>则称<span class="math inline">\(X\)</span>服从(0-1)分布.</p><h4 id="等可能分布离散型均匀分布">等可能分布(离散型均匀分布)</h4><p>如果随机变量<span class="math inline">\(X\)</span>可以取<span class="math inline">\(n\)</span>个不同的值<span class="math inline">\(x_1&lt;x_2&lt;...&lt;x_n\)</span>, 且取每个<span class="math inline">\(x_k\)</span>值的概率相等, 即</p><p><span class="math display">\[P\{X=x_k\}=\frac {1}{n}\]</span></p><p>则称<span class="math inline">\(X\)</span>服从等可能或称离散型均匀分布.</p><h4 id="二项分布">二项分布</h4><p>如果随机变量<span class="math inline">\(X\)</span>取值为<span class="math inline">\(0,1,2,...,n\)</span>的概率为</p><p><span class="math display">\[P\{X=k\}= \left( \begin{matrix}  n \\ k \end{matrix} \right) p^k (1-p)^{n-k}\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(n,p\)</span>的二项分布, 记为<span class="math inline">\(X \sim B(n,p)\)</span></p><p>设试验<span class="math inline">\(E\)</span>的可能结果只有两个,即<span class="math inline">\(A\)</span>或<span class="math inline">\(\bar{A}\)</span>, 且<span class="math inline">\(P(A)=p, P(\bar{A})=1-p=q(0&lt;p&lt;1)\)</span>, 若将此试验<span class="math inline">\(E\)</span>独立地重复<span class="math inline">\(n\)</span>次,则称这一串重复的独立试验为<span class="math inline">\(n\)</span>重贝努力(Bernoulli)试验,或称<span class="math inline">\(n\)</span>重贝努力概型.</p><h4 id="泊松分布">泊松分布</h4><p>如果随机变量X的可能取值为<span class="math inline">\(0,1,2,...\)</span>取各值的概率为</p><p><span class="math display">\[P\{X=k\}=\frac{\lambda ^k e^{-\lambda}}{k!}\]</span></p><p>其中<span class="math inline">\(\lambda&gt;0\)</span>为常数,则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\lambda\)</span>的泊松分布,记为<span class="math inline">\(X \sim P(\lambda)\)</span>.</p><p>泊松逼近定理</p><p>设<span class="math inline">\(\lambda &gt; 0\)</span>是一常数, <span class="math inline">\(n\)</span>是任意正整数, 设<span class="math inline">\(np_n=\lambda\)</span>, 则对于任一固定的非负整数<span class="math inline">\(k\)</span>, 有</p><p><span class="math display">\[\lim_{n\rightarrow \infty} \left( \begin{matrix}n \\ p \end{matrix} \right) (1-p_n)^{n-k} = \frac{\lambda ^k e^{-\lambda}}{k!}\]</span></p><h4 id="几何分布">几何分布</h4><p>如果随机变量<span class="math inline">\(X\)</span>可能取值为<span class="math inline">\(1,2,..\)</span>的概率为</p><p><span class="math display">\[P\{X=k\}=pq^{k-1} \qquad k=1,2,..., \quad 0 &lt; p &lt; 1, \quad q=1-p\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p\)</span>的几何分布,记为<span class="math inline">\(X \sim Ge(p)\)</span>.</p><p>几何分布的数学描述:</p><p>若进行一系列重复的独立试验,每次试验中某事件<span class="math inline">\(A\)</span>发生的概率为<span class="math inline">\(p\)</span>,即<span class="math inline">\(p=P(A)\)</span>, 令<span class="math inline">\(X\)</span>表示事件<span class="math inline">\(A\)</span>首次发送时试验的总次数,则此<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p\)</span>的几何分布.</p><h4 id="帕斯卡分布负二项分布">帕斯卡分布(负二项分布)</h4><p>如果随机变量<span class="math inline">\(X\)</span>的概率分布为</p><p><span class="math display">\[P\{X=k\}=\left( \begin{matrix} k-1 \\ r-1 \end{matrix} \right) p^r q^{k-r} \]</span></p><p><span class="math display">\[k=r,r+1,r+2,...,r \ge 1, \quad 0 &lt; p &lt; 1, \quad q = 1-p\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p,r\)</span>的帕斯卡分布或负二项分布.</p><p>帕斯卡分布的数学描述;</p><p>若进行一系列重复的独立试验, 每次试验中某事件<span class="math inline">\(A\)</span>发生的概率为<span class="math inline">\(p\)</span>发生的概率为<span class="math inline">\(p\)</span>, 即<span class="math inline">\(p=P(A)\)</span>. 令<span class="math inline">\(X\)</span>表示在事件<span class="math inline">\(A\)</span>恰发生<span class="math inline">\(r\)</span>次时试验的总次数,则此<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p,r\)</span>的帕斯卡分布.</p><h4 id="超几何分布">超几何分布</h4><p>如果随机变量<span class="math inline">\(X\)</span>的概率分布为</p><p><span class="math display">\[P\{X=k\}=\frac{\left( \begin{matrix} M \\ k \end{matrix} \right) \left( \begin{matrix} N-M \\ n-k \end{matrix} \right) }{\left( \begin{matrix} N \\ n \end{matrix} \right)}\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(n,M,N\)</span>的超几何分布.</p><p>超几何分布的数学描述:</p><p>设一代中总有<span class="math inline">\(N\)</span>个产品,其中有<span class="math inline">\(M\)</span>个次品,现从中任取<span class="math inline">\(n\)</span>个产品,令<span class="math inline">\(X\)</span>为<span class="math inline">\(n\)</span>个产品中的次品的个数,则此<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(n,M,N\)</span>的超几何分布.</p><p>定理:</p><p>设<span class="math inline">\(p(0&lt;p&lt;1)\)</span>为一常数,当<span class="math inline">\(N \rightarrow \infty\)</span>时, <span class="math inline">\(\lim \frac{M}{N} = p\)</span>, 则对固定的非负整数<span class="math inline">\(n(n\le M)\)</span>, 任一固定的非负整数<span class="math inline">\(k=0,1,2,...,n\)</span> 有</p><p><span class="math display">\[\lim_{N \rightarrow \infty} \frac {\left( \begin{matrix} M \\ k \end{matrix} \right) \left( \begin{matrix} N-M \\ n-k \end{matrix} \right)}{\left( \begin{matrix} N \\ n \end{matrix} \right)} = \left( \begin{matrix} n \\ k \end{matrix} \right)p^k(1-p)^{n-k}\]</span></p><h2 id="连续型随机变量">连续型随机变量</h2><h3 id="概念-1">概念</h3><p>如果对于随机变量<span class="math inline">\(X\)</span>的分布函数<span class="math inline">\(F(x)\)</span>, 存在非负函数<span class="math inline">\(f(x)\)</span>, 使对于任意实数<span class="math inline">\(x\)</span>均有</p><p><span class="math display">\[F(x)=\int^x_{-\infty} f(t)dt \]</span></p><p>则称<span class="math inline">\(X\)</span>为连续型随机变量, 其中函数<span class="math inline">\(f(x)\)</span>称为<span class="math inline">\(X\)</span>的概率密度函数,简称概率密度.</p><p>概率密度<span class="math inline">\(f(x)\)</span>具有以下性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(f(x) \ge 0\)</span></p></li><li><p><span class="math inline">\(\int_{- \infty}^{+ \infty}f(x)dx=1\)</span></p></li><li><p><span class="math inline">\(P\{x_1 &lt; X \le x_2\} = F(x_2) - F(x_1) = \int_{x_1}^{x_2}dx \qquad (x_1 \le x_2\)</span>)</p></li><li><p>若<span class="math inline">\(f(x)\)</span>在点<span class="math inline">\(x\)</span>处连续, 则有<span class="math inline">\(F^{&#39;}(x) = f(x)\)</span></p></li></ol><p>对于连续型随机变量<span class="math inline">\(X\)</span>来说,<span class="math inline">\(X\)</span>取任一固定值<span class="math inline">\(a\)</span>的概率为0, 故连续型随机变量概率与区间开闭无关:</p><p><span class="math display">\[P\{a \le x \le b\} = P\{a \le x &lt; b\} = P\{a &lt; x \le b\} = P\{a &lt; x &lt; b\}\]</span></p><h3 id="连续型随机变量的分布">连续型随机变量的分布</h3><h4 id="均匀分布">均匀分布</h4><p>若随机变量<span class="math inline">\(X\)</span>具有概率密度</p><p><span class="math display">\[f(x)=\begin{cases} &amp; \frac{1}{b-a} \quad &amp; a &lt; x &lt; b \\ &amp; 1 \quad &amp; x \ge b, x \le a \end{cases}\]</span></p><p>s则称<span class="math inline">\(X\)</span>服从<span class="math inline">\((a,b)\)</span>上的均匀分布, 记作<span class="math inline">\(X \sim U(a,b)\)</span>. 当参数<span class="math inline">\(a=0, b=1\)</span>时, <span class="math inline">\(U(a,b)\)</span>成为标准分布.</p><p>容易得到<span class="math inline">\(X\)</span>的分布函数为</p><p><span class="math display">\[f(x)=\begin{cases} 0 &amp; x&lt;a \\ \frac{x-a}{b-a} &amp; a \le x &lt; b \\ 1 &amp; x \ge b \end{cases}\]</span></p><h4 id="指数分布">指数分布</h4><p>若随机变量<span class="math inline">\(X\)</span>具有概率密度</p><p><span class="math display">\[f(x)=\begin{cases} \alpha e^{-\alpha x} &amp; x&gt;0 \\ 0 &amp; x \le 0 \end{cases}\]</span></p><p>其中参数<span class="math inline">\(\alpha &gt; 0\)</span>, 则称随机变量<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\alpha\)</span>的指数分布, 记为<span class="math inline">\(X \sim Z(\alpha)\)</span>.</p><p>其分布函数为</p><p><span class="math display">\[F(x)=\begin{cases} 1-e^{-\alpha x} &amp; x &gt; 0 \\ 0 &amp; x \le 0 \end{cases}\]</span></p><h4 id="正态分布">正态分布</h4><p>若随机变量<span class="math inline">\(X\)</span>具有概率密度</p><p><span class="math display">\[f(x)=\frac{1}{\sqrt{2 \pi \sigma}} e^{-\frac{(x-\mu)^2}{2 \sigma^2}}\]</span></p><p>则称<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\sigma^2(\sigma &gt; 0)\)</span>的正态分布,记作<span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, 此时称<span class="math inline">\(X\)</span>为正态变量.</p><p><span class="math inline">\(X\)</span>的分布函数为</p><p><span class="math display">\[F(x)=\int _{-\infty}^x \frac{1}{\sqrt{2 \pi \sigma}} e^{-\frac{(t-\mu)^2}{2 \sigma^2}} dt \qquad -\infty &lt; x &lt; +\infty\]</span></p><p>当<span class="math inline">\(\mu =0, \sigma = 1\)</span>时, <span class="math inline">\(X \sim N(0,1)\)</span>, 称<span class="math inline">\(X\)</span>服从标准正态分布,称<span class="math inline">\(X\)</span>为标准正态变量. 它的概率密度和分布函数分布标记为</p><p><span class="math display">\[\varphi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \qquad -\infty&lt;x&lt;+\infty \]</span></p><p><span class="math display">\[\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}dt \qquad -\infty&lt;x&lt;+\infty \]</span></p><p>若<span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, 其分布函数为<span class="math inline">\(F(x)\)</span>, 则标准化变量</p><p><span class="math display">\[Z=\frac{X-\mu}{\sigma} \sim N(0,1)\]</span></p><p>且</p><p><span class="math display">\[F(x)=\Phi(\frac{x-\mu}{\sigma})\]</span></p><p>设随机变量<span class="math inline">\(X\)</span>的分布函数<span class="math inline">\(F(x)\)</span>,对于任一正数<span class="math inline">\(\alpha(0&lt;\alpha&lt;1)\)</span>, 若<span class="math inline">\(X\)</span>大于等于某实数<span class="math inline">\(z_\alpha\)</span>, 即</p><p><span class="math display">\[1-F(z_\alpha)=P\{X \ge z_\alpha\} = \alpha \qquad 0 &lt; \alpha &lt; 1\]</span></p><p>则称此实数<span class="math inline">\(z_\alpha\)</span>为分布<span class="math inline">\(F(x)\)</span>的上<span class="math inline">\(\alpha\)</span>分为点.</p><h2 id="随机变量的函数的分布">随机变量的函数的分布</h2><h3 id="离散型随机变量的函数的分布">离散型随机变量的函数的分布</h3><p>离散型随机变量的函数<span class="math inline">\(Y=g(X)\)</span>仍是离散型随机变量.计算离散型随机变量的函数的分布律,首先找出它的一切可能值,然后计算它取各个值的概率.</p><h3 id="连续型随机变量的函数的分布">连续型随机变量的函数的分布</h3><p>如果<span class="math inline">\(X\)</span>是连续型随机变量,函数<span class="math inline">\(g(x)\)</span>是连续函数,这时<span class="math inline">\(Y=g(X)\)</span>也是一个连续型随机变量.</p><p>设连续型随机变量<span class="math inline">\(X\)</span>的概率密度为<span class="math inline">\(f_X(s)\)</span>, 当<span class="math inline">\(a&lt;x&lt;b\)</span>时, <span class="math inline">\(f_X(x)&gt;0;y=g(x)\)</span>处处可导, 且恒有<span class="math inline">\(g&#39;(x)&gt;0\)</span>(或<span class="math inline">\(g&#39;(x)&lt;0\)</span>),则随机变量<span class="math inline">\(X\)</span>的函数<span class="math inline">\(Y=g(X)\)</span>的概率密度为</p><p><span class="math display">\[f_Y(y)=\begin{cases} f_X(h(y))|h&#39;(y)| &amp; c&lt;y&lt;d \\ 0 &amp; y\ge d, y &lt; c \end{cases}\]</span></p><p>其中<span class="math inline">\(x=h(y)\)</span>为<span class="math inline">\(y=g(x)\)</span>的反函数, <span class="math inline">\(c=min\{g(a), g(b)\}, d=max\{g(a),g(b)\}\)</span></p><p>设随机变量<span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, <span class="math inline">\(X\)</span>的线性函数<span class="math inline">\(Y=aX+b(a\neq 0)\)</span>也服从正态分布.</p><h1 id="多维随机变量">多维随机变量</h1><h2 id="二维随机变量">二维随机变量</h2><p>设<span class="math inline">\(E\)</span>为一个随机试验,它的样本空间为<span class="math inline">\(S=\{e\}\)</span>, 并设<span class="math inline">\(X=X(e)\)</span>和<span class="math inline">\(Y=Y(e)\)</span>是定义在<span class="math inline">\(S\)</span>上的随机变量,由它们两个构成的联合变量<span class="math inline">\((X,Y)\)</span>,称为二维随机变量或二维随机向量.</p><p>设<span class="math inline">\((X,Y)\)</span>是定义在样本空间<span class="math inline">\(S=\{e\}\)</span>上的二维随机变量, 对于任意实数<span class="math inline">\(x,y\)</span>, 二元函数</p><p><span class="math display">\[F(x,y)=P\{(X\le x) \cap (Y\le y)\} \triangleq P\{X\le x, Y\le y\}\]</span></p><p>称为二维随机变量<span class="math inline">\((X,Y)\)</span>的分布函数, 或称为随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的联合分布函数.</p><p>二维随机变量的分布函数的性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(F(x,y)\)</span>是变量<span class="math inline">\(x\)</span>和<span class="math inline">\(y\)</span>的不减函数.</p></li><li><p><span class="math inline">\(0 \le F(x,y) \le 1\)</span>, 且对于任意固定的<span class="math inline">\(y, F(-\infty,y)=0\)</span>;对于固定的<span class="math inline">\(x\)</span>,有<span class="math inline">\(F(x,-\infty)=0\)</span>; 且<span class="math inline">\(F(-\infty, +\infty)=0;F(+\infty,-\infty)=1\)</span>.</p></li><li><p><span class="math inline">\(F(x,y)=F(x+0,y)=F(x, y+0)\)</span>, 即<span class="math inline">\(F(x,y)\)</span>关于<span class="math inline">\(x\)</span>右连续,关于<span class="math inline">\(y\)</span>右连续.</p></li><li><p>对于任意的<span class="math inline">\(x_1&lt;x_2, y_1&lt;y_2\)</span>, 下述不等式成立</p></li></ol><p><span class="math display">\[F(x_2,y_2)-F(x_2,y_1)-F(x_1,y_2)-F(x_1,y_1) \ge 0\]</span></p><p><span class="math inline">\(X,Y\)</span>的边缘分布函数<span class="math inline">\(F_X(x),F_Y(y)\)</span>:</p><p><span class="math display">\[F_X(x)=P\{X \le x\} = P\{X \le x, Y &lt; +\infty\}=F(x,+\infty)\]</span></p><p><span class="math display">\[F_Y(y)=P\{Y \le y\} = P\{X &lt; +\infty, Y \le y\}=F(+\infty, y)\]</span></p><h3 id="二维离散型随机变量">二维离散型随机变量</h3><p>如果二维随机变量<span class="math inline">\((X,Y)\)</span>的所有可能取的值是有限对或可列多对,则称<span class="math inline">\((X,Y)\)</span>是二维离散想随机变量.</p><p>设二维离散型随机变量<span class="math inline">\((X,Y)\)</span>所有可能取的值为<span class="math inline">\((x_i,y_j)(i,j=1,2,...)\)</span>, 其概率记为<span class="math inline">\(P\{X=x_i,Y=y_j\} = p_{ij}(i,j=1,2,...)\)</span>,则由概率的定义有</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(p_{ij} \ge 0\)</span></p></li><li><p><span class="math inline">\(\sum_{i=1}^\infty \sum_{j=1}^\infty p_{ij} = 1\)</span></p></li></ol><p><span class="math inline">\((X,Y)\)</span>的分布函数为</p><p><span class="math display">\[F(x,y)=P\{X \le x, Y\le y\}=\sum_{x_i\le x}\sum_{y_j\le y}P\{X=x_i, Y=y_j\}=\sum_{x_i\le x}\sum_{y_j\le y}p_{ij}\]</span></p><p><span class="math inline">\(X\)</span>的分布律:</p><p><span class="math display">\[P\{X=x_i\}=\sum_{j=1}^\infty p_{ij} \triangleq p_{i\cdot} \qquad i=1,2,...\]</span></p><p><span class="math inline">\(Y\)</span>的分布律:</p><p><span class="math display">\[P\{Y=y_j\}=\sum_{i=1}^\infty p_{ij} \triangleq p_{\cdot i} \qquad j=1,2,...\]</span></p><h3 id="二维连续型随机变量">二维连续型随机变量</h3><p>如果二维随机变量<span class="math inline">\((X,Y)\)</span>的分布函数<span class="math inline">\(F(x,y)\)</span>, 存在一个非负可积的二元函数<span class="math inline">\(f(x,y)\)</span>,使它对应任意实数<span class="math inline">\(x,y\)</span>, 都有</p><p><span class="math display">\[F(x,y)=\int_{-\infty}^x \int_{-\infty}^y f(s,t)dsdt\]</span></p><p>则称<span class="math inline">\((X,Y)\)</span>是二维连续型随机变量,函数<span class="math inline">\(f(x,y)\)</span>称为二维随机变量<span class="math inline">\((X,Y)\)</span>的概率密度,或称为随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的联合概率密度.</p><p>概率密度<span class="math inline">\(f(x,y)\)</span>具有以下性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(f(x,y) \ge 0\)</span></p></li><li><p><span class="math inline">\(\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f(x,y)dxdy = 1\)</span></p></li><li><p>若<span class="math inline">\(f(x,y)\)</span>在点<span class="math inline">\((x,y)\)</span>连续, 则有</p></li></ol><p><span class="math display">\[\frac{\partial^2 F(x,y)}{\partial x \partial y}=f(x,y)\]</span></p><ol start="4" style="list-style-type: decimal"><li>随机点<span class="math inline">\((X,Y)\)</span>落在平面区域<span class="math inline">\(D\)</span>上的概率为</li></ol><p><span class="math display">\[P\{(X,Y) \in D\}=\int \int_D f(x,y) dxdy\]</span></p><p><span class="math inline">\(X\)</span>为连续型变量,其概率密度为</p><p><span class="math display">\[f_X(x)=\int_{-\infty}^{+\infty}f(x,y)dy\]</span></p><p><span class="math inline">\(Y\)</span>为连续型变量,其概率密度为</p><p><span class="math display">\[f_Y(y)=\int_{-\infty}^{+\infty}f(x,y)dx\]</span></p><p><span class="math inline">\(X,Y\)</span>的联合分布可以确定<span class="math inline">\(X,Y\)</span>的边缘分布函数, 反过来,有<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的边缘分布,一般不能确定<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的联合分布.</p><h2 id="条件分布">条件分布</h2><h3 id="条件分布律">条件分布律</h3><p>设<span class="math inline">\((X,Y)\)</span>是离散型随机变量, 可能取值为<span class="math inline">\((x_i,y_j)(i,j=1,2,...)\)</span>, 其分布律及边缘分布律分别为<span class="math inline">\(P\{X=x_i,Y=y_j\}=p_{ij}, P\{X=x_i\}=p_{i\cdot}, P\{Y=y_j\}=p_{\cdot j}\)</span>.</p><p>若对于固定的<span class="math inline">\(i, P\{X=x_i\} &gt; 0\)</span>,则称</p><p><span class="math display">\[P\{Y=y_j|X=x_i\}=\frac{P\{X=x_i,Y=y_j\}}{P\{X=x_i\}}=\frac{p_{ij}}{p_{i\cdot}} \triangleq p_{j|i}\]</span></p><p>为在<span class="math inline">\(X=x_i\)</span>条件下<span class="math inline">\(Y\)</span>的条件分布律.</p><p>若对于固定的<span class="math inline">\(j, P\{Y=y_j\}&gt;0\)</span>,则称</p><p><span class="math display">\[P\{X=x_i|Y=y_j\}=\frac{P\{X=x_i,Y=y_j\}}{P\{Y=y_j\}}=\frac{p_{ij}}{p_{\cdot j}} \triangleq p_{i|j}\]</span></p><p>为在<span class="math inline">\(Y=y_j\)</span>条件下<span class="math inline">\(X\)</span>的条件分布律.</p><h3 id="条件分布函数与条件概率密度">条件分布函数与条件概率密度</h3><p>由离散型分布函数定义可得条件分布函数为</p><p><span class="math display">\[F_{Y|X}(y|x_i)=P\{Y \le y | X=x_i\}=\sum_{y_j\le y} p_{j|i}\]</span></p><p><span class="math display">\[F_{X|Y}(x|y_j)=P\{X \le x | Y=y_j\}=\sum_{x_i\le x} p_{i|j}\]</span></p><p>给定<span class="math inline">\(y\)</span>, 设对于任意固定的正数<span class="math inline">\(\varepsilon, P\{y-\varepsilon &lt; Y \le y+\varepsilon \} &gt; 0\)</span>, 且若对于任意实数<span class="math inline">\(x\)</span>,极限</p><p><span class="math display">\[\lim_{\varepsilon \rightarrow 0^+} P\{X \le x | y-\varepsilon &lt; Y \le y+\varepsilon \} = \lim_{\varepsilon \rightarrow 0^+} \frac{P\{X \le x , y-\varepsilon &lt; Y \le y+\varepsilon \}}{P\{y-\varepsilon &lt; Y \le y+\varepsilon \}}\]</span></p><p>存在,则称此极限在条件<span class="math inline">\(Y=y\)</span>下<span class="math inline">\(X\)</span>的条件分布函数,记为<span class="math inline">\(P\{X \le x | Y=y\}\)</span>, 或记为<span class="math inline">\(F_{X|Y}(x|y)\)</span>.s</p><p>设<span class="math inline">\((X,Y)\)</span>的分布函数为<span class="math inline">\(F(x,y)\)</span>,概率密度为<span class="math inline">\(f(x,y)\)</span>, 若在点<span class="math inline">\((x,y)\)</span>处<span class="math inline">\(f(x,y)\)</span>连续,边缘概率密度<span class="math inline">\(f_Y(y)\)</span>连续,且<span class="math inline">\(f_Y(y) &gt; 0\)</span>,则有</p><p><span class="math display">\[F_{X|Y}(x|y)=\int_{-\infty}^x \frac{f(u,y)}{f_Y(y)} du\]</span></p><p><span class="math display">\[f_{X|Y}(x|y)=\frac{f(x,y)}{f_Y(y)}\]</span></p><p>同理</p><p><span class="math display">\[F_{Y|X}(y|x)=\int_{-\infty}^y \frac{f(x,v)}{f_X(x)} dv\]</span></p><p><span class="math display">\[f_{Y|X}(y|x)=\frac{f(x,y)}{f_X(x)}\]</span></p><h2 id="相互独立的随机变量">相互独立的随机变量</h2><p>设<span class="math inline">\(F(x,y)\)</span>及<span class="math inline">\(F_X(x),F_Y(y)\)</span>分别是二维随机变量<span class="math inline">\((X,Y)\)</span>的分布函数及边缘分布函数,若对于所有<span class="math inline">\(x,y\)</span>有</p><p><span class="math display">\[P\{X\le x, Y\le y\}=P\{X\le x\}P\{Y\le y\}\]</span></p><p>即<span class="math inline">\(F(x,y)=F_X(x)F_Y(y)\)</span>, 则称随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>是相互独立的.</p><h3 id="离散型随机变量-1">离散型随机变量</h3><p>离散型随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>相互独立的充要条件是它们的联合分布函数等于两个边缘分布绿的乘积,即</p><p><span class="math display">\[P\{X=x_i,Y=y_j\}=P\{X=x_i\}P\{Y=y_j\}\]</span> 即<span class="math inline">\(p_{ij}=p_{i\cdot} \cdot p_{\cdot j}\)</span></p><h3 id="连续型随机变量-1">连续型随机变量</h3><p>连续型随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>相互独立的充要条件是它们的联合概率密度<span class="math inline">\(f(x,y)\)</span>等于边缘概率密度<span class="math inline">\(f_X(x)\)</span>和<span class="math inline">\(f_Y(y)\)</span>的乘积,即</p><p><span class="math display">\[f(x,y)=f_X(x)f_Y(y)\]</span></p><h2 id="两个随机变量的函数的分布">两个随机变量的函数的分布</h2><h3 id="两个离散型随机变量的函数的分布">两个离散型随机变量的函数的分布</h3><p><span class="math inline">\(Z=g(X,Y)\)</span>的概率分布的一般求法</p><p>设<span class="math inline">\((X,Y)\)</span>为离散型随机变量,其概率分布为</p><p><span class="math display">\[P\{X=x_i,Y=y_j\} = p_{ij} \qquad i,j=1,2,...\]</span></p><p>则<span class="math inline">\(Z=g(X,Y)\)</span>的概率分布的一般求法是:先确定函数<span class="math inline">\(Z=g(X,Y)\)</span>的全部可能取值<span class="math inline">\(z=g(x_i,y_j)(i,j=1,2,...)\)</span>;再确定相应概率</p><p><span class="math display">\[P\{Z=g(x_i,y_j)\}=P\{X=x_i,Y=y_j\}=p_{ij}\]</span></p><p>然后将<span class="math inline">\(z=g(x_i,y_j)(i,j=1,2,...)\)</span>中相同的值合并,相应的概率相加,并将<span class="math inline">\(z\)</span>值按从小到大的顺序重新排列,且与其概率对应,即可写出<span class="math inline">\(Z=g(X,Y)\)</span>的概率分布.</p><p>两个离散型随机变量的和的概率公式</p><p><span class="math display">\[P\{Z=k\}=\sum_{i=0}^k P\{X=i\}P\{Y=k-i\}=\sum_{j=0}^k P\{Y=j\}P\{X=k-j\}\]</span></p><h3 id="两个连续型随机变量的函数的分布">两个连续型随机变量的函数的分布</h3><h4 id="随机变量的和的分布">随机变量的和的分布</h4><p><span class="math display">\[f_Z(z)=\int_{-\infty}^{+\infty}f(z-y,y)dy\]</span></p><p>或</p><p><span class="math display">\[f_Z(z)=\int_{-\infty}^{+\infty}f(x,z-x)dx\]</span></p><h4 id="随机变量的商的分布">随机变量的商的分布</h4><p><span class="math display">\[f_Z(z)=\int_{-\infty}^{+\infty}|y|f(yz,y)dy\]</span></p><h4 id="随机变量的极值的分布">随机变量的极值的分布</h4><p>设<span class="math inline">\(X,Y\)</span>是两个相互独立的随机事件,称<span class="math inline">\(M=max(X,Y)\)</span>为最大值变量, <span class="math inline">\(N=min(X,Y)\)</span>为最小值变量, 统称为极值变量.</p><p><span class="math display">\[F_{max}(z)=P\{M \le z\}=P\{X\le z\}P\{Y\le z\}=F_X(z)F_Y(z)\]</span></p><p><span class="math display">\[\begin{aligned} F_{min}(z) &amp;=P\{N\le z\} \\ &amp;=1-P\{N&gt;z\} \\ &amp;=1-P\{Y&gt;z,X&gt;z\} \\ &amp;=1-P\{X&gt;z\}P\{Y&gt;z\} \\ &amp;=1-[1-F_X(z)][1-F_Y(z)] \end{aligned} \]</span></p><h2 id="nnge-2维随机变量"><span class="math inline">\(n(N\ge 2)\)</span>维随机变量</h2><h3 id="nnge-2维随机变量及其分布"><span class="math inline">\(n(N\ge 2)\)</span>维随机变量及其分布</h3><p>设<span class="math inline">\(E\)</span>是一个随机变量,其样本空间为<span class="math inline">\(S=\{e\}\)</span>, 设<span class="math inline">\(X_i=X_i(e),(i=1,2,...,n)\)</span>是定义在<span class="math inline">\(S\)</span>上的<span class="math inline">\(n\)</span>个随机变量,由它们构成的一个向量</p><p><span class="math display">\[(X_1,X_2,...,X_n)=(X_1(e),X_2(e),...X_n(e)) \qquad e \in S\]</span></p><p>称为<span class="math inline">\(n\)</span>维随机向量或<span class="math inline">\(n\)</span>维随机变量.</p><p>设<span class="math inline">\((X_1,X_2,...,X_n)\)</span>是<span class="math inline">\(n\)</span>维随机变量,对于任意实数<span class="math inline">\(x_1,x_2,...,x_n\)</span>,<span class="math inline">\(n\)</span>元函数</p><p><span class="math display">\[F(x_1,x_2,...,x_n)=P\{X_1\le x_1, X_2\le x_2, ..., X_n \le x_n\}\]</span></p><p>称为<span class="math inline">\(n\)</span>维随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的分布函数,或称为随机变量<span class="math inline">\(X_1,X_2,...X_n\)</span>的联合分布函数.</p><p>若存在非负函数<span class="math inline">\(f(x_1,x_2,...x_n)\)</span>, 使对于任意实数<span class="math inline">\(x_1,x_2,...,x_n\)</span>,有</p><p><span class="math display">\[F(x_1,x_2,...,x_n)=\int_{-\infty}^{x_n}\int_{-\infty}^{x_{n-1}}...\int_{-\infty}^{x_1}f(x_1,x_2,...,x_n)dx_1dx_2...dx_n\]</span></p><p>则称<span class="math inline">\(f(x_1,x_2,...x_n)\)</span>为<span class="math inline">\(n\)</span>维连续型随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的概率密度函数.</p><p>设<span class="math inline">\(X_i\)</span>可能取值为<span class="math inline">\(x_{ij_i}(i=1,2,...,n, \quad j_i=1,2,...)\)</span>, 则记</p><p><span class="math display">\[P\{X_1=x_{1j_1},X_2=x_{2j_2},...,X_n=x_{nj_n}\}=p_{j_1j_2...j_ns}\]</span></p><p>为<span class="math inline">\(n\)</span>为离散型随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的概率分布或分布律,或随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的联合分布律.</p><p>对于<span class="math inline">\(n\)</span>维空间中任一区域<span class="math inline">\(D, \{X_1,X_2,...,X_n\} \in D\)</span> 为一随机事件,若<span class="math inline">\(X_1,X_2,...,X_n\)</span>具有概率密度<span class="math inline">\(f(x_1,x_2,...,x_n\)</span>, 则概率</p><p><span class="math display">\[P\{(X_1,X_2,...,X_n) \in D\}=\int \int ... \int _D f(x_1,x_2,...,x_n)dx_1dx_2...dx_n\]</span></p><h3 id="n个随机变量的相互独立性"><span class="math inline">\(n\)</span>个随机变量的相互独立性</h3><p>若对于所有实数<span class="math inline">\(x_1,x_2,...,x_n\)</span>有</p><p><span class="math display">\[F(x_1,x_2,...,x_n)=F_{X_1}(x_1)F_{X_2}(x_2)...F_{X_n}(x_n)\]</span></p><p>则称<span class="math inline">\(n\)</span>个随机变量<span class="math inline">\(X_1,X_2,...,X_n\)</span>是相互独立的.</p><p>并且</p><p><span class="math display">\[f(x_1,x_2,...,x_n)=f_{X_1}(x_1)f_{X_2}(x_2)...f_{X_n}(x_n)\]</span></p><p>若对所有的实数<span class="math inline">\(x_1,x_2,...,x_m,y_1,y_2,...,y_n\)</span>,随机变量<span class="math inline">\((X_1,X_2,...,X_n,Y_1,Y_2,...,Y_n)\)</span>的分布函数<span class="math inline">\(F(x_1,x_2,...,x_m,y_1,y_2,...,y_n)\)</span>与关于<span class="math inline">\((X_1,X_2,...,X_m)\)</span>及<span class="math inline">\((Y_1,Y_2,...,Y_n)\)</span>的边缘分布函数<span class="math inline">\(F_1(x_1,x_2,...,x_m), F_2(y_1,y_2,...,y_n)\)</span>满足下述等式:</p><p><span class="math display">\[F(x_1,x_2,...,x_m,y_1,y_2,...,y_n)=F_1(x_1,x_2,...,x_m)F_2(y_1,y_2,...,y_n)\]</span></p><p>则称随机变量<span class="math inline">\((X_1,X_2,...,X_m)\)</span>与<span class="math inline">\((Y_1,Y_2,...,Y_n)\)</span>是相互独立的.</p><p>设<span class="math inline">\((X_1,X_2,...,X_m)\)</span>和<span class="math inline">\((Y_1,Y_2,...,Y_n)\)</span>相互独立,则<span class="math inline">\(X_i(i=1,2,...,m)\)</span>与<span class="math inline">\(Y_j(j=1,2,...,n)\)</span>相互独立.又若<span class="math inline">\(h,g\)</span>是连续函数,则<span class="math inline">\(h(X_1,X_2,...,X_m)\)</span>与<span class="math inline">\(g(Y_1,Y_2,...,Y_n)\)</span>相互独立.</p><h3 id="n维随机变量的函数的分布"><span class="math inline">\(n\)</span>维随机变量的函数的分布</h3><p>设<span class="math inline">\((X_1,X_2,...,X_n)\)</span>为<span class="math inline">\(n\)</span>维随机变量,其概率密度为<span class="math inline">\(f(x_1,x_2,...,x_n)\)</span>,<span class="math inline">\(g(x_1,x_2,...,x_n)\)</span>为<span class="math inline">\(n\)</span>元连续函数,则对任意实数<span class="math inline">\(z \in R, Z=g(X_1,X_2,...,X_n)\)</span>的分布函数为</p><p><span class="math display">\[F_Z(z)=P\{g(X_1,X_2,...,X_n) \le z\}=\int \int ... \int_{D_Z}f(x_1,x_2,...,x_n)dx_1dx_2...dx_n\]</span></p><p>其中<span class="math inline">\(D_Z=\{(x_1,x_2,...,x_n)|g(x_1,x_2,...,x_n) \le z\}\)</span>.</p><h1 id="随机变量的数字特征">随机变量的数字特征</h1><h2 id="数学期望">数学期望</h2><h3 id="数学期望的概念">数学期望的概念</h3><p>设离散型随机变量<span class="math inline">\(X\)</span>的分布律为</p><p><span class="math display">\[P\{X=x_k\}=p_k \qquad k=1,2,...\]</span></p><p>若级数<span class="math inline">\(\sum_{k=1}^{\infty}x_kp_k\)</span>绝对收敛,则称级数<span class="math inline">\(\sum_{k=1}^{\infty}x_kp_ks\)</span>的值为离散型随机变量<span class="math inline">\(X\)</span>的数学期望,记为<span class="math inline">\(E(X)\)</span>, 即</p><p><span class="math display">\[E(X)=\sum_{k=1}^{\infty}x_kp_k\]</span></p><p>数学期望可简称为期望或均值.</p><p>设连续型随机变量<span class="math inline">\(X\)</span>的概率密度为<span class="math inline">\(f(x)\)</span>,若积分</p><p><span class="math display">\[f_{-\infty}^{+\infty}xf(x)dx\]</span></p><p>绝对收敛,则称积分<span class="math inline">\(f_{-\infty}^{+\infty}xf(x)dx\)</span>的值为随机变量<span class="math inline">\(X\)</span>的数学期望,记为<span class="math inline">\(E(X)\)</span>,即</p><p><span class="math display">\[E(X)=f_{-\infty}^{+\infty}xf(x)dx\]</span></p><h3 id="随机变量的函数的数学期望">随机变量的函数的数学期望</h3><p>设<span class="math inline">\(Y\)</span>是随机变量<span class="math inline">\(X\)</span>的函数:<span class="math inline">\(Y=g(X)\)</span>(<span class="math inline">\(g\)</span>是连续函数)</p><ol style="list-style-type: decimal"><li><span class="math inline">\(X\)</span>是离散型随机变量,它的分布律为<span class="math inline">\(p_K=P\{X=x_k\}(k=1,2,...)\)</span>,若<span class="math inline">\(\sum_{k=1}^{\infty}g(x_k)p_k\)</span>绝对收敛,则有</li></ol><p><span class="math display">\[E(Y)=E[g(X)]=\sum_{k=1}^{\infty}g(x_k)p_k\]</span></p><ol start="2" style="list-style-type: decimal"><li><span class="math inline">\(X\)</span>是连续型随机变量,它的概率密度为<span class="math inline">\(f(x)\)</span>,若<span class="math inline">\(\int_{-\infty}^{+\infty}g(x)f(x)dx\)</span>绝对收敛,则有</li></ol><p><span class="math display">\[E(Y)=E[g(X)]=\int_{-\infty}^{+\infty}g(x)f(x)dx\]</span></p><h3 id="数学期望的简单性质">数学期望的简单性质</h3><ol style="list-style-type: decimal"><li>(线性法则)设<span class="math inline">\(X\)</span>为随机变量,其期望为<span class="math inline">\(E(X)\)</span>,对于任意常数<span class="math inline">\(a,b\)</span>有</li></ol><p><span class="math display">\[E(aX+b)=aE(X)+b\]</span></p><ol start="2" style="list-style-type: decimal"><li>(加法法则) 设<span class="math inline">\(X,Y\)</span>为随机变量,则有</li></ol><p><span class="math display">\[E(X+Y)=E(X)+E(Y)\]</span></p><ol start="3" style="list-style-type: decimal"><li>(乘法法则) 设<span class="math inline">\(X,Y\)</span>为两个相互独立的随机变量,则</li></ol><p><span class="math display">\[E(XY)=E(X)E(Y)\]</span></p><ol start="4" style="list-style-type: decimal"><li><p>(柯西-许瓦兹不等式)</p><p>设<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>是两个随机变量,则</p></li></ol><p><span class="math display">\[|E(XY)|^2 \le E(X^2)E(Y^2)\]</span></p><h2 id="方差">方差</h2><h3 id="概念-2">概念</h3><p>设<span class="math inline">\(X\)</span>是一个随机变量,若<span class="math inline">\(E\{[X-E(X)]^2\}\)</span>存在,则乘<span class="math inline">\(E\{[X-E(X)]^2\}\)</span>称为<span class="math inline">\(X\)</span>的方差,记为<span class="math inline">\(D(X)\)</span>或<span class="math inline">\(Var(X)\)</span>,即</p><p><span class="math display">\[D(X)=Var(X)=E\{[X-E(X)]^2\}\]</span></p><p>显然<span class="math inline">\(D(X) \ge 0\)</span>, 故在应用中引入与随机变量<span class="math inline">\(X\)</span>具有相同量纲的量<span class="math inline">\(\sqrt{D(X)}\)</span>, 记为<span class="math inline">\(\sigma(X)\)</span>,称为标准差或均方差.</p><p>由方差的定义可知,随机变量<span class="math inline">\(X\)</span>的方差实际上就是<span class="math inline">\(X\)</span>的函数<span class="math inline">\(Y=g(X)=(X-E(X))^2\)</span>. 故</p><p>若<span class="math inline">\(X\)</span>为离散型随机变量,其分布律为<span class="math inline">\(p_k=P\{X=x_k\}(k=1,2,...)\)</span>,其方差为</p><p><span class="math display">\[D(X)=\sum_{k=1}^{\infty}[x_k-E(X)]^2p_k\]</span></p><p>若<span class="math inline">\(X\)</span>为连续型随机变量,其概率密度为<span class="math inline">\(f(x)\)</span>,则<span class="math inline">\(X\)</span>的方差为</p><p><span class="math display">\[D(X)=\int_{-\infty}^{+\infty}[x-E(X)]^2f(x)dx\]</span></p><p>并且具有公式</p><p><span class="math display">\[D(X)=E[X^2]-[E(X)]^2\]</span></p><h3 id="方差的简单性质">方差的简单性质</h3><ol style="list-style-type: decimal"><li>设<span class="math inline">\(X\)</span>为随机变量,对于任意的常数<span class="math inline">\(a,b\)</span></li></ol><p><span class="math display">\[D(aX+b)=a^2D(X)\]</span></p><ol start="2" style="list-style-type: decimal"><li>设<span class="math inline">\(X,Y\)</span>为两个相互独立的随机变量,则有</li></ol><p><span class="math display">\[D(X+Y)=D(X)+D(Y)\]</span></p><ol start="3" style="list-style-type: decimal"><li>(契比雪夫不等式) 设<span class="math inline">\(X\)</span>为一随机变量,其均值<span class="math inline">\(E(X)=\mu\)</span>,方差<span class="math inline">\(D(X)=\sigma^2\)</span>,则对任意正数<span class="math inline">\(\sigma &gt; 0\)</span>,有</li></ol><p><span class="math display">\[P\{|X-\mu|\ge \varepsilon \} \le \frac{\sigma^2}{\varepsilon^2}\]</span></p><ol start="4" style="list-style-type: decimal"><li><span class="math inline">\(D(X)=0\)</span>的充要条件是<span class="math inline">\(X\)</span>以概率1取常数<span class="math inline">\(\mu =E(X)\)</span>,即</li></ol><p><span class="math display">\[P\{X=\mu \} = 1\]</span></p><p>### 几种重要随机变量的数学期望及方差</p><ol style="list-style-type: decimal"><li><p>二项分布<span class="math inline">\(B(n,p)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(n,p\)</span>的二项分布,其分布律为:</p></li></ol><p><span class="math display">\[P\{X=k\}=\left( \begin{matrix} n \\ k \end{matrix} \right) p^k(1-p)^{n-k}\]</span></p><p><span class="math inline">\(E(X)=np, \quad D(X)=np(1-p)\)</span></p><ol start="2" style="list-style-type: decimal"><li><p>泊松分布<span class="math inline">\(\pi(\lambda)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\lambda\)</span>的泊松分布,其 分布律为:</p></li></ol><p><span class="math display">\[P\{X=k\}=\frac{\lambda^ke^{-\lambda}}{k!} \qquad k=0,1,2,...; \lambda&gt;0\]</span></p><p><span class="math inline">\(E(X)=\lambda \qquad D(X)=\lambda\)</span></p><ol start="3" style="list-style-type: decimal"><li><p>几何分布<span class="math inline">\(Ge(p)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(p\)</span>的几何分布,其分布律为</p></li></ol><p><span class="math display">\[P\{X=k\}=pq^{k-1} \quad k=1,2,.., \quad 0&lt;p&lt;1, q=1-p\]</span></p><p><span class="math inline">\(E(X)=\frac{1}{p} \qquad D(X)=\frac{q}{p^2}\)</span></p><ol start="4" style="list-style-type: decimal"><li>均匀分布<span class="math inline">\(U(a,b)\)</span></li></ol><p>设在区间<span class="math inline">\((a,b)\)</span>上服从均匀分布, 其概率密度为</p><p><span class="math display">\[f(x)=\begin{cases} \frac{1}{b-q} &amp; a&lt;x&lt;b \\ 0 &amp; other \end{cases}\]</span></p><p><span class="math inline">\(E(X)=\frac{a+b}{2} \qquad D(x)=\frac{(b-a)^2}{12}\)</span></p><ol start="5" style="list-style-type: decimal"><li><p>指数分布<span class="math inline">\(Z(\alpha)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\alpha\)</span>的指数分布,其概率密度为</p></li></ol><p><span class="math display">\[f(x)=\begin{cases} \alpha e^{-\alpha x} &amp; x&gt;0, \alpha &gt; 0 \\ 0 &amp; x \le 0 \end{cases}\]</span></p><p><span class="math inline">\(E(X)=\frac{1}{\alpha} \qquad D(X)=\frac{1}{\alpha ^2}\)</span></p><ol start="6" style="list-style-type: decimal"><li><p>正态分布<span class="math inline">\(N(\mu, \sigma ^2)\)</span></p><p>设<span class="math inline">\(X\)</span>服从参数为<span class="math inline">\(\mu, \sigma ^2\)</span>的正态分布,其概率密度为</p></li></ol><p><span class="math display">\[f(X)=\frac{1}{\sqrt{2\pi \sigma}} e ^{-\frac{(x-\mu)^2}{2\sigma ^2}} \qquad \sigma &gt; 0, -\infty &lt; x &lt; +\infty\]</span></p><p><span class="math inline">\(E(X)=\mu, \qquad D(X)=\sigma ^2\)</span></p><h2 id="协方差与相关系数">协方差与相关系数</h2><h3 id="概念-3">概念</h3><p>设<span class="math inline">\((X,Y)\)</span>为二维随机变量,量<span class="math inline">\(E\{[X-E(X)][Y-E(Y)]\}\)</span>称为<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>的协方差, 记为<span class="math inline">\(Cov(X,Y)\)</span>,即</p><p><span class="math display">\[Cov(X,Y)=E\{[X-E(X)][Y-E(Y)]\}\]</span></p><p>而量</p><p><span class="math display">\[\rho _{_{XY}}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}\]</span></p><p>称为随机变量<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>的相关系数, <span class="math inline">\(\rho _{_{XY}}\)</span>是一个无量纲的量.</p><p>特别的,当<span class="math inline">\(Y=X\)</span>时, <span class="math inline">\(Cov(X,X)=D(X)\)</span>,此时<span class="math inline">\(\rho _{_{XY}}=1\)</span>. 并且</p><p><span class="math display">\[D(X+Y)=D(X)+D(Y)+2Cov(X,Y)\]</span></p><p><span class="math display">\[Cov(X,Y)=E(XY)-E(X)E(Y)\]</span></p><p>设<span class="math inline">\(X,Y\)</span>为随机变量,<span class="math inline">\(a,b\)</span>为任意常数,则协方差<span class="math inline">\(Cov(X,Y)\)</span>具有一下性质:</p><ol style="list-style-type: decimal"><li><p><span class="math inline">\(Cov(X,Y)=Cov(Y,X)\)</span></p></li><li><p><span class="math inline">\(Cov(X+a,Y+b)=Cov(X,Y)\)</span></p></li><li><p><span class="math inline">\(Cov(aX,bY)=abCov(X,Y)\)</span></p></li><li><p><span class="math inline">\(Cov(X_1+X_2, Y)=Cov(X_1,Y)+Cov(X_2,Y)\)</span></p></li><li><p><span class="math inline">\(|Cov(X,Y)| \le \sqrt{D(X)} \sqrt{D(Y)}\)</span></p></li></ol><h3 id="相关系数的性质">相关系数的性质</h3><ol style="list-style-type: decimal"><li><p><span class="math inline">\(|\rho _{_{XY}}| \le 1\)</span></p></li><li><p>若<span class="math inline">\(X,Y\)</span>相互独立,且<span class="math inline">\(D(X),D(Y)\)</span>存在,则</p></li></ol><p><span class="math display">\[Cov(X,Y)=\rho _{_{XY}}=0\]</span></p><p>如果随机变量<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>的相关系数<span class="math inline">\(\rho _{_{XY}}\)</span>,则<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>不相关.</p><h2 id="矩及协方差矩阵">矩及协方差矩阵</h2><h3 id="概念-4">概念</h3><p>设<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>是随机变量, <span class="math inline">\(k,l\)</span>为任一正整数:</p><ol style="list-style-type: decimal"><li><p>若<span class="math inline">\(E(X^k)\)</span>存在,则称<span class="math inline">\(\mu_k=E(X^k)\)</span>为<span class="math inline">\(X\)</span>的<span class="math inline">\(k\)</span>阶原点矩,简称<span class="math inline">\(k\)</span>阶距.</p></li><li><p>若<span class="math inline">\(E[X-E(X)]^k\)</span>存在,则称<span class="math inline">\(\sigma_k=E[X-E(X)]^k\)</span>为<span class="math inline">\(X\)</span>的<span class="math inline">\(k\)</span>阶中心矩.</p></li><li><p>若<span class="math inline">\(E(X^kY^l)\)</span>存在,则称<span class="math inline">\(\mu_{kl}=E(X^kY^l)\)</span>为<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的<span class="math inline">\(k+l\)</span>阶混合原点矩.</p></li><li><p>若<span class="math inline">\(E\{[X-E(X)]^k[Y-E(Y)]^l\}\)</span>存在,则称<span class="math inline">\(\sigma_{kl}=E\{[X-E(X)]^k[Y-E(Y)]^l\}\)</span>为<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的<span class="math inline">\(k+l\)</span>阶混合中心矩.</p></li></ol><p>显然,<span class="math inline">\(X\)</span>的一阶原点矩<span class="math inline">\(E(X)\)</span>就是<span class="math inline">\(X\)</span>的数学期望,<span class="math inline">\(X\)</span>的一阶中心矩<span class="math inline">\(E[X-E(X)]\)</span>为<span class="math inline">\(X\)</span>的偏差的数学期望,其恒等于0,即</p><p><span class="math display">\[E[X-E(X)] = E(X)-E(X)=0\]</span></p><p>而<span class="math inline">\(X\)</span>的二阶中心矩<span class="math inline">\(E\{[X-E(X)]^2\}\)</span>就是<span class="math inline">\(X\)</span>的方差.<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的二阶混合中心矩就是<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的协方差<span class="math inline">\(Cov(X,Y)\)</span>.</p><h3 id="协方差矩阵">协方差矩阵</h3><p>设<span class="math inline">\(n\)</span>维随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的二阶混合中心矩</p><p><span class="math display">\[C_{ij}=Cov(X_i,Y_j)=E\{[X_i-E(X_i)][Y_j-E(Y_j)]\} \qquad i,j=1,2,...n\]</span></p><p>都存在,则称矩阵</p><p><span class="math display">\[C=\left \lgroup \begin{matrix} C_{11} &amp; C_{12} &amp; \cdots &amp; C_{1n} \\ C_{21} &amp; C_{22} &amp; \cdots &amp; C_{2n} \\ \vdots &amp; \vdots &amp; \cdots &amp; \vdots \\ C_{n1} &amp; C_{n2} &amp; \cdots &amp; C_{nn} \end{matrix} \right \rgroup\]</span></p><p>为<span class="math inline">\(n\)</span>维随机变量<span class="math inline">\((X_1,X_2,...,X_n)\)</span>的协方差矩阵.由于<span class="math inline">\(C_{ij}=C_{ji}(i,j=1,2,...n)\)</span>,因而矩阵<span class="math inline">\(C\)</span>为一对称矩阵.</p><h1 id="大数定律及中心极限定理">大数定律及中心极限定理</h1><h2 id="大数定律lln">大数定律<span class="math inline">\((LLN)\)</span></h2><p>设<span class="math inline">\(X_1,X_2,...,X_n,...,\)</span>是随便变量序列,<span class="math inline">\(E(X_k)(k=1,2,...)\)</span>存在. 令<span class="math inline">\(\bar{X}_n=\frac{1}{n}\sum_{k=1}^{n}X_k\)</span>,若对于任意给定正数<span class="math inline">\(\varepsilon &gt; 0\)</span>, 有</p><p><span class="math display">\[\lim_{n \rightarrow \infty}P\{|\bar{X}_n-E(\bar{X}_n)| \ge \varepsilon \} = 0\]</span></p><p>或</p><p><span class="math display">\[\lim_{n \rightarrow \infty}P\{|\bar{X}_n-E(\bar{X}_n)| &lt; \varepsilon \} =1 \]</span></p><p>则称<span class="math inline">\(\{X_n\}\)</span>服从大数定律或称大数法成立.</p><p>(贝努利定理)设<span class="math inline">\(n_A\)</span>是<span class="math inline">\(n\)</span>次独立重复试验中事件<span class="math inline">\(A\)</span>发生的次数,<span class="math inline">\(p\)</span>是事件<span class="math inline">\(A\)</span>在每次试验中发送的概率,则对于任意的正数<span class="math inline">\(\varepsilon &gt; 0\)</span>, 有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{|\frac{n_A}{n}-p| &lt; \varepsilon \} = 1 \]</span></p><p>或</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{|\frac{n_A}{n}-p| \ge \varepsilon \} = 0 \]</span></p><p>契比雪夫特殊情况: 设<span class="math inline">\(X_1,X_2,\cdots,X_n,\cdots\)</span>相互独立(即对于任意的<span class="math inline">\(n\ge 1, X_1,X_2,\cdots,X_n\)</span>是相互独立的), 且具有相同的数学期望和方差<span class="math inline">\(E(X_k)=\mu, D(X_k)=\sigma ^2(k=1,2,\cdots)\)</span>, 则对任意正数<span class="math inline">\(\varepsilon &gt; 0\)</span>, 有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P \{|\bar{X}_n - \mu | &lt; \varepsilon \} = 1\]</span></p><p>辛钦定理: 设随机变量序列<span class="math inline">\(X_1,X_2,\cdots,X_n,\cdots\)</span>相互独立,服从同一分布,且具有数学期望<span class="math inline">\(E(X_k)=\mu(k=1,2,...)\)</span>,则对于任意正数<span class="math inline">\(\varepsilon\)</span>有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{|\bar{X}_n - \mu| &lt; \varepsilon \} = 1\]</span></p><p>即</p><p><span class="math display">\[\bar{X}_n \stackrel{P} \longrightarrow \mu \]</span></p><h2 id="中心极限定理clt">中心极限定理<span class="math inline">\((CLT)\)</span></h2><p>凡是在一定条件下,断定随机变量序列<span class="math inline">\(X_1,X_2,\cdots\)</span>的部分和<span class="math inline">\(Y_n=\sum_{k=1}^{n}X_k\)</span>的极限分布为正态分布的定理,均称为中心极限定理.</p><p>即中心极限定理应当说明,在何种条件下,下式成立:对任意的<span class="math inline">\(x\)</span>,有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{\frac{Y_n - E(Y_n)}{\sqrt{D(Y_n)}} \le x \} = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}}dt=\Phi(x)\]</span></p><p>隶莫佛-拉普拉斯定理</p><p>设随机变量列<span class="math inline">\(Y_n(n=1,2,\cdots)\)</span>服从参数为<span class="math inline">\(n,p\)</span>的二项分布<span class="math inline">\(B(n,p)(0&lt;p&lt;1)\)</span>,则对于任意的<span class="math inline">\(x\)</span>,恒有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{\frac{Y_n - np}{\sqrt{np(1-p)}} \le x \} = \Phi(x)\]</span></p><p>独立同分布中极限定理</p><p>设<span class="math inline">\(X_1,X_2,\cdots,X_n,\cdots\)</span>相互独立,且服从同一分布,具有数学期望及方差:<span class="math inline">\(E(X_k)=\mu, D(X_k)=\sigma^2 \neq 0(k=1,2,\cdots)\)</span>,则随机变量<span class="math inline">\(Y_n=\sum_{k=1}{n}X_k\)</span>近似服从正态分布<span class="math inline">\(N(n\mu,n\sigma^2)\)</span>,即对于任意的<span class="math inline">\(x\)</span>,有</p><p><span class="math display">\[\lim_{n\rightarrow \infty}P\{\frac{Y_n - n\mu}{\sqrt{n}\sigma} \le x \} = \Phi(x)\]</span></p><p>李雅普诺夫定理</p><p>设随机变量<span class="math inline">\(X_1,X_2,\cdots,X_n\)</span>相互独立,它们具有数学期望和方差:</p><p><span class="math display">\[E(X_k)=\mu_k, D(X_k)=\sigma_k^2 \neq 0 \qquad k=1,2,\cdots\]</span></p><p>记<span class="math inline">\(B_n^2=\sum_{k=1}^n\sigma_k^2\)</span>,若存在正数<span class="math inline">\(\delta\)</span>,使得当<span class="math inline">\(n \rightarrow \infty\)</span>时,</p><p><span class="math display">\[\frac{1}{B_n^{2+\delta}} \sum_{k=1}^nE\{|X_k-\mu_k|^{2+\delta} \} \rightarrow 0\]</span></p><p>则随机变量<span class="math inline">\(Y_n=\sum_{k=1}^nX_k\)</span>近似服从正态分布<span class="math inline">\(N(\sum_{k=1}^n\mu_k,B_n^2)\)</span>, 即对于任意的<span class="math inline">\(x\)</span>,有</p><p><span class="math display">\[\lim_{n \rightarrow \infty} P\{\frac{Y_n-\sum_{k=1}^n \mu_k}{B_n} \le x \} = \Phi(x)\]</span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本概念&quot;&gt;基本概念&lt;/h1&gt;
&lt;h2 id=&quot;古典概型&quot;&gt;古典概型&lt;/h2&gt;
&lt;h3 id=&quot;古典改型的特点&quot;&gt;古典改型的特点:&lt;/h3&gt;
&lt;ol style=&quot;list-style-type: decimal&quot;&gt;
&lt;li&gt;试验的样本空间中的元素个数只有有限个,
      
    
    </summary>
    
      <category term="数学" scheme="https://mejhwu.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>线性代数基础</title>
    <link href="https://mejhwu.github.io/2018/04/19/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/"/>
    <id>https://mejhwu.github.io/2018/04/19/数学基础/线性代数基础/</id>
    <published>2018-04-18T16:00:00.000Z</published>
    <updated>2018-10-14T14:25:36.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性代数基础">线性代数基础</h1><h2 id="基础理论和符号">基础理论和符号</h2><p>线性代数提供了一种简单的表示和操作线性等式集（线性方程组）的方式。例如，考虑下面的方程组： <span class="math display">\[\begin{align}4x_1 - 5x_2 &amp; = -13 \\-2x_1 + 3x_2 &amp; = 9\end{align}\]</span> 上面的方程组中有两个公式和两个变量，正如中学代数中所学，<span class="math inline">\(x_1\)</span>和<span class="math inline">\(x_2\)</span>存在唯一解（除非方程组在一定程度上是退化的，比如第二个等式是第一个等式的简单乘积，但是上面的方程组中存在唯一解）。运用矩阵符号，我们能够更简单的表示上面的方程组： <span class="math display">\[\begin{align}Ax  = b &amp; \\with \ \  A =  \left [  \begin{matrix}4  &amp;  -5 \\ -2 &amp; 3 \end{matrix} \right]  &amp;, \ \  b = \left[ \begin{matrix} 13 \\ 9 \end{matrix} \right]\end{align}\]</span> 正如我们下面马上就要看见的，用这种形式来分析线性等式有很多优点（包含明显的节约空间）。</p><h3 id="基础符号">基础符号</h3><p>我们要使用下面的这些符号：</p><ul><li><p><span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span>表示一个<span class="math inline">\(m\)</span>行<span class="math inline">\(n\)</span>列的矩阵，矩阵<span class="math inline">\(A\)</span>的元素是实数。</p></li><li><p><span class="math inline">\(x \in \mathbb{R}^n\)</span>表示有<span class="math inline">\(n\)</span>个元素的向量。通常向量<span class="math inline">\(x\)</span>表示一个列向量（一个有<span class="math inline">\(n\)</span>行1列的矩阵）。如果我们要明确的表示行向量（1行<span class="math inline">\(n\)</span>列的矩阵），我们通常用<span class="math inline">\(x^T\)</span>表示（<span class="math inline">\(x^T\)</span>表示<span class="math inline">\(x\)</span>的转置）。</p></li><li><p>向量<span class="math inline">\(x\)</span>的第<span class="math inline">\(i\)</span>个元素表示为<span class="math inline">\(x_1\)</span>： <span class="math display">\[  x = \left[ \begin{matrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{matrix} \right]  \]</span></p></li><li><p>用符号<span class="math inline">\(a_{ij}\)</span>（或者<span class="math inline">\(A_{ij}, A_{i,j}\)</span>）表示矩阵<span class="math inline">\(A\)</span>的第<span class="math inline">\(i\)</span>行第<span class="math inline">\(j\)</span>列元素： <span class="math display">\[  A = \left[ \begin{matrix}a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nn}  \end{matrix} \right]  \]</span></p></li><li><p>用<span class="math inline">\(a_j\)</span>或<span class="math inline">\(A_j\)</span>表示<span class="math inline">\(A\)</span>的第<span class="math inline">\(j\)</span>列： <span class="math display">\[  A = \left[ \begin{matrix}\mid &amp; \mid &amp; &amp; \mid \\a_1 &amp; a_ 2 &amp; \cdots &amp; a_n \\\mid &amp; \mid &amp; &amp; \mid \\\end{matrix} \right]  \]</span></p></li><li><p>用<span class="math inline">\(a_i^T\)</span>或<span class="math inline">\(A_i^T\)</span>表示<span class="math inline">\(A\)</span>的第<span class="math inline">\(i\)</span>行： <span class="math display">\[  A = \left[ \begin{matrix}- &amp; a_1^T  &amp; - \\- &amp; a_2^T &amp; - \\  &amp;   \vdots &amp; \\- &amp; a_n^T &amp; -   \end{matrix} \right]  \]</span></p></li></ul><p>注意以上的这些定义可能会引起歧义（比如，在前面的两个定义中<span class="math inline">\(a_1\)</span>和<span class="math inline">\(a_1^T\)</span>不是相同的向量）。通常这些符号的意思可以很明显的从它们的使用中看出来。</p><h2 id="矩阵乘法">矩阵乘法</h2><p>两个矩阵<span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span> 和<span class="math inline">\(B \in \mathbb{R}^{n \times p}\)</span>的积是矩阵： <span class="math display">\[C = AB = \mathbb{R}^{m \times p}\]</span> 其中 <span class="math display">\[C_{ij} = \sum_{k=1}^n A_{ik}B_{kj}\]</span> 注意，为了是矩阵的乘积存在，<span class="math inline">\(A\)</span>的列数必须等于<span class="math inline">\(B\)</span>的行数。有很多种方法去看待矩阵乘法，我们会解释几种特殊的情况。</p><h3 id="向量-向量乘积">向量-向量乘积</h3><p>给定两个向量<span class="math inline">\(x, y \in \mathbb{R}^n\)</span>，<span class="math inline">\(x^Ty\)</span>（有时称为向量的<strong><em>內积</em></strong>或<strong><em>点积</em></strong>）的结果是一个实数： <span class="math display">\[x^Ty \in \mathbb{R} = \sum_{i=1}^nx_iy_i\]</span> 总是有<span class="math inline">\(x^Ty=y^Tx\)</span>。</p><p>给定两个向量<span class="math inline">\(x \in \mathbb{R}^m, y \in \mathbb{R}^n\)</span>（两个向量的长度不等），<span class="math inline">\(xy^T\)</span>称为向量的外积。其结果是一个矩阵，并且结果矩阵的元素为<span class="math inline">\((xy^T)_{ij}=x_iy_j\)</span>。 <span class="math display">\[xy^T \in \mathbb{R}_{m \times n} = \left[ \begin{matrix}                            x_1y_1 &amp; x_1y_2 &amp; \cdots &amp; x_1y_n \\                            x_2y_1 &amp; x_2y_2 &amp; \cdot &amp; x_2y_n \\                            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\                            x_my_1 &amp; x_my_2 &amp; \cdots &amp; x_my_n                            \end{matrix} \right]\]</span></p><h3 id="矩阵-向量乘积">矩阵-向量乘积</h3><p>给定一个矩阵<span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span>和向量<span class="math inline">\(x \in \mathbb{R}^n\)</span>，它们的乘积是一个向量<span class="math inline">\(y=Ax \in \mathbb{R}^m\)</span>，有两种方式来看待矩阵向量乘法：</p><p>如果<span class="math inline">\(A\)</span>写作行向量形式，我们能将<span class="math inline">\(Ax\)</span>表达为： <span class="math display">\[y = \left[ \begin{matrix}     - &amp; a_1^T &amp; - \\    - &amp; a_2^T &amp; - \\     &amp; \vdots &amp; \\     - &amp; a_m^T &amp; - \\    \end{matrix} \right] x    = \left[ \begin{matrix}     a_1^Tx \\    a_2^Tx \\     \vdots \\     a_m^Tx \\    \end{matrix} \right]\]</span> 换句话说，向量<span class="math inline">\(y\)</span>的第<span class="math inline">\(i\)</span>个元素等于矩阵<span class="math inline">\(A\)</span>的第<span class="math inline">\(i\)</span>行和向量<span class="math inline">\(x\)</span>的內积，<span class="math inline">\(y_i = a_i^Tx\)</span>。</p><p>另外，将<span class="math inline">\(A\)</span>写作行向量形式，在这种情况下， <span class="math display">\[y = \left[ \begin{matrix}     \mid &amp; \mid &amp; &amp; \mid \\    a_1 &amp; a_2 &amp; &amp; a_n \\    \mid &amp; \mid &amp; &amp; \mid     \end{matrix} \right]    \left[ \begin{matrix}     x_1 \\ x_2 \\ \vdots \\ x_n    \end{matrix} \right] =     \left[ \begin{matrix}     a_1    \end{matrix} \right] x_1 +      \left[ \begin{matrix}     a_2    \end{matrix} \right] x_2 +  \cdots +     \left[ \begin{matrix}     a_n    \end{matrix} \right] x_n\]</span> 话句话说，<span class="math inline">\(y\)</span>是矩阵的列的线性组合，其系数是向量<span class="math inline">\(x\)</span>的元素。</p><p>到目前为止，我们已经讨论过在矩阵右边乘上一个列向量，同样，也可以在矩阵左边乘上一个行向量。写作$y<sup>T=x</sup>TA,  其中 A ^{m n},  x ^m,  y ^n <span class="math inline">\(。类似于前面所讨论的，我们也可以用两张方式来表达\)</span>y^T<span class="math inline">\(，取决于我们将矩阵\)</span>A<span class="math inline">\(写作行向量形式还是列向量形式。首先将\)</span>A$写作列向量形式： <span class="math display">\[y^T=x^T    \left[ \begin{matrix}     \mid &amp; \mid &amp; &amp; \mid \\    a_1 &amp; a_2 &amp; &amp; a_n \\    \mid &amp; \mid &amp; &amp; \mid     \end{matrix} \right] =    \left[ \begin{matrix}     x^Ta_1 &amp; x^Ta_2 &amp; \cdots &amp; x^Ta_n    \end{matrix} \right]\]</span> 上面的公式表明了向量<span class="math inline">\(y^T\)</span>的第<span class="math inline">\(i\)</span>的元素等于向量<span class="math inline">\(x\)</span>和矩阵第<span class="math inline">\(i\)</span>列的内积。</p><p>最后，通过将<span class="math inline">\(A\)</span>写作行向量形式，我们得到了向量-矩阵乘积的最后一种表达方式。 <span class="math display">\[\begin{align}y^T &amp; =\left[ \begin{matrix}     x_1 &amp; x_2 &amp; \cdots &amp; x_n    \end{matrix} \right]    \left[ \begin{matrix}     - &amp; a_1^T &amp; - \\    - &amp; a_2^T &amp; - \\     &amp; \vdots &amp; \\     - &amp; a_n^T &amp; - \\    \end{matrix} \right]  \\ &amp;=    x_1\left[ \begin{matrix}  - &amp; a_1^T &amp; - \end{matrix} \right]  +     x_1\left[ \begin{matrix}  - &amp; a_2^T &amp; - \end{matrix} \right]  +     \cdots +     x_1\left[ \begin{matrix}  - &amp; a_n^T &amp; - \end{matrix} \right]\end{align}\]</span> 可以看出<span class="math inline">\(y^T\)</span>是<span class="math inline">\(A\)</span>的行的线性组合，其系数是<span class="math inline">\(x\)</span>的元素。</p><h3 id="矩阵-矩阵乘积">矩阵-矩阵乘积</h3><p>有了以上的基础后，我们可以用4种不同的方式来看待本节开始所定义的矩阵-矩阵乘积<span class="math inline">\(C=AB\)</span>。首先，我们可以将矩阵-矩阵乘积看作是向量-向量乘积的一个集合。一个很容易从定义中就能看出的观点，矩阵<span class="math inline">\(C\)</span>的第<span class="math inline">\(i,j\)</span>个元素是矩阵<span class="math inline">\(A\)</span>的第<span class="math inline">\(i\)</span>行和矩阵<span class="math inline">\(B\)</span>的第<span class="math inline">\(j\)</span>列的内积。用符号表示如下： <span class="math display">\[C=AB=\left[ \begin{matrix}     - &amp; a_1^T &amp; - \\    - &amp; a_2^T &amp; - \\     &amp; \vdots &amp; \\     - &amp; a_m^T &amp; - \\    \end{matrix} \right]    \left[ \begin{matrix}     \mid &amp; \mid &amp; &amp; \mid \\    b_1 &amp; b_2 &amp; \cdots   &amp; b_p\\    \mid &amp; \mid &amp; &amp; \mid     \end{matrix} \right] =     \left[ \begin{matrix}     a_1^Tb_1 &amp; a_1^Tb_2 &amp; \cdots &amp; a_1^Tb_p \\    a_2^Tb_1 &amp; a_2^Tb_2 &amp; \cdots &amp; a_2^Tb_p \\    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\    a_m^Tb_1 &amp; a_m^Tb_2 &amp; \cdots &amp; a_m^Tb_p \\    \end{matrix} \right]\]</span> 因为<span class="math inline">\(A \in \mathbb{R}^{m \times n}, \ B \in \mathbb{R}^{n \times p}, a_i \in \mathbb{R}^n, b_j \in \mathbb{R}^n\)</span>，这些內积总是有意义的。用行向量表示<span class="math inline">\(A\)</span>，用列向量表示<span class="math inline">\(B\)</span>是最“自然“的表示。相应的，当我们用行向量表示<span class="math inline">\(A\)</span>，用列向量表示<span class="math inline">\(B\)</span>时，<span class="math inline">\(AB\)</span>可以解释为向量外积的和。用符号表示如下： <span class="math display">\[C=AB=\left[ \begin{matrix}     \mid &amp; \mid &amp; &amp; \mid \\    a_1 &amp; a_2 &amp; \cdots &amp; a_n\\    \mid &amp; \mid &amp; &amp; \mid     \end{matrix} \right]    \left[ \begin{matrix}     - &amp; a_b^T &amp; - \\    - &amp; a_b^T &amp; - \\     &amp; \vdots &amp; \\     - &amp; a_n^T &amp; - \\    \end{matrix} \right]    =\sum_{i=1}^n a_ib_i^T\]</span> 用另一种方式来看，对于所有的<span class="math inline">\(i\)</span>，<span class="math inline">\(AB\)</span>等于<span class="math inline">\(A\)</span>的第<span class="math inline">\(i\)</span>行和<span class="math inline">\(B\)</span>的第<span class="math inline">\(i\)</span>列的外积的和。因此，在这种情况下，<span class="math inline">\(a_i \in \mathbb{R}^m, \ b_i \in \mathbb{R}^p\)</span>，外积<span class="math inline">\(a_ib_i^T\)</span>的维度是<span class="math inline">\(m \times p\)</span>，其与<span class="math inline">\(C\)</span>的维度一样。</p><p>其次，我们也可以将矩阵-矩阵乘积看作是一个矩阵-向量乘积的集合。特别地，如果将<span class="math inline">\(B\)</span>用列向量表示，我们能够将<span class="math inline">\(C\)</span>的列看作是<span class="math inline">\(A\)</span>和<span class="math inline">\(B\)</span>的列之间的矩阵-向量乘积。用符号表示： <span class="math display">\[C=AB=A    \left[ \begin{matrix}     \mid &amp; \mid &amp; &amp; \mid \\    b_1 &amp; b_2 &amp; \cdots  &amp; b_p\\    \mid &amp; \mid &amp; &amp; \mid     \end{matrix} \right]  =     \left[ \begin{matrix}     \mid &amp; \mid &amp; &amp; \mid \\    Ab_1 &amp;A b_2 &amp; \cdots  &amp; Ab_p\\    \mid &amp; \mid &amp; &amp; \mid     \end{matrix} \right]\]</span> 这里<span class="math inline">\(C\)</span>的第<span class="math inline">\(i\)</span>列是在右边乘上向量的矩阵-向量乘法，<span class="math inline">\(c_i = Ab_i\)</span>。这个矩阵-向量乘法能够依次用前面部分所讲的观点解释。最后，我们有类似的观点，用行向量表示<span class="math inline">\(A\)</span>，<span class="math inline">\(C\)</span>的行可以看作A的行和<span class="math inline">\(B\)</span>之间的矩阵-向量乘积。 <span class="math display">\[C=AB=\left[ \begin{matrix}     - &amp; a_1^T &amp; - \\    - &amp; a_2^T &amp; - \\     &amp; \vdots &amp; \\     - &amp; a_m^T &amp; - \\    \end{matrix} \right] B =    \left[ \begin{matrix}     - &amp; a_1^TB &amp; - \\    - &amp; a_2^TB &amp; - \\     &amp; \vdots &amp; \\     - &amp; a_m^TB &amp; - \\    \end{matrix} \right]\]</span> 这里，<span class="math inline">\(C\)</span>的第<span class="math inline">\(i\)</span>行给定为在左边乘上向量的矩阵-向量乘法，<span class="math inline">\(c_i^T=a_i^TB\)</span>。</p><p>当这些所有的观点都可以很容易的从在第一部分中所个的最初的定义中推导出来，如此大程度的解剖矩阵乘法看起来有点用力过猛。但是，事实上所有的线性代数都是用一定的方式处理矩阵乘法，并且值得花一定的时间去对以上讨论的观点有一个直观的理解。</p><p>另外，在更高层次上去了解一些矩阵乘法的基本属性是很有用的。</p><ul><li>矩阵乘法满足交换律：<span class="math inline">\((AB)C=A(BC)\)</span></li><li>矩阵乘法满足分配律：<span class="math inline">\(A(B+C)=AB+AC\)</span></li><li>一般而言，矩阵乘法是不能左右交换的：<span class="math inline">\(AB \neq BA\)</span></li></ul><h2 id="操作和属性">操作和属性</h2><p>这部分我们将呈现几种矩阵和向量的操作与属性。希望这些大量的矩阵处理能帮助你回顾，因此这些笔记指数作为这些主题的参考（hopefully a great deal of this will be review for you, so the notes can just serve as a reference for these topics）。</p><h3 id="单位矩阵和对角矩阵">单位矩阵和对角矩阵</h3><p>单位矩阵表示为<span class="math inline">\(I \in \mathbb{R}^{n \times n}\)</span>，是一个对角线上为1其余全为0的方阵， <span class="math display">\[I_{ij} = \left \{ \begin{align} &amp; 1 &amp; i = j \\                             &amp;0 &amp; i \ne  j\end{align} \right.\]</span></p><p>对于所有的<span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span>， <span class="math display">\[AI=A=IA\]</span> 其中<span class="math inline">\(I\)</span>的大小由<span class="math inline">\(A\)</span>的维数决定，所以以上的乘法是可以成立的。</p><p>对角阵是一个非对角元素都为0的矩阵，通常表示为<span class="math inline">\(D=diag(d_1, d_2, \cdots, d_n)\)</span>， <span class="math display">\[D_{ij}=\left\{ \begin{align} &amp; d_i &amp; i=j  \\ &amp; 0 &amp; i \ne j \end{align} \right.\]</span> 很明显，<span class="math inline">\(I=diag(1,1,\cdots, 1)\)</span>.</p><h3 id="转置">转置</h3><p>转置是指将矩阵的行列翻转。给定一个矩阵<span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span>，其转置(写作<span class="math inline">\(A^T\)</span>)定义为 <span class="math display">\[A^T \in \mathbb{R}^{n \times m}, \ (A^T)_{ij} = A_{ji}\]</span> 实际上，我们已经在描述行向量中已经使用过转置了，因为列向量的转置就是行向量。</p><p>转置具有以下属性：</p><ul><li><span class="math inline">\((A^T)^T=A\)</span></li><li><span class="math inline">\((AB)^T= B^TA^T\)</span></li><li><span class="math inline">\((A+B)^T=A^T+B^T\)</span></li></ul><h3 id="对称矩阵">对称矩阵</h3><p>如果方阵<span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span>，并且<span class="math inline">\(A=A^T\)</span>，则矩阵<span class="math inline">\(A\)</span>称为对称阵。如果<span class="math inline">\(A=-A^T\)</span>，那么<span class="math inline">\(A\)</span>就称为反对称的。对于所有的矩阵<span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span>，矩阵<span class="math inline">\(A+A^T\)</span>是对称的，矩阵<span class="math inline">\(A-A^T\)</span>是反对称的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性代数基础&quot;&gt;线性代数基础&lt;/h1&gt;
&lt;h2 id=&quot;基础理论和符号&quot;&gt;基础理论和符号&lt;/h2&gt;
&lt;p&gt;线性代数提供了一种简单的表示和操作线性等式集（线性方程组）的方式。例如，考虑下面的方程组： &lt;span class=&quot;math display&quot;&gt;\[

      
    
    </summary>
    
      <category term="数学" scheme="https://mejhwu.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>二叉搜索树</title>
    <link href="https://mejhwu.github.io/2017/10/22/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"/>
    <id>https://mejhwu.github.io/2017/10/22/算法/二叉搜索树/</id>
    <published>2017-10-21T16:00:00.000Z</published>
    <updated>2018-11-13T14:17:43.243Z</updated>
    
    <content type="html"><![CDATA[<p>二叉搜索树是一种被用于查找的二叉树。其要求是：每个节点都大于其左子树，小于或等于右子树。</p><div class="figure"><img src="..\images\binary_search_tree\binary_search_tree.png"></div><h3 id="查找">1. 查找</h3><p>从根节点开始查找。如果关键值等于当前节点值，说明查找成功。如果关键值小于当前节点值，则在当前节点的左子树上查找。如果关键值大于当前节点，则在当前节点的右子树上查找。</p><div class="figure"><img src="..\images\binary_search_tree\binary_search_tree_search.png"></div><h3 id="插入">2. 插入</h3><p>插入的节点一定是叶子节点。二叉搜索树插入前需要先进行查找，最后查找到的叶子节点即为插入节点的位置。</p><div class="figure"><img src="..\images\binary_search_tree\binary_search_tree_insert.png"></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;二叉搜索树是一种被用于查找的二叉树。其要求是：每个节点都大于其左子树，小于或等于右子树。&lt;/p&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src=&quot;..\images\binary_search_tree\binary_search_tree.png&quot;&gt;

      
    
    </summary>
    
      <category term="算法" scheme="https://mejhwu.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
</feed>
